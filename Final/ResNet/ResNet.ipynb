{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a54888",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# RESNET50 SOFT CHANNEL MASKING (BN-SAFE, GRAPH-SAFE, SERIALIZABLE)\n",
    "# ==========================================================\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "MODEL_PATH   = \"/content/ishan_100__resnet.h5\"\n",
    "DATASET_PATH = \"/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\"\n",
    "\n",
    "BATCH = 32\n",
    "KEEP_RATIO = 0.85\n",
    "ALPHA = 0.1\n",
    "EPOCHS = 10\n",
    "PATIENCE = 3\n",
    "UNFREEZE_LAST = 15\n",
    "img_size=(128,128)\n",
    "# ---------------- DATA ----------------\n",
    "def load_ds(path, img_size):\n",
    "    train = tf.keras.utils.image_dataset_from_directory(\n",
    "        path,\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=42,\n",
    "        image_size=img_size,\n",
    "        batch_size=BATCH\n",
    "    )\n",
    "    val = tf.keras.utils.image_dataset_from_directory(\n",
    "        path,\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        seed=42,\n",
    "        image_size=img_size,\n",
    "        batch_size=BATCH\n",
    "    )\n",
    "\n",
    "    scale = layers.Rescaling(1. / 255)\n",
    "    train = train.map(lambda x, y: (scale(x), y)).prefetch(tf.data.AUTOTUNE)\n",
    "    val   = val.map(lambda x, y: (scale(x), y)).prefetch(tf.data.AUTOTUNE)\n",
    "    return train, val\n",
    "\n",
    "# ---------------- FIND CONVS ----------------\n",
    "def find_convs(model):\n",
    "    convs = []\n",
    "\n",
    "    def walk(l):\n",
    "        if isinstance(l, layers.Conv2D):\n",
    "            convs.append(l)\n",
    "        if isinstance(l, tf.keras.Model):\n",
    "            for x in l.layers:\n",
    "                walk(x)\n",
    "\n",
    "    walk(model)\n",
    "    return convs\n",
    "\n",
    "# ---------------- SOFT CHANNEL MASK ----------------\n",
    "@tf.keras.utils.register_keras_serializable()\n",
    "class ChannelMask(layers.Layer):\n",
    "    def __init__(self, mask, alpha=0.1, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        mask = np.asarray(mask, dtype=\"float32\")\n",
    "        mask = np.where(mask > 0, 1.0, alpha)\n",
    "        mask = mask / np.mean(mask)\n",
    "        self.mask_init = mask\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.mask = self.add_weight(\n",
    "            name=\"mask\",\n",
    "            shape=(input_shape[-1],),\n",
    "            initializer=tf.constant_initializer(self.mask_init),\n",
    "            trainable=False\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        return x * self.mask[None, None, None, :]\n",
    "\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        cfg.update({\n",
    "            \"mask\": self.mask_init.tolist(),\n",
    "            \"alpha\": self.alpha\n",
    "        })\n",
    "        return cfg\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        mask = config.pop(\"mask\")\n",
    "        return cls(mask=mask, **config)\n",
    "\n",
    "# ---------------- MASK CREATION ----------------\n",
    "def make_masks(convs):\n",
    "    masks = {}\n",
    "    for l in convs:\n",
    "        W = l.kernel.numpy()\n",
    "        scores = np.mean(np.abs(W), axis=(0, 1, 2))\n",
    "        k = max(1, int(len(scores) * KEEP_RATIO))\n",
    "        thr = np.partition(scores, -k)[-k]\n",
    "        mask = (scores >= thr).astype(\"float32\")\n",
    "        masks[l.name] = mask\n",
    "        print(f\"[PRUNE] {l.name}: keep {int(mask.sum())}/{len(mask)}\")\n",
    "    return masks\n",
    "\n",
    "# ---------------- GRAPH-SAFE MASK INSERT ----------------\n",
    "def build_masked_resnet(base_model, masks):\n",
    "    tensor_map = {}\n",
    "    last_tensor = None\n",
    "\n",
    "    for inp in base_model.inputs:\n",
    "        tensor_map[inp] = inp\n",
    "        last_tensor = inp\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "\n",
    "        if isinstance(layer, layers.InputLayer):\n",
    "            continue\n",
    "\n",
    "        inbound = layer.input\n",
    "        if isinstance(inbound, list):\n",
    "            mapped = [tensor_map.get(x, x) for x in inbound]\n",
    "        else:\n",
    "            mapped = tensor_map.get(inbound, inbound)\n",
    "\n",
    "        x = layer(mapped)\n",
    "\n",
    "        # Insert mask AFTER BatchNorm\n",
    "        if isinstance(layer, layers.BatchNormalization):\n",
    "            prev = layer.input._keras_history[0]\n",
    "            if isinstance(prev, layers.Conv2D) and prev.name in masks:\n",
    "                x = ChannelMask(\n",
    "                    masks[prev.name],\n",
    "                    alpha=ALPHA,\n",
    "                    name=prev.name + \"_mask\"\n",
    "                )(x)\n",
    "\n",
    "        tensor_map[layer.output] = x\n",
    "        last_tensor = x\n",
    "\n",
    "    return tf.keras.Model(\n",
    "        inputs=base_model.inputs,\n",
    "        outputs=last_tensor,\n",
    "        name=base_model.name + \"_masked\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ---------------- FLOPs ----------------\n",
    "def baseline_flops(model):\n",
    "    total = 0\n",
    "    for l in find_convs(model):\n",
    "        if not l._inbound_nodes:\n",
    "            continue\n",
    "        _, h, w, cout = l.output.shape\n",
    "        cin = l.input.shape[-1]\n",
    "        k = l.kernel_size[0]\n",
    "        total += h * w * cin * cout * k * k * 2\n",
    "    return int(total)\n",
    "\n",
    "def effective_flops_from_masks(model, masks):\n",
    "    total = 0\n",
    "    for l in find_convs(model):\n",
    "        if l.name in masks and l._inbound_nodes:\n",
    "            _, h, w, _ = l.output.shape\n",
    "            cin = l.input.shape[-1]\n",
    "            k = l.kernel_size[0]\n",
    "            active = int(np.sum(masks[l.name]))\n",
    "            total += h * w * cin * active * k * k * 2\n",
    "    return int(total)\n",
    "\n",
    "# ---------------- MAIN ----------------\n",
    "def run():\n",
    "    print(\"[INFO] Loading base model...\")\n",
    "    base = tf.keras.models.load_model(MODEL_PATH, compile=False)\n",
    "\n",
    "    # ðŸ”§ force base graph build\n",
    "    dummy = tf.zeros((1,) + base.input_shape[1:])\n",
    "    _ = base(dummy)\n",
    "\n",
    "    train, val = load_ds(DATASET_PATH, base.input_shape[1:3])\n",
    "\n",
    "    convs = find_convs(base)\n",
    "    masks = make_masks(convs)\n",
    "\n",
    "    masked = build_masked_resnet(base, masks)\n",
    "\n",
    "    # ðŸ”§ force masked graph build\n",
    "    _ = masked(dummy)\n",
    "\n",
    "    # freeze\n",
    "    for l in masked.layers[:-UNFREEZE_LAST]:\n",
    "        l.trainable = False\n",
    "\n",
    "    masked.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    early = tf.keras.callbacks.EarlyStopping(\n",
    "        patience=PATIENCE,\n",
    "        restore_best_weights=True,\n",
    "        monitor=\"val_loss\"\n",
    "    )\n",
    "\n",
    "    masked.fit(\n",
    "        train,\n",
    "        validation_data=val,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[early],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    masked.save(\"masked_finetuned_resnet_leaf.keras\")\n",
    "\n",
    "    b = baseline_flops(base)\n",
    "    e = effective_flops_from_masks(base, masks)\n",
    "\n",
    "    print(\"\\n=========== EFFECTIVE FLOPs ANALYSIS ===========\")\n",
    "    print(f\"Baseline FLOPs : {b:,}\")\n",
    "    print(f\"Effective FLOPs: {e:,}\")\n",
    "    print(f\"Reduction (%)  : {(b - e) / b * 100:.2f}%\")\n",
    "    print(\"===============================================\")\n",
    "\n",
    "# ---------------- RUN ----------------\n",
    "if __name__ == \"__main__\":\n",
    "    run()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
