{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "396f64cb",
   "metadata": {},
   "source": [
    "# **Forward Pass for FNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1dcdf7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tensorflow.python.framework.convert_to_constants import (\n",
    "    convert_variables_to_constants_v2_as_graph\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# USER INPUTS (ONLY THESE)\n",
    "# ==========================================================\n",
    "\n",
    "MODEL_PATH = r\"D:\\college\\sem-8\\models\\FNN\\asthma_fnn_binary.h5\"\n",
    "DATASET_PATH = r\"D:\\college\\sem-8\\dataset\\clean_asthma_dataset.csv\"\n",
    "DATASET_FRACTION = 0.02\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# ==========================================================\n",
    "# 1️⃣ LOAD MODEL (ANY KERAS MODEL)\n",
    "# ==========================================================\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_PATH, compile=False)\n",
    "print(\"✔ Model loaded\")\n",
    "\n",
    "# Infer model input shape (remove batch dim)\n",
    "model_input_shape = model.input_shape\n",
    "if isinstance(model_input_shape, list):\n",
    "    model_input_shape = model_input_shape[0]\n",
    "\n",
    "feature_shape = tuple(model_input_shape[1:])\n",
    "print(\"✔ Model input shape:\", feature_shape)\n",
    "\n",
    "# ==========================================================\n",
    "# 2️⃣ LOAD DATASET (MODEL-AWARE)\n",
    "# ==========================================================\n",
    "\n",
    "def load_dataset(path, feature_shape):\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "\n",
    "    # ---------- CSV / TABULAR ----------\n",
    "    if ext == \".csv\":\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        num_features = int(np.prod(feature_shape))\n",
    "        X = df.iloc[:, :num_features].values.astype(np.float32)\n",
    "\n",
    "        # Dummy labels (not used for FLOPs)\n",
    "        y = np.zeros(len(X), dtype=np.int32)\n",
    "\n",
    "        return tf.data.Dataset.from_tensor_slices((X, y))\n",
    "\n",
    "    # ---------- NUMPY ----------\n",
    "    if ext == \".npz\":\n",
    "        data = np.load(path)\n",
    "        return tf.data.Dataset.from_tensor_slices(\n",
    "            (data[\"x\"], data[\"y\"])\n",
    "        )\n",
    "\n",
    "    raise ValueError(\"Unsupported dataset format\")\n",
    "\n",
    "dataset = load_dataset(DATASET_PATH, feature_shape)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "print(\"✔ Dataset loaded\")\n",
    "\n",
    "# ==========================================================\n",
    "# 3️⃣ SAMPLE DATASET (1–2%)\n",
    "# ==========================================================\n",
    "\n",
    "def sample_dataset(ds, fraction):\n",
    "    total_batches = tf.data.experimental.cardinality(ds).numpy()\n",
    "    sample_batches = max(1, int(total_batches * fraction))\n",
    "    return ds.take(sample_batches), total_batches\n",
    "\n",
    "sampled_ds, total_batches = sample_dataset(dataset, DATASET_FRACTION)\n",
    "\n",
    "# ==========================================================\n",
    "# 4️⃣ COMPUTE FLOPs (ROBUST & SAFE)\n",
    "# ==========================================================\n",
    "\n",
    "def compute_flops_per_sample(model, feature_shape):\n",
    "    \"\"\"\n",
    "    Computes FLOPs for ONE forward pass of ONE sample\n",
    "    \"\"\"\n",
    "    input_spec = tf.TensorSpec(\n",
    "        shape=(1,) + feature_shape,\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "\n",
    "    concrete_fn = tf.function(model).get_concrete_function(input_spec)\n",
    "\n",
    "    frozen_func, _ = convert_variables_to_constants_v2_as_graph(\n",
    "        concrete_fn\n",
    "    )\n",
    "\n",
    "    flops = tf.compat.v1.profiler.profile(\n",
    "        graph=frozen_func.graph,\n",
    "        options=tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "    )\n",
    "\n",
    "    return flops.total_float_ops\n",
    "\n",
    "flops_per_sample = compute_flops_per_sample(model, feature_shape)\n",
    "print(\"✔ FLOPs per sample:\", flops_per_sample)\n",
    "\n",
    "# ==========================================================\n",
    "# 5️⃣ EXTRAPOLATE TO FULL DATASET\n",
    "# ==========================================================\n",
    "\n",
    "total_samples = total_batches * BATCH_SIZE\n",
    "total_flops = flops_per_sample * total_samples\n",
    "total_gflops = total_flops / 1e9\n",
    "\n",
    "# ==========================================================\n",
    "# 6️⃣ FINAL REPORT\n",
    "# ==========================================================\n",
    "\n",
    "print(\"\\n========== FLOPs ESTIMATION REPORT ==========\")\n",
    "print(f\"Total samples     : {total_samples}\")\n",
    "print(f\"FLOPs per sample  : {flops_per_sample:.3e}\")\n",
    "print(f\"Total FLOPs       : {total_flops:.3e}\")\n",
    "print(f\"Total GFLOPs      : {total_gflops:.3f}\")\n",
    "print(\"============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8390a2d1",
   "metadata": {},
   "source": [
    "# **Forward Pass for CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ec3b8c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.python.framework.convert_to_constants import (\n",
    "    convert_variables_to_constants_v2_as_graph\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# USER INPUTS\n",
    "# ==========================================================\n",
    "\n",
    "MODEL_PATH = r\"D:\\college\\sem-8\\models\\CNN\\pothole_cnn_model.h5\"\n",
    "IMAGE_DIR  = r\"D:\\college\\sem-8\\dataset\\pothole\"   # class-wise folders\n",
    "DATASET_FRACTION = 0.02\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# ==========================================================\n",
    "# 1️⃣ LOAD CNN MODEL\n",
    "# ==========================================================\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_PATH, compile=False)\n",
    "print(\"✔ Model loaded\")\n",
    "\n",
    "# Infer input shape (H, W, C)\n",
    "model_input_shape = model.input_shape\n",
    "if isinstance(model_input_shape, list):\n",
    "    model_input_shape = model_input_shape[0]\n",
    "\n",
    "feature_shape = tuple(model_input_shape[1:])\n",
    "print(\"✔ Model input shape:\", feature_shape)\n",
    "\n",
    "IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = feature_shape\n",
    "\n",
    "# ==========================================================\n",
    "# 2️⃣ LOAD IMAGE DATASET (MODEL-AWARE)\n",
    "# ==========================================================\n",
    "\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    IMAGE_DIR,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"✔ Dataset loaded\")\n",
    "\n",
    "# ==========================================================\n",
    "# 3️⃣ SAMPLE DATASET (1–2%)\n",
    "# ==========================================================\n",
    "\n",
    "def sample_dataset(ds, fraction):\n",
    "    total_batches = tf.data.experimental.cardinality(ds).numpy()\n",
    "    sample_batches = max(1, int(total_batches * fraction))\n",
    "    return ds.take(sample_batches), total_batches\n",
    "\n",
    "sampled_ds, total_batches = sample_dataset(dataset, DATASET_FRACTION)\n",
    "\n",
    "# ==========================================================\n",
    "# 4️⃣ COMPUTE FLOPs PER SAMPLE\n",
    "# ==========================================================\n",
    "\n",
    "def compute_flops_per_sample(model, feature_shape):\n",
    "    input_spec = tf.TensorSpec(\n",
    "        shape=(1,) + feature_shape,\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "\n",
    "    concrete_fn = tf.function(model).get_concrete_function(input_spec)\n",
    "\n",
    "    frozen_func, _ = convert_variables_to_constants_v2_as_graph(\n",
    "        concrete_fn\n",
    "    )\n",
    "\n",
    "    flops = tf.compat.v1.profiler.profile(\n",
    "        graph=frozen_func.graph,\n",
    "        options=tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "    )\n",
    "\n",
    "    return flops.total_float_ops\n",
    "\n",
    "flops_per_sample = compute_flops_per_sample(model, feature_shape)\n",
    "print(\"✔ FLOPs per sample:\", flops_per_sample)\n",
    "\n",
    "# ==========================================================\n",
    "# 5️⃣ EXTRAPOLATE TO FULL DATASET\n",
    "# ==========================================================\n",
    "\n",
    "total_samples = total_batches * BATCH_SIZE\n",
    "total_flops = flops_per_sample * total_samples\n",
    "total_gflops = total_flops / 1e9\n",
    "\n",
    "# ==========================================================\n",
    "# 6️⃣ FINAL REPORT\n",
    "# ==========================================================\n",
    "\n",
    "print(\"\\n========== CNN FLOPs ESTIMATION REPORT ==========\")\n",
    "print(f\"Total samples     : {total_samples}\")\n",
    "print(f\"FLOPs per sample  : {flops_per_sample:.3e}\")\n",
    "print(f\"Total FLOPs       : {total_flops:.3e}\")\n",
    "print(f\"Total GFLOPs      : {total_gflops:.3f}\")\n",
    "print(\"===============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c9d625",
   "metadata": {},
   "source": [
    "# **Foreward Pass FNN with memory check and inference time for whole dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc273c6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FNN FEASIBILITY CHECK (TensorFlow 2.x)\n",
    "\n",
    "✔ FLOPs → speed estimation\n",
    "✔ Memory → crash prediction (YES / NO)\n",
    "✔ User-provided batch size\n",
    "✔ Optimizer auto-detection\n",
    "✔ Training cost estimation\n",
    "✔ Colab GPU support\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.python.framework.convert_to_constants import (\n",
    "    convert_variables_to_constants_v2\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# HARDWARE DATABASE\n",
    "# ==========================================================\n",
    "GPU_DATABASE = [\n",
    "    # Local GPUs\n",
    "    (\"RTX 3060\", 12 * 1024, 9_000),\n",
    "    (\"RTX 4090\", 24 * 1024, 55_000),\n",
    "    (\"RTX 5090\", 32 * 1024, 60_000),\n",
    "\n",
    "    # Google Colab GPUs\n",
    "    (\"Colab T4\",   16 * 1024, 4_000),\n",
    "    (\"Colab P100\", 16 * 1024, 9_000),\n",
    "    (\"Colab V100\", 16 * 1024, 14_000),\n",
    "    (\"Colab A100\", 40 * 1024, 14_000),\n",
    "]\n",
    "\n",
    "CPU_DATABASE = [\n",
    "    (8,  8 * 1024, 70),\n",
    "    (16, 16 * 1024, 100),\n",
    "    (32, 32 * 1024, 130),\n",
    "]\n",
    "\n",
    "# ==========================================================\n",
    "# MENU INPUT\n",
    "# ==========================================================\n",
    "def select_option(title, options):\n",
    "    print(f\"\\n{title}\")\n",
    "    for i, opt in enumerate(options, 1):\n",
    "        print(f\"{i}. {opt}\")\n",
    "    while True:\n",
    "        c = input(\"Select option number: \")\n",
    "        if c.isdigit() and 1 <= int(c) <= len(options):\n",
    "            return int(c) - 1\n",
    "        print(\"❌ Invalid selection. Try again.\")\n",
    "\n",
    "# ==========================================================\n",
    "# OPTIMIZER AUTO-DETECTION\n",
    "# ==========================================================\n",
    "def detect_optimizer(model):\n",
    "    try:\n",
    "        name = model.optimizer.__class__.__name__.lower()\n",
    "        if \"adamw\" in name:\n",
    "            return \"adamw\"\n",
    "        if \"adam\" in name:\n",
    "            return \"adam\"\n",
    "        if \"sgd\" in name:\n",
    "            return \"sgd\"\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "# ==========================================================\n",
    "# DATASET VALIDATION (CSV)\n",
    "# ==========================================================\n",
    "def load_csv_dataset(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    X = df.iloc[:, :-1].values\n",
    "    y = df.iloc[:, -1].values\n",
    "\n",
    "    num_samples = X.shape[0]\n",
    "    num_features = X.shape[1]\n",
    "    num_classes = len(set(y))\n",
    "\n",
    "    return num_samples, num_features, num_classes\n",
    "\n",
    "# ==========================================================\n",
    "# GFLOPs (INFERENCE)\n",
    "# ==========================================================\n",
    "def compute_model_gflops(model, input_dim):\n",
    "    model.trainable = False\n",
    "\n",
    "    @tf.function\n",
    "    def forward(x):\n",
    "        return model(x, training=False)\n",
    "\n",
    "    concrete_func = forward.get_concrete_function(\n",
    "        tf.TensorSpec([1, input_dim], tf.float32)\n",
    "    )\n",
    "\n",
    "    frozen_func = convert_variables_to_constants_v2(concrete_func)\n",
    "    graph_def = frozen_func.graph.as_graph_def()\n",
    "\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def, name=\"\")\n",
    "        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "        flops = tf.compat.v1.profiler.profile(\n",
    "            graph=graph,\n",
    "            cmd=\"op\",\n",
    "            options=opts\n",
    "        )\n",
    "\n",
    "    return flops.total_float_ops / 1e9\n",
    "\n",
    "# ==========================================================\n",
    "# TRAINING FLOPs (FNN)\n",
    "# ==========================================================\n",
    "def estimate_training_gflops(forward_gflops, num_samples, epochs):\n",
    "    return forward_gflops * num_samples * epochs * 2.0  # FNN\n",
    "\n",
    "# ==========================================================\n",
    "# MEMORY (CRASH) CHECK — FNN\n",
    "# ==========================================================\n",
    "def memory_check(model, batch_size, available_mem_mb, optimizer):\n",
    "    param_mb = model.count_params() * 4 / (1024 ** 2)\n",
    "\n",
    "    # FNN has small activations\n",
    "    activation_mb = param_mb * 1.5 * batch_size\n",
    "\n",
    "    optimizer_mb = param_mb * (2 if optimizer != \"sgd\" else 1)\n",
    "\n",
    "    total_mb = param_mb + activation_mb + optimizer_mb + 400\n",
    "\n",
    "    return param_mb, activation_mb, optimizer_mb, total_mb\n",
    "\n",
    "# ==========================================================\n",
    "# PRINT HELPERS (STANDARD FORMAT)\n",
    "# ==========================================================\n",
    "def print_dataset_info(num_classes, num_samples, input_shape):\n",
    "    print(\"\\n=== DATASET INFO ===\")\n",
    "    print(f\"Classes     : {num_classes}\")\n",
    "    print(f\"Samples     : {num_samples}\")\n",
    "    print(f\"Input shape : {input_shape}\")\n",
    "\n",
    "def print_flops_info(gflops):\n",
    "    print(\"\\n=== INFERENCE FLOPs ===\")\n",
    "    print(f\"GFLOPs per inference : {gflops:.4f}\")\n",
    "\n",
    "def print_memory_info(batch_size, param_mb, activation_mb, optimizer_mb, total_mb, available_mb):\n",
    "    print(\"\\n=== MEMORY CHECK ===\")\n",
    "    print(f\"Batch size         : {batch_size}\")\n",
    "    print(f\"Parameters        : {param_mb:.2f} MB\")\n",
    "    print(f\"Activations       : {activation_mb:.2f} MB\")\n",
    "    print(f\"Optimizer state   : {optimizer_mb:.2f} MB\")\n",
    "    print(f\"Estimated TOTAL   : {total_mb:.2f} MB\")\n",
    "    print(f\"Available memory : {available_mb} MB\")\n",
    "\n",
    "    if total_mb > available_mb:\n",
    "        print(\"RESULT            : ❌ WILL CRASH (OOM)\")\n",
    "    else:\n",
    "        print(\"RESULT            : ✅ WILL NOT CRASH\")\n",
    "\n",
    "def print_speed_info(model_gflops, hardware_gflops_s):\n",
    "    time_sec = model_gflops / hardware_gflops_s\n",
    "    fps = 1 / time_sec\n",
    "    print(\"\\n=== INFERENCE SPEED ===\")\n",
    "    print(f\"Time per inference : {time_sec:.6f} sec\")\n",
    "    print(f\"Theoretical FPS    : {fps:.1f}\")\n",
    "\n",
    "def print_training_cost(total_train_gflops, hardware_gflops_s):\n",
    "    train_time_sec = total_train_gflops / hardware_gflops_s\n",
    "    print(\"\\n=== TRAINING COST ===\")\n",
    "    print(f\"Total training FLOPs : {total_train_gflops:.2f} GFLOPs\")\n",
    "    print(f\"Training time       : {train_time_sec/60:.2f} minutes\")\n",
    "\n",
    "# ==========================================================\n",
    "# MAIN\n",
    "# ==========================================================\n",
    "def run_feasibility_check():\n",
    "    print(\"\\nFNN FEASIBILITY CHECK\\n\")\n",
    "\n",
    "    model_path = input(\"Enter FNN model path (.keras/.h5): \")\n",
    "    dataset_path = input(\"Enter CSV dataset path: \")\n",
    "    epochs = int(input(\"Enter training epochs: \"))\n",
    "    batch_size = int(input(\"Enter batch size (you plan to use): \"))\n",
    "\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    model.summary()\n",
    "\n",
    "    num_samples, num_features, num_classes = load_csv_dataset(dataset_path)\n",
    "    input_shape = (num_features,)\n",
    "\n",
    "    print_dataset_info(num_classes, num_samples, input_shape)\n",
    "\n",
    "    forward_gflops = compute_model_gflops(model, num_features)\n",
    "    print_flops_info(forward_gflops)\n",
    "\n",
    "    device_idx = select_option(\"Select device type:\", [\"GPU\", \"CPU\"])\n",
    "\n",
    "    if device_idx == 0:\n",
    "        gpu_idx = select_option(\"Select GPU:\", [g[0] for g in GPU_DATABASE])\n",
    "        _, available_mem_mb, hw_gflops = GPU_DATABASE[gpu_idx]\n",
    "    else:\n",
    "        cpu_idx = select_option(\n",
    "            \"Select CPU RAM:\",\n",
    "            [f\"{c[0]} GB RAM\" for c in CPU_DATABASE]\n",
    "        )\n",
    "        _, available_mem_mb, hw_gflops = CPU_DATABASE[cpu_idx]\n",
    "\n",
    "    optimizer = detect_optimizer(model)\n",
    "    if optimizer:\n",
    "        print(f\"✅ Detected optimizer: {optimizer}\")\n",
    "    else:\n",
    "        opt_idx = select_option(\"Select optimizer:\", [\"SGD\", \"Adam\", \"AdamW\"])\n",
    "        optimizer = [\"sgd\", \"adam\", \"adamw\"][opt_idx]\n",
    "\n",
    "    param_mb, act_mb, opt_mb, total_mb = memory_check(\n",
    "        model, batch_size, available_mem_mb, optimizer\n",
    "    )\n",
    "\n",
    "    print_memory_info(\n",
    "        batch_size, param_mb, act_mb, opt_mb, total_mb, available_mem_mb\n",
    "    )\n",
    "\n",
    "    print_speed_info(forward_gflops, hw_gflops)\n",
    "\n",
    "    total_train_gflops = estimate_training_gflops(\n",
    "        forward_gflops, num_samples, epochs\n",
    "    )\n",
    "    print_training_cost(total_train_gflops, hw_gflops)\n",
    "\n",
    "# ==========================================================\n",
    "# RUN\n",
    "# ==========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    run_feasibility_check()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617d29b3",
   "metadata": {},
   "source": [
    "# **Foreward Pass CNN with memory check and inference time for whole dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2855f4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CNN FEASIBILITY CHECK (TensorFlow 2.x)\n",
    "\n",
    "✔ FLOPs → speed estimation\n",
    "✔ Memory → crash prediction (YES / NO)\n",
    "✔ User-provided batch size\n",
    "✔ Optimizer auto-detection\n",
    "✔ Training cost estimation\n",
    "✔ Colab GPU support\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.framework.convert_to_constants import (\n",
    "    convert_variables_to_constants_v2\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# HARDWARE DATABASE\n",
    "# ==========================================================\n",
    "GPU_DATABASE = [\n",
    "    # Local GPUs\n",
    "    (\"RTX 3060\", 12 * 1024, 9_000),\n",
    "    (\"RTX 4090\", 24 * 1024, 55_000),\n",
    "    (\"RTX 5090\", 32 * 1024, 60_000),\n",
    "\n",
    "    # Google Colab GPUs\n",
    "    (\"Colab T4\",   16 * 1024, 4_000),\n",
    "    (\"Colab P100\", 16 * 1024, 9_000),\n",
    "    (\"Colab V100\", 16 * 1024, 14_000),\n",
    "    (\"Colab A100\", 40 * 1024, 14_000),\n",
    "]\n",
    "\n",
    "CPU_DATABASE = [\n",
    "    (8,  8 * 1024, 70),\n",
    "    (16, 16 * 1024, 100),\n",
    "    (32, 32 * 1024, 130),\n",
    "]\n",
    "\n",
    "# ==========================================================\n",
    "# MENU INPUT\n",
    "# ==========================================================\n",
    "def select_option(title, options):\n",
    "    print(f\"\\n{title}\")\n",
    "    for i, opt in enumerate(options, 1):\n",
    "        print(f\"{i}. {opt}\")\n",
    "    while True:\n",
    "        c = input(\"Select option number: \")\n",
    "        if c.isdigit() and 1 <= int(c) <= len(options):\n",
    "            return int(c) - 1\n",
    "        print(\"❌ Invalid selection. Try again.\")\n",
    "\n",
    "# ==========================================================\n",
    "# OPTIMIZER AUTO-DETECTION\n",
    "# ==========================================================\n",
    "def detect_optimizer(model):\n",
    "    try:\n",
    "        name = model.optimizer.__class__.__name__.lower()\n",
    "        if \"adamw\" in name:\n",
    "            return \"adamw\"\n",
    "        if \"adam\" in name:\n",
    "            return \"adam\"\n",
    "        if \"sgd\" in name:\n",
    "            return \"sgd\"\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "# ==========================================================\n",
    "# DATASET VALIDATION\n",
    "# ==========================================================\n",
    "def validate_image_dataset(dataset_dir):\n",
    "    if not os.path.isdir(dataset_dir):\n",
    "        raise ValueError(\"❌ Dataset path is not a directory\")\n",
    "\n",
    "    classes = [\n",
    "        d for d in os.listdir(dataset_dir)\n",
    "        if os.path.isdir(os.path.join(dataset_dir, d))\n",
    "    ]\n",
    "\n",
    "    if len(classes) < 2:\n",
    "        raise ValueError(\"❌ Dataset must have ≥2 class folders\")\n",
    "\n",
    "    num_samples = sum(len(files) for _, _, files in os.walk(dataset_dir))\n",
    "\n",
    "    return len(classes), num_samples\n",
    "\n",
    "# ==========================================================\n",
    "# GFLOPs (INFERENCE)\n",
    "# ==========================================================\n",
    "def compute_model_gflops(model, input_shape):\n",
    "    model.trainable = False\n",
    "\n",
    "    @tf.function\n",
    "    def forward(x):\n",
    "        return model(x, training=False)\n",
    "\n",
    "    concrete_func = forward.get_concrete_function(\n",
    "        tf.TensorSpec([1] + list(input_shape), tf.float32)\n",
    "    )\n",
    "\n",
    "    frozen_func = convert_variables_to_constants_v2(concrete_func)\n",
    "    graph_def = frozen_func.graph.as_graph_def()\n",
    "\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def, name=\"\")\n",
    "        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "        flops = tf.compat.v1.profiler.profile(\n",
    "            graph=graph,\n",
    "            cmd=\"op\",\n",
    "            options=opts\n",
    "        )\n",
    "\n",
    "    return flops.total_float_ops / 1e9\n",
    "\n",
    "# ==========================================================\n",
    "# TRAINING FLOPs (CNN)\n",
    "# ==========================================================\n",
    "def estimate_training_gflops(forward_gflops, num_samples, epochs):\n",
    "    return forward_gflops * num_samples * epochs * 2.5\n",
    "\n",
    "# ==========================================================\n",
    "# MEMORY (CRASH) CHECK — CNN\n",
    "# ==========================================================\n",
    "def memory_check(model, batch_size, available_mem_mb, optimizer):\n",
    "    param_mb = model.count_params() * 4 / (1024 ** 2)\n",
    "    activation_mb = param_mb * 4 * batch_size   # CNN multiplier\n",
    "    optimizer_mb = param_mb * (2 if optimizer != \"sgd\" else 1)\n",
    "\n",
    "    total_mb = param_mb + activation_mb + optimizer_mb + 600\n",
    "\n",
    "    return param_mb, activation_mb, optimizer_mb, total_mb\n",
    "\n",
    "# ==========================================================\n",
    "# PRINT HELPERS (STANDARD FORMAT)\n",
    "# ==========================================================\n",
    "def print_dataset_info(num_classes, num_samples, input_shape):\n",
    "    print(\"\\n=== DATASET INFO ===\")\n",
    "    print(f\"Classes     : {num_classes}\")\n",
    "    print(f\"Samples     : {num_samples}\")\n",
    "    print(f\"Input shape : {input_shape}\")\n",
    "\n",
    "def print_flops_info(gflops):\n",
    "    print(\"\\n=== INFERENCE FLOPs ===\")\n",
    "    print(f\"GFLOPs per inference : {gflops:.4f}\")\n",
    "\n",
    "def print_memory_info(batch_size, param_mb, activation_mb, optimizer_mb, total_mb, available_mb):\n",
    "    print(\"\\n=== MEMORY CHECK ===\")\n",
    "    print(f\"Batch size         : {batch_size}\")\n",
    "    print(f\"Parameters        : {param_mb:.2f} MB\")\n",
    "    print(f\"Activations       : {activation_mb:.2f} MB\")\n",
    "    print(f\"Optimizer state   : {optimizer_mb:.2f} MB\")\n",
    "    print(f\"Estimated TOTAL   : {total_mb:.2f} MB\")\n",
    "    print(f\"Available memory : {available_mb} MB\")\n",
    "\n",
    "    if total_mb > available_mb:\n",
    "        print(\"RESULT            : ❌ WILL CRASH (OOM)\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"RESULT            : ✅ WILL NOT CRASH\")\n",
    "        return True\n",
    "\n",
    "def print_speed_info(model_gflops, hardware_gflops_s):\n",
    "    time_sec = model_gflops / hardware_gflops_s\n",
    "    fps = 1 / time_sec\n",
    "    print(\"\\n=== INFERENCE SPEED ===\")\n",
    "    print(f\"Time per inference : {time_sec:.6f} sec\")\n",
    "    print(f\"Theoretical FPS    : {fps:.1f}\")\n",
    "\n",
    "def print_training_cost(total_train_gflops, hardware_gflops_s):\n",
    "    train_time_sec = total_train_gflops / hardware_gflops_s\n",
    "    print(\"\\n=== TRAINING COST ===\")\n",
    "    print(f\"Total training FLOPs : {total_train_gflops:.2f} GFLOPs\")\n",
    "    print(f\"Training time       : {train_time_sec/60:.2f} minutes\")\n",
    "\n",
    "# ==========================================================\n",
    "# MAIN\n",
    "# ==========================================================\n",
    "def run_feasibility_check():\n",
    "    print(\"\\nCNN FEASIBILITY CHECK\\n\")\n",
    "\n",
    "    model_path = input(\"Enter CNN model path (.keras/.h5): \")\n",
    "    dataset_path = input(\"Enter image dataset directory: \")\n",
    "    epochs = int(input(\"Enter training epochs: \"))\n",
    "    batch_size = int(input(\"Enter batch size (you plan to use): \"))\n",
    "\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    model.summary()\n",
    "\n",
    "    num_classes, num_samples = validate_image_dataset(dataset_path)\n",
    "    input_shape = model.input_shape[1:]\n",
    "\n",
    "    print_dataset_info(num_classes, num_samples, input_shape)\n",
    "\n",
    "    # FLOPs\n",
    "    forward_gflops = compute_model_gflops(model, input_shape)\n",
    "    print_flops_info(forward_gflops)\n",
    "\n",
    "    # Device selection\n",
    "    device_idx = select_option(\"Select device type:\", [\"GPU\", \"CPU\"])\n",
    "\n",
    "    if device_idx == 0:\n",
    "        gpu_idx = select_option(\"Select GPU:\", [g[0] for g in GPU_DATABASE])\n",
    "        _, available_mem_mb, hw_gflops = GPU_DATABASE[gpu_idx]\n",
    "    else:\n",
    "        cpu_idx = select_option(\n",
    "            \"Select CPU RAM:\",\n",
    "            [f\"{c[0]} GB RAM\" for c in CPU_DATABASE]\n",
    "        )\n",
    "        _, available_mem_mb, hw_gflops = CPU_DATABASE[cpu_idx]\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = detect_optimizer(model)\n",
    "    if optimizer:\n",
    "        print(f\"✅ Detected optimizer: {optimizer}\")\n",
    "    else:\n",
    "        opt_idx = select_option(\"Select optimizer:\", [\"SGD\", \"Adam\", \"AdamW\"])\n",
    "        optimizer = [\"sgd\", \"adam\", \"adamw\"][opt_idx]\n",
    "\n",
    "    # Memory check\n",
    "    param_mb, act_mb, opt_mb, total_mb = memory_check(\n",
    "        model, batch_size, available_mem_mb, optimizer\n",
    "    )\n",
    "\n",
    "    print_memory_info(\n",
    "        batch_size, param_mb, act_mb, opt_mb, total_mb, available_mem_mb\n",
    "    )\n",
    "\n",
    "    # Speed\n",
    "    print_speed_info(forward_gflops, hw_gflops)\n",
    "\n",
    "    # Training cost\n",
    "    total_train_gflops = estimate_training_gflops(\n",
    "        forward_gflops, num_samples, epochs\n",
    "    )\n",
    "    print_training_cost(total_train_gflops, hw_gflops)\n",
    "\n",
    "# ==========================================================\n",
    "# RUN\n",
    "# ==========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    run_feasibility_check()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3456eb",
   "metadata": {},
   "source": [
    "# **Foreward Pass ResNet with memory check and inference time for whole dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192d5bca",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RESNET FEASIBILITY CHECK (TensorFlow 2.x)\n",
    "\n",
    "✔ FLOPs → speed estimation\n",
    "✔ Memory → crash prediction (YES / NO)\n",
    "✔ User-provided batch size\n",
    "✔ Optimizer auto-detection\n",
    "✔ Training cost estimation\n",
    "✔ Colab GPU support\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.framework.convert_to_constants import (\n",
    "    convert_variables_to_constants_v2\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# HARDWARE DATABASE\n",
    "# ==========================================================\n",
    "GPU_DATABASE = [\n",
    "    # Local GPUs\n",
    "    (\"RTX 3060\", 12 * 1024, 9_000),\n",
    "    (\"RTX 4090\", 24 * 1024, 55_000),\n",
    "    (\"RTX 5090\", 32 * 1024, 60_000),\n",
    "\n",
    "    # Google Colab GPUs\n",
    "    (\"Colab T4\",   16 * 1024, 4_000),\n",
    "    (\"Colab P100\", 16 * 1024, 9_000),\n",
    "    (\"Colab V100\", 16 * 1024, 14_000),\n",
    "    (\"Colab A100\", 40 * 1024, 14_000),\n",
    "]\n",
    "\n",
    "CPU_DATABASE = [\n",
    "    (8,  8 * 1024, 70),\n",
    "    (16, 16 * 1024, 100),\n",
    "    (32, 32 * 1024, 130),\n",
    "]\n",
    "\n",
    "# ==========================================================\n",
    "# MENU INPUT\n",
    "# ==========================================================\n",
    "def select_option(title, options):\n",
    "    print(f\"\\n{title}\")\n",
    "    for i, opt in enumerate(options, 1):\n",
    "        print(f\"{i}. {opt}\")\n",
    "\n",
    "    while True:\n",
    "        choice = input(\"Select option number: \")\n",
    "        if choice.isdigit() and 1 <= int(choice) <= len(options):\n",
    "            return int(choice) - 1\n",
    "        print(\"❌ Invalid selection. Try again.\")\n",
    "\n",
    "# ==========================================================\n",
    "# OPTIMIZER AUTO-DETECTION\n",
    "# ==========================================================\n",
    "def detect_optimizer(model):\n",
    "    try:\n",
    "        opt = model.optimizer\n",
    "        name = opt.__class__.__name__.lower()\n",
    "        if \"adamw\" in name:\n",
    "            return \"adamw\"\n",
    "        if \"adam\" in name:\n",
    "            return \"adam\"\n",
    "        if \"sgd\" in name:\n",
    "            return \"sgd\"\n",
    "    except:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "# ==========================================================\n",
    "# DATASET VALIDATION\n",
    "# ==========================================================\n",
    "def validate_image_dataset(dataset_dir):\n",
    "    if not os.path.isdir(dataset_dir):\n",
    "        raise ValueError(\"❌ Dataset path is not a directory\")\n",
    "\n",
    "    classes = [\n",
    "        d for d in os.listdir(dataset_dir)\n",
    "        if os.path.isdir(os.path.join(dataset_dir, d))\n",
    "    ]\n",
    "\n",
    "    if len(classes) < 2:\n",
    "        raise ValueError(\"❌ Dataset must have ≥2 class folders\")\n",
    "\n",
    "    num_samples = sum(len(files) for _, _, files in os.walk(dataset_dir))\n",
    "\n",
    "    print(\"\\n=== DATASET INFO ===\")\n",
    "    print(f\"Classes     : {len(classes)}\")\n",
    "    print(f\"Samples     : {num_samples}\")\n",
    "    print(f\"Class names : {classes}\")\n",
    "\n",
    "    return num_samples\n",
    "\n",
    "# ==========================================================\n",
    "# GFLOPs (INFERENCE)\n",
    "# ==========================================================\n",
    "def compute_model_gflops(model, input_shape):\n",
    "    model.trainable = False\n",
    "\n",
    "    @tf.function\n",
    "    def forward(x):\n",
    "        return model(x, training=False)\n",
    "\n",
    "    concrete_func = forward.get_concrete_function(\n",
    "        tf.TensorSpec([1] + list(input_shape), tf.float32)\n",
    "    )\n",
    "\n",
    "    frozen_func = convert_variables_to_constants_v2(concrete_func)\n",
    "    graph_def = frozen_func.graph.as_graph_def()\n",
    "\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def, name=\"\")\n",
    "        opts = tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "        flops = tf.compat.v1.profiler.profile(\n",
    "            graph=graph, cmd=\"op\", options=opts\n",
    "        )\n",
    "\n",
    "    gflops = flops.total_float_ops / 1e9\n",
    "\n",
    "    print(\"\\n=== INFERENCE FLOPs ===\")\n",
    "    print(f\"GFLOPs per inference : {gflops:.4f}\")\n",
    "\n",
    "    return gflops\n",
    "\n",
    "# ==========================================================\n",
    "# TRAINING FLOPs (ResNet)\n",
    "# ==========================================================\n",
    "def estimate_training_gflops(forward_gflops, num_samples, epochs):\n",
    "    return forward_gflops * num_samples * epochs * 3.0\n",
    "\n",
    "# ==========================================================\n",
    "# MEMORY (CRASH) CHECK — USER BATCH SIZE\n",
    "# ==========================================================\n",
    "def crash_check(model, available_mem_mb, batch_size, optimizer=\"adam\"):\n",
    "    param_mb = model.count_params() * 4 / (1024 ** 2)\n",
    "\n",
    "    # ResNet activation cost\n",
    "    activation_mb = param_mb * 8 * batch_size\n",
    "\n",
    "    optimizer_multiplier = {\n",
    "        \"sgd\": 1.0,\n",
    "        \"adam\": 2.0,\n",
    "        \"adamw\": 2.0\n",
    "    }[optimizer]\n",
    "\n",
    "    optimizer_mb = param_mb * optimizer_multiplier\n",
    "\n",
    "    total = param_mb + activation_mb + optimizer_mb + 800\n",
    "\n",
    "    print(\"\\n=== MEMORY CHECK ===\")\n",
    "    print(f\"Batch size         : {batch_size}\")\n",
    "    print(f\"Parameters        : {param_mb:.2f} MB\")\n",
    "    print(f\"Activations       : {activation_mb:.2f} MB\")\n",
    "    print(f\"Optimizer state   : {optimizer_mb:.2f} MB\")\n",
    "    print(f\"Estimated TOTAL   : {total:.2f} MB\")\n",
    "    print(f\"Available memory : {available_mem_mb} MB\")\n",
    "\n",
    "    if total > available_mem_mb:\n",
    "        print(\"❌ RESULT: MODEL WILL CRASH (OOM)\")\n",
    "        return False\n",
    "    else:\n",
    "        print(\"✅ RESULT: MODEL WILL NOT CRASH\")\n",
    "        return True\n",
    "\n",
    "# ==========================================================\n",
    "# SPEED (INFERENCE)\n",
    "# ==========================================================\n",
    "def speed_check(model_gflops, hardware_gflops_s):\n",
    "    time_sec = model_gflops / hardware_gflops_s\n",
    "    fps = 1 / time_sec\n",
    "\n",
    "    print(\"\\n=== INFERENCE SPEED ===\")\n",
    "    print(f\"Time per inference : {time_sec:.8f} sec\")\n",
    "    print(f\"Theoretical FPS    : {fps:.1f}\")\n",
    "\n",
    "# ==========================================================\n",
    "# MAIN\n",
    "# ==========================================================\n",
    "def run_feasibility_check():\n",
    "    print(\"\\nRESNET FEASIBILITY CHECK\\n\")\n",
    "\n",
    "    model_path = input(\"Enter ResNet model path (.keras/.h5): \")\n",
    "    dataset_path = input(\"Enter image dataset directory: \")\n",
    "    epochs = int(input(\"Enter training epochs: \"))\n",
    "    batch_size = int(input(\"Enter batch size (you plan to use): \"))\n",
    "\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    model.summary()\n",
    "\n",
    "    num_samples = validate_image_dataset(dataset_path)\n",
    "\n",
    "    input_shape = model.input_shape[1:]\n",
    "    print(f\"✅ Input shape: {input_shape}\")\n",
    "\n",
    "    # FLOPs\n",
    "    forward_gflops = compute_model_gflops(model, input_shape)\n",
    "\n",
    "    # Hardware\n",
    "    device_idx = select_option(\"Select device type:\", [\"GPU\", \"CPU\"])\n",
    "\n",
    "    if device_idx == 0:\n",
    "        gpu_idx = select_option(\"Select GPU:\", [g[0] for g in GPU_DATABASE])\n",
    "        _, mem_mb, gflops_s = GPU_DATABASE[gpu_idx]\n",
    "    else:\n",
    "        cpu_idx = select_option(\n",
    "            \"Select CPU RAM:\",\n",
    "            [f\"{c[0]} GB RAM\" for c in CPU_DATABASE]\n",
    "        )\n",
    "        _, mem_mb, gflops_s = CPU_DATABASE[cpu_idx]\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = detect_optimizer(model)\n",
    "    if optimizer:\n",
    "        print(f\"✅ Detected optimizer: {optimizer}\")\n",
    "    else:\n",
    "        opt_idx = select_option(\"Select optimizer:\", [\"SGD\", \"Adam\", \"AdamW\"])\n",
    "        optimizer = [\"sgd\", \"adam\", \"adamw\"][opt_idx]\n",
    "\n",
    "    # Crash check\n",
    "    crash_check(model, mem_mb, batch_size, optimizer)\n",
    "\n",
    "    # Speed\n",
    "    speed_check(forward_gflops, gflops_s)\n",
    "\n",
    "    # Training cost\n",
    "    total_train_gflops = estimate_training_gflops(\n",
    "        forward_gflops, num_samples, epochs\n",
    "    )\n",
    "    train_time_sec = total_train_gflops / gflops_s\n",
    "\n",
    "    print(\"\\n=== TRAINING COST ===\")\n",
    "    print(f\"Total training FLOPs : {total_train_gflops:.2f} GFLOPs\")\n",
    "    print(f\"Training time       : {train_time_sec/60:.2f} minutes\")\n",
    "\n",
    "# ==========================================================\n",
    "# RUN\n",
    "# ==========================================================\n",
    "if __name__ == \"__main__\":\n",
    "    run_feasibility_check()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
