{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "396f64cb",
   "metadata": {},
   "source": [
    "# **Forward Pass for FNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1dcdf7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from tensorflow.python.framework.convert_to_constants import (\n",
    "    convert_variables_to_constants_v2_as_graph\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# USER INPUTS (ONLY THESE)\n",
    "# ==========================================================\n",
    "\n",
    "MODEL_PATH = r\"D:\\college\\sem-8\\models\\FNN\\asthma_fnn_binary.h5\"\n",
    "DATASET_PATH = r\"D:\\college\\sem-8\\dataset\\clean_asthma_dataset.csv\"\n",
    "DATASET_FRACTION = 0.02\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# ==========================================================\n",
    "# 1️⃣ LOAD MODEL (ANY KERAS MODEL)\n",
    "# ==========================================================\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_PATH, compile=False)\n",
    "print(\"✔ Model loaded\")\n",
    "\n",
    "# Infer model input shape (remove batch dim)\n",
    "model_input_shape = model.input_shape\n",
    "if isinstance(model_input_shape, list):\n",
    "    model_input_shape = model_input_shape[0]\n",
    "\n",
    "feature_shape = tuple(model_input_shape[1:])\n",
    "print(\"✔ Model input shape:\", feature_shape)\n",
    "\n",
    "# ==========================================================\n",
    "# 2️⃣ LOAD DATASET (MODEL-AWARE)\n",
    "# ==========================================================\n",
    "\n",
    "def load_dataset(path, feature_shape):\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "\n",
    "    # ---------- CSV / TABULAR ----------\n",
    "    if ext == \".csv\":\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        num_features = int(np.prod(feature_shape))\n",
    "        X = df.iloc[:, :num_features].values.astype(np.float32)\n",
    "\n",
    "        # Dummy labels (not used for FLOPs)\n",
    "        y = np.zeros(len(X), dtype=np.int32)\n",
    "\n",
    "        return tf.data.Dataset.from_tensor_slices((X, y))\n",
    "\n",
    "    # ---------- NUMPY ----------\n",
    "    if ext == \".npz\":\n",
    "        data = np.load(path)\n",
    "        return tf.data.Dataset.from_tensor_slices(\n",
    "            (data[\"x\"], data[\"y\"])\n",
    "        )\n",
    "\n",
    "    raise ValueError(\"Unsupported dataset format\")\n",
    "\n",
    "dataset = load_dataset(DATASET_PATH, feature_shape)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "print(\"✔ Dataset loaded\")\n",
    "\n",
    "# ==========================================================\n",
    "# 3️⃣ SAMPLE DATASET (1–2%)\n",
    "# ==========================================================\n",
    "\n",
    "def sample_dataset(ds, fraction):\n",
    "    total_batches = tf.data.experimental.cardinality(ds).numpy()\n",
    "    sample_batches = max(1, int(total_batches * fraction))\n",
    "    return ds.take(sample_batches), total_batches\n",
    "\n",
    "sampled_ds, total_batches = sample_dataset(dataset, DATASET_FRACTION)\n",
    "\n",
    "# ==========================================================\n",
    "# 4️⃣ COMPUTE FLOPs (ROBUST & SAFE)\n",
    "# ==========================================================\n",
    "\n",
    "def compute_flops_per_sample(model, feature_shape):\n",
    "    \"\"\"\n",
    "    Computes FLOPs for ONE forward pass of ONE sample\n",
    "    \"\"\"\n",
    "    input_spec = tf.TensorSpec(\n",
    "        shape=(1,) + feature_shape,\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "\n",
    "    concrete_fn = tf.function(model).get_concrete_function(input_spec)\n",
    "\n",
    "    frozen_func, _ = convert_variables_to_constants_v2_as_graph(\n",
    "        concrete_fn\n",
    "    )\n",
    "\n",
    "    flops = tf.compat.v1.profiler.profile(\n",
    "        graph=frozen_func.graph,\n",
    "        options=tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "    )\n",
    "\n",
    "    return flops.total_float_ops\n",
    "\n",
    "flops_per_sample = compute_flops_per_sample(model, feature_shape)\n",
    "print(\"✔ FLOPs per sample:\", flops_per_sample)\n",
    "\n",
    "# ==========================================================\n",
    "# 5️⃣ EXTRAPOLATE TO FULL DATASET\n",
    "# ==========================================================\n",
    "\n",
    "total_samples = total_batches * BATCH_SIZE\n",
    "total_flops = flops_per_sample * total_samples\n",
    "total_gflops = total_flops / 1e9\n",
    "\n",
    "# ==========================================================\n",
    "# 6️⃣ FINAL REPORT\n",
    "# ==========================================================\n",
    "\n",
    "print(\"\\n========== FLOPs ESTIMATION REPORT ==========\")\n",
    "print(f\"Total samples     : {total_samples}\")\n",
    "print(f\"FLOPs per sample  : {flops_per_sample:.3e}\")\n",
    "print(f\"Total FLOPs       : {total_flops:.3e}\")\n",
    "print(f\"Total GFLOPs      : {total_gflops:.3f}\")\n",
    "print(\"============================================\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8390a2d1",
   "metadata": {},
   "source": [
    "# **Forward Pass for CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ec3b8c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.python.framework.convert_to_constants import (\n",
    "    convert_variables_to_constants_v2_as_graph\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# USER INPUTS\n",
    "# ==========================================================\n",
    "\n",
    "MODEL_PATH = r\"D:\\college\\sem-8\\models\\CNN\\pothole_cnn_model.h5\"\n",
    "IMAGE_DIR  = r\"D:\\college\\sem-8\\dataset\\pothole\"   # class-wise folders\n",
    "DATASET_FRACTION = 0.02\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# ==========================================================\n",
    "# 1️⃣ LOAD CNN MODEL\n",
    "# ==========================================================\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_PATH, compile=False)\n",
    "print(\"✔ Model loaded\")\n",
    "\n",
    "# Infer input shape (H, W, C)\n",
    "model_input_shape = model.input_shape\n",
    "if isinstance(model_input_shape, list):\n",
    "    model_input_shape = model_input_shape[0]\n",
    "\n",
    "feature_shape = tuple(model_input_shape[1:])\n",
    "print(\"✔ Model input shape:\", feature_shape)\n",
    "\n",
    "IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = feature_shape\n",
    "\n",
    "# ==========================================================\n",
    "# 2️⃣ LOAD IMAGE DATASET (MODEL-AWARE)\n",
    "# ==========================================================\n",
    "\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    IMAGE_DIR,\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"✔ Dataset loaded\")\n",
    "\n",
    "# ==========================================================\n",
    "# 3️⃣ SAMPLE DATASET (1–2%)\n",
    "# ==========================================================\n",
    "\n",
    "def sample_dataset(ds, fraction):\n",
    "    total_batches = tf.data.experimental.cardinality(ds).numpy()\n",
    "    sample_batches = max(1, int(total_batches * fraction))\n",
    "    return ds.take(sample_batches), total_batches\n",
    "\n",
    "sampled_ds, total_batches = sample_dataset(dataset, DATASET_FRACTION)\n",
    "\n",
    "# ==========================================================\n",
    "# 4️⃣ COMPUTE FLOPs PER SAMPLE\n",
    "# ==========================================================\n",
    "\n",
    "def compute_flops_per_sample(model, feature_shape):\n",
    "    input_spec = tf.TensorSpec(\n",
    "        shape=(1,) + feature_shape,\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "\n",
    "    concrete_fn = tf.function(model).get_concrete_function(input_spec)\n",
    "\n",
    "    frozen_func, _ = convert_variables_to_constants_v2_as_graph(\n",
    "        concrete_fn\n",
    "    )\n",
    "\n",
    "    flops = tf.compat.v1.profiler.profile(\n",
    "        graph=frozen_func.graph,\n",
    "        options=tf.compat.v1.profiler.ProfileOptionBuilder.float_operation()\n",
    "    )\n",
    "\n",
    "    return flops.total_float_ops\n",
    "\n",
    "flops_per_sample = compute_flops_per_sample(model, feature_shape)\n",
    "print(\"✔ FLOPs per sample:\", flops_per_sample)\n",
    "\n",
    "# ==========================================================\n",
    "# 5️⃣ EXTRAPOLATE TO FULL DATASET\n",
    "# ==========================================================\n",
    "\n",
    "total_samples = total_batches * BATCH_SIZE\n",
    "total_flops = flops_per_sample * total_samples\n",
    "total_gflops = total_flops / 1e9\n",
    "\n",
    "# ==========================================================\n",
    "# 6️⃣ FINAL REPORT\n",
    "# ==========================================================\n",
    "\n",
    "print(\"\\n========== CNN FLOPs ESTIMATION REPORT ==========\")\n",
    "print(f\"Total samples     : {total_samples}\")\n",
    "print(f\"FLOPs per sample  : {flops_per_sample:.3e}\")\n",
    "print(f\"Total FLOPs       : {total_flops:.3e}\")\n",
    "print(f\"Total GFLOPs      : {total_gflops:.3f}\")\n",
    "print(\"===============================================\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
