{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2a4b50",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "FNN-only pruning pipeline (auto-detect model type).\n",
    "- Detects model type from final layer (binary / multiclass / regression).\n",
    "- Adapts CSV loader accordingly.\n",
    "- Keeps final layer intact (never pruned).\n",
    "- Reports FLOPs, GFLOPs, MFLOPS and inference time.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# -----------------------\n",
    "# Helper: detect model type\n",
    "# -----------------------\n",
    "def detect_model_type(model):\n",
    "    out = model.layers[-1]\n",
    "    units = getattr(out, \"units\", None)\n",
    "    act = getattr(out, \"activation\", None)\n",
    "    act_name = act.__name__ if act is not None else None\n",
    "\n",
    "    if units == 1 and act_name in (\"sigmoid\",):\n",
    "        return \"binary\"\n",
    "    if units == 1 and act_name in (\"linear\", \"relu\", \"tanh\"):\n",
    "        return \"regression\"\n",
    "    if units is not None and units > 1 and act_name == \"softmax\":\n",
    "        return \"multiclass\"\n",
    "    # fallback tries\n",
    "    if units == 1:\n",
    "        return \"binary\"\n",
    "    if units and units > 1:\n",
    "        return \"multiclass\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def get_loss_and_metrics_for_type(model_type):\n",
    "    if model_type == \"binary\":\n",
    "        return (\"binary_crossentropy\", [\"accuracy\"])\n",
    "    if model_type == \"multiclass\":\n",
    "        # use sparse labels to avoid forcing one-hot encoding\n",
    "        return (\"sparse_categorical_crossentropy\", [\"sparse_categorical_accuracy\"])\n",
    "    if model_type == \"regression\":\n",
    "        return (\"mse\", [\"mse\"])\n",
    "    raise ValueError(\"Unknown model type\")\n",
    "\n",
    "# =====================================================================\n",
    "# 1) UNIVERSAL CSV LOADER  (adapts target based on model_type)\n",
    "# =====================================================================\n",
    "def load_any_csv_dataset(csv_path, target=None, test_size=0.2, val_size=0.1, model_type=\"binary\"):\n",
    "    \"\"\"\n",
    "    Loads CSV (auto-detect delimiter). Adapts target processing to model_type:\n",
    "      - binary/regression: returns y as float32 shaped (n,1)\n",
    "      - multiclass: returns integer labels shaped (n,1) for sparse loss\n",
    "    \"\"\"\n",
    "    print(\"[INFO] Loading CSV with automatic delimiter detection...\")\n",
    "    df = pd.read_csv(csv_path, sep=None, engine=\"python\")\n",
    "    print(\"[INFO] Columns detected:\", list(df.columns))\n",
    "\n",
    "    if target is None:\n",
    "        target = df.columns[-1]\n",
    "        print(f\"[INFO] Auto-detected target column = {target}\")\n",
    "\n",
    "    if target not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target}' not found in dataset!\")\n",
    "\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    # Preprocess target based on model_type\n",
    "    if model_type == \"binary\":\n",
    "        # convert yes/no/true/false -> 1/0\n",
    "        if y.dtype == object:\n",
    "            y = y.astype(str).str.strip().str.lower()\n",
    "            y = y.replace({\"yes\": 1, \"no\": 0, \"true\": 1, \"false\": 0})\n",
    "        # ensure numeric\n",
    "        y = y.astype(np.float32).values.reshape(-1, 1)\n",
    "\n",
    "    elif model_type == \"multiclass\":\n",
    "        # convert strings to categorical integer codes if needed\n",
    "        if y.dtype == object:\n",
    "            y = y.astype(\"category\").cat.codes\n",
    "        # ensure integer labels (sparse labels)\n",
    "        y = y.astype(np.int32).values.reshape(-1, 1)\n",
    "\n",
    "    elif model_type == \"regression\":\n",
    "        # numeric continuous\n",
    "        y = y.astype(np.float32).values.reshape(-1, 1)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model_type for loader\")\n",
    "\n",
    "    # One-hot encode only categorical predictors (keep numeric as-is)\n",
    "    cat_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "    if len(cat_cols) > 0:\n",
    "        print(\"[INFO] One-hot encoding predictors:\", list(cat_cols))\n",
    "        X = pd.get_dummies(X, drop_first=True)\n",
    "    else:\n",
    "        print(\"[INFO] No categorical predictor columns to encode.\")\n",
    "\n",
    "    # convert to float32 (features)\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    # Split\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=(test_size + val_size), random_state=42, stratify=y if model_type!=\"regression\" else None\n",
    "    )\n",
    "    # second split into val/test\n",
    "    val_ratio = val_size / (test_size + val_size)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=(1 - val_ratio), random_state=42,\n",
    "        stratify=y_temp if model_type!=\"regression\" else None\n",
    "    )\n",
    "\n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "\n",
    "# =====================================================================\n",
    "# 2) GET DENSE LAYERS\n",
    "# =====================================================================\n",
    "def get_dense_layers(model):\n",
    "    return [layer for layer in model.layers if isinstance(layer, Dense)]\n",
    "\n",
    "# =====================================================================\n",
    "# 3) ACTIVATION + GRADIENT STATS  (SHAPE-SAFE)\n",
    "# =====================================================================\n",
    "def compute_activation_grad_stats(model, dense_layers, X, y, model_type,\n",
    "                                  batch_size=64, max_batches=30):\n",
    "    \"\"\"\n",
    "    Returns stats dict: {layer.name: (A_mean_per_neuron, G_mean_per_neuron, Var_per_neuron)}\n",
    "    Uses appropriate loss for model_type when computing gradients.\n",
    "    \"\"\"\n",
    "    # Convert X,y to numpy if DataFrame\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X_np = X.to_numpy()\n",
    "    else:\n",
    "        X_np = X\n",
    "    if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):\n",
    "        y_np = y.to_numpy()\n",
    "    else:\n",
    "        y_np = y\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X_np, y_np)).batch(batch_size)\n",
    "    acc_A = {l.name: [] for l in dense_layers}\n",
    "    acc_G = {l.name: [] for l in dense_layers}\n",
    "    acc_V = {l.name: [] for l in dense_layers}\n",
    "\n",
    "    # choose loss for gradient computation\n",
    "    if model_type == \"binary\":\n",
    "        loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False, reduction=tf.keras.losses.Reduction.NONE)\n",
    "    elif model_type == \"multiclass\":\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction=tf.keras.losses.Reduction.NONE)\n",
    "    elif model_type == \"regression\":\n",
    "        loss_fn = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model_type for stats\")\n",
    "\n",
    "    batch_count = 0\n",
    "    for xb, yb in ds:\n",
    "        if batch_count >= max_batches:\n",
    "            break\n",
    "        batch_count += 1\n",
    "\n",
    "        # ensure shapes consistent\n",
    "        x = tf.cast(xb, tf.float32)\n",
    "        # For sparse multiclass loss, yb should be shape (batch,) ints\n",
    "        if model_type == \"multiclass\":\n",
    "            yb_proc = tf.cast(tf.squeeze(yb, axis=-1), tf.int32)\n",
    "        else:\n",
    "            # binary/regression: keep shape (batch,1) as float32\n",
    "            yb_proc = tf.cast(yb, tf.float32)\n",
    "\n",
    "        layer_outputs = {}\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            for layer in model.layers:\n",
    "                x = layer(x)\n",
    "                if layer in dense_layers:\n",
    "                    tape.watch(x)\n",
    "                    layer_outputs[layer.name] = x\n",
    "            preds = x\n",
    "            # compute per-sample loss (shape [batch,] or [batch, ...])\n",
    "            per_sample_loss = loss_fn(yb_proc, preds)\n",
    "            # compute scalar loss for gradient direction\n",
    "            loss = tf.reduce_mean(per_sample_loss)\n",
    "\n",
    "        for layer in dense_layers:\n",
    "            name = layer.name\n",
    "            if name not in layer_outputs:\n",
    "                continue\n",
    "            a = layer_outputs[name]            # shape (batch, units)\n",
    "            A = tf.reduce_mean(tf.abs(a), axis=0).numpy()\n",
    "            V = tf.math.reduce_variance(a, axis=0).numpy()\n",
    "\n",
    "            g = tape.gradient(loss, a)\n",
    "            if g is None:\n",
    "                G = np.zeros_like(A)\n",
    "            else:\n",
    "                G = tf.reduce_mean(tf.abs(g), axis=0).numpy()\n",
    "\n",
    "            acc_A[name].append(A)\n",
    "            acc_G[name].append(G)\n",
    "            acc_V[name].append(V)\n",
    "\n",
    "        del tape\n",
    "\n",
    "    # Aggregate\n",
    "    stats = {}\n",
    "    for layer in dense_layers:\n",
    "        name = layer.name\n",
    "        if len(acc_A[name]) == 0:\n",
    "            stats[name] = (np.array([]), np.array([]), np.array([]))\n",
    "            continue\n",
    "        A = np.mean(np.stack(acc_A[name], axis=0), axis=0)\n",
    "        G = np.mean(np.stack(acc_G[name], axis=0), axis=0)\n",
    "        V = np.mean(np.stack(acc_V[name], axis=0), axis=0)\n",
    "        stats[name] = (A, G, V)\n",
    "\n",
    "    return stats\n",
    "\n",
    "# =====================================================================\n",
    "# 4) IMPORTANCE MASKS (protect last Dense layer)\n",
    "# =====================================================================\n",
    "def compute_importance_mask(\n",
    "        stats,\n",
    "        keep_ratio=0.7,\n",
    "        alpha=0.5,\n",
    "        beta=0.3,\n",
    "        gamma=0.2,\n",
    "        last_dense_name=None,\n",
    "        min_units=4  # <-- increase minimum neurons per layer\n",
    "    ):\n",
    "    \n",
    "    masks = {}\n",
    "    for name, (A, G, V) in stats.items():\n",
    "        if A.size == 0:\n",
    "            masks[name] = np.array([], dtype=np.float32)\n",
    "            continue\n",
    "\n",
    "        def normalize(x):\n",
    "            x2 = x - np.min(x)\n",
    "            mx = np.max(x2)\n",
    "            return x2 / (mx + 1e-12)\n",
    "\n",
    "        # compute score\n",
    "        score = alpha * normalize(A) + beta * normalize(G) + gamma * normalize(V)\n",
    "\n",
    "        # ---- NEVER prune final Dense layer ----\n",
    "        if last_dense_name is not None and name == last_dense_name:\n",
    "            masks[name] = np.ones_like(score, dtype=np.float32)\n",
    "            continue\n",
    "\n",
    "        # ---- compute K ----\n",
    "        k = int(len(score) * keep_ratio)\n",
    "        k = max(k, min_units)        # enforce minimum\n",
    "        k = min(k, len(score))       # safety\n",
    "\n",
    "        # ---- If all scores are zero â†’ randomly pick k neurons ----\n",
    "        if np.all(score == 0):\n",
    "            sel = np.random.choice(len(score), size=k, replace=False)\n",
    "            mask = np.zeros_like(score)\n",
    "            mask[sel] = 1\n",
    "            masks[name] = mask.astype(np.float32)\n",
    "            continue\n",
    "\n",
    "        # normal path\n",
    "        thresh = np.partition(score, -k)[-k]\n",
    "        mask = (score >= thresh).astype(np.float32)\n",
    "\n",
    "        # final safety: ensure >= min_units survive\n",
    "        if np.sum(mask) < min_units:\n",
    "            topk = np.argsort(score)[-min_units:]\n",
    "            mask = np.zeros_like(score)\n",
    "            mask[topk] = 1\n",
    "\n",
    "        masks[name] = mask.astype(np.float32)\n",
    "\n",
    "    return masks\n",
    "\n",
    "# =====================================================================\n",
    "# 5) DNAGate Layer (Zeroing)\n",
    "# =====================================================================\n",
    "# =====================================================================\n",
    "# 5) DNAGate Layer (Zeroing) â€” NOW FULLY SERIALIZABLE\n",
    "# =====================================================================\n",
    "class DNAGate(tf.keras.layers.Layer):\n",
    "    def __init__(self, mask=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # store original numpy mask (for config saving)\n",
    "        self._mask_np = None\n",
    "        if mask is not None:\n",
    "            self._mask_np = np.array(mask, dtype=np.float32)\n",
    "\n",
    "        # keras-serializable field (converted to list)\n",
    "        self.mask_list = self._mask_np.tolist() if self._mask_np is not None else None\n",
    "        self.mask = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.mask_list is None:\n",
    "            self.mask = None\n",
    "        else:\n",
    "            # rebuild tensor mask\n",
    "            mask_np = np.array(self.mask_list, dtype=np.float32)\n",
    "            if input_shape[-1] != mask_np.shape[0]:\n",
    "                raise ValueError(\n",
    "                    f\"DNAGate mask length {mask_np.shape[0]} != layer units {input_shape[-1]}\"\n",
    "                )\n",
    "            self.mask = tf.constant(mask_np, dtype=self.dtype)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        if self.mask is None:\n",
    "            return x\n",
    "        return x * self.mask\n",
    "\n",
    "    # â­â­ IMPORTANT â€” MAKES THE LAYER SAVEABLE â­â­\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"mask\": self.mask_list,   # store mask as list\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # mask list gets restored automatically\n",
    "        return cls(**config)\n",
    "\n",
    "def build_masked_model(orig_model, masks):\n",
    "    inp = Input(shape=orig_model.input_shape[1:])\n",
    "    x = inp\n",
    "    for layer in orig_model.layers:\n",
    "        x = layer(x)\n",
    "        if layer.name in masks:\n",
    "            x = DNAGate(mask=masks[layer.name], name=layer.name + \"_dna\")(x)\n",
    "    new_model = Model(inp, x)\n",
    "    # copy weights where possible\n",
    "    for l in orig_model.layers:\n",
    "        try:\n",
    "            new_model.get_layer(l.name).set_weights(l.get_weights())\n",
    "        except Exception:\n",
    "            pass\n",
    "    return new_model\n",
    "\n",
    "# =====================================================================\n",
    "# 6) FLOPS + INFERENCE TIME\n",
    "# =====================================================================\n",
    "def dense_flops(in_size, out_size, bias=True):\n",
    "    # multiply-adds counted as 2 ops per MAC\n",
    "    return int(in_size * out_size * 2 + (out_size if bias else 0))\n",
    "\n",
    "def model_flops(model):\n",
    "    total = 0\n",
    "    in_size = int(model.input_shape[1])\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, Dense):\n",
    "            total += dense_flops(in_size, layer.units, layer.use_bias)\n",
    "            in_size = layer.units\n",
    "    return total\n",
    "\n",
    "def effective_flops(model, masks):\n",
    "    total = 0\n",
    "    in_size = int(model.input_shape[1])\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, Dense):\n",
    "            if layer.name in masks and masks[layer.name].size > 0:\n",
    "                units = int(np.sum(masks[layer.name]))\n",
    "            else:\n",
    "                units = layer.units\n",
    "            total += dense_flops(in_size, units, layer.use_bias)\n",
    "            in_size = units\n",
    "    return total\n",
    "\n",
    "def flops_to_gflops(f):\n",
    "    return f / 1e9\n",
    "\n",
    "def flops_to_mflops(f):\n",
    "    return f / 1e6\n",
    "\n",
    "def measure_inference_time(model, X, runs=200):\n",
    "    \"\"\"Return average inference time in milliseconds per sample.\n",
    "       Accepts X as pandas DataFrame or numpy array.\"\"\"\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X_np = X.to_numpy()\n",
    "    else:\n",
    "        X_np = X\n",
    "    if len(X_np) == 0:\n",
    "        return float(\"nan\")\n",
    "    # pick random indices\n",
    "    idx = np.random.randint(0, len(X_np), size=min(runs, len(X_np)))\n",
    "    samples = X_np[idx]\n",
    "    # warm-up single predict\n",
    "    model.predict(samples[:1], verbose=0)\n",
    "    t0 = time.time()\n",
    "    model.predict(samples, verbose=0)\n",
    "    t1 = time.time()\n",
    "    total_ms = (t1 - t0) * 1000.0\n",
    "    return total_ms / len(samples)\n",
    "\n",
    "# =====================================================================\n",
    "# 7) STRUCTURAL PRUNING (REMOVE NEURONS) â€” protect final Dense layer\n",
    "# =====================================================================\n",
    "def structurally_prune_fnn(orig_model, masks, last_dense_name=None):\n",
    "    inp = Input(shape=orig_model.input_shape[1:])\n",
    "    x = inp\n",
    "    prev_sel = None\n",
    "\n",
    "    for layer in orig_model.layers:\n",
    "        if isinstance(layer, Dense):\n",
    "            W, b = layer.get_weights()\n",
    "\n",
    "            # If previous layer was pruned â†’ prune rows\n",
    "            if prev_sel is not None:\n",
    "                W = W[prev_sel, :]\n",
    "\n",
    "            # ---- SAFETY: determine neurons to keep ----\n",
    "            if last_dense_name is not None and layer.name == last_dense_name:\n",
    "                # never prune final layer\n",
    "                sel = np.arange(layer.units)\n",
    "\n",
    "            else:\n",
    "                mask = masks.get(layer.name, None)\n",
    "                if mask is not None and mask.size > 0:\n",
    "                    sel = np.where(mask == 1)[0]\n",
    "\n",
    "                    # ðŸ’¥ SAFETY FIX: ensure >=1 neuron survives\n",
    "                    if len(sel) == 0:\n",
    "                        sel = np.array([np.argmax(mask)])  \n",
    "                else:\n",
    "                    sel = None\n",
    "\n",
    "            # ---- Apply pruning ----\n",
    "            if sel is not None:\n",
    "                W_new = W[:, sel]\n",
    "                b_new = b[sel]\n",
    "                new_units = len(sel)\n",
    "            else:\n",
    "                W_new = W\n",
    "                b_new = b\n",
    "                new_units = W.shape[1]\n",
    "\n",
    "            new_layer = Dense(new_units, activation=layer.activation, name=layer.name)\n",
    "            x = new_layer(x)\n",
    "            new_layer.set_weights([W_new, b_new])\n",
    "\n",
    "            prev_sel = sel\n",
    "\n",
    "        else:\n",
    "            x = layer(x)\n",
    "\n",
    "    return Model(inp, x)\n",
    "\n",
    "# =====================================================================\n",
    "# 8) MAIN PIPELINE (auto-detect model type)\n",
    "# =====================================================================\n",
    "def fnn_pruning_pipeline(model_path, dataset_path,\n",
    "                         keep_ratio=0.7,\n",
    "                         alpha=0.5, beta=0.3, gamma=0.2,\n",
    "                         calib_batches=30, batch_size=64, ft_epochs=3):\n",
    "    # 1) load model and detect type\n",
    "    print(\"Loading model:\", model_path)\n",
    "    model = load_model(model_path)\n",
    "    model_type = detect_model_type(model)\n",
    "    print(f\"[INFO] Detected model type: {model_type}\")\n",
    "\n",
    "    loss_name, metrics = get_loss_and_metrics_for_type(model_type)\n",
    "    print(f\"[INFO] Using loss='{loss_name}', metrics={metrics}\")\n",
    "\n",
    "    # 2) load dataset adapted to model_type\n",
    "    print(\"Loading dataset:\", dataset_path)\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = load_any_csv_dataset(dataset_path, model_type=model_type)\n",
    "\n",
    "    # 3) find dense layers and the last Dense layer name\n",
    "    dense_layers = get_dense_layers(model)\n",
    "    last_dense_name = dense_layers[-1].name if len(dense_layers) > 0 else None\n",
    "    print(\"Dense layers:\", [l.name for l in dense_layers], \"| last_dense:\", last_dense_name)\n",
    "\n",
    "    # 4) compute stats (activation + gradient)\n",
    "    print(\"Computing activation & gradient stats...\")\n",
    "    stats = compute_activation_grad_stats(model, dense_layers, X_train, y_train, model_type,\n",
    "                                          batch_size=batch_size, max_batches=calib_batches)\n",
    "\n",
    "    # 5) compute masks (protect final layer)\n",
    "    masks = compute_importance_mask(stats, keep_ratio=keep_ratio, alpha=alpha, beta=beta, gamma=gamma, last_dense_name=last_dense_name)\n",
    "    for k,v in masks.items():\n",
    "        if v.size > 0:\n",
    "            print(f\"{k} -> kept units: {int(np.sum(v))}/{len(v)}\")\n",
    "\n",
    "    # 6) build masked model (DNAGate zeroing) and compile with correct loss/metrics\n",
    "    print(\"Building masked model (DNAGate zeroing)...\")\n",
    "    masked_model = build_masked_model(model, masks)\n",
    "    masked_model.compile(optimizer='adam', loss=loss_name, metrics=metrics)\n",
    "\n",
    "    # compute baseline & masked flops/accuracy\n",
    "    baseline_acc = None\n",
    "    masked_acc_before = None\n",
    "    if model_type == \"regression\":\n",
    "        baseline_eval = model.evaluate(X_val, y_val, verbose=0)\n",
    "        baseline_acc = baseline_eval[0] if len(baseline_eval)>0 else None\n",
    "        masked_acc_before = masked_model.evaluate(X_val, y_val, verbose=0)[0]\n",
    "    else:\n",
    "        baseline_acc = model.evaluate(X_val, y_val, verbose=0)[1]  # accuracy or sparse_accuracy\n",
    "        masked_acc_before = masked_model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "\n",
    "    baseline_flops = model_flops(model)\n",
    "    masked_flops = effective_flops(model, masks)\n",
    "\n",
    "    print(f\"Baseline Acc: {baseline_acc} | FLOPS: {baseline_flops}\")\n",
    "    print(f\"Masked Acc (before FT): {masked_acc_before} | Effective FLOPS: {masked_flops}\")\n",
    "\n",
    "    # 7) fine-tune masked model\n",
    "    print(\"Fine-tuning masked model...\")\n",
    "    masked_model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=ft_epochs, verbose=2)\n",
    "\n",
    "    # evaluate masked after FT\n",
    "    if model_type == \"regression\":\n",
    "        masked_eval = masked_model.evaluate(X_val, y_val, verbose=0)\n",
    "        masked_acc_after = masked_eval[0] if len(masked_eval)>0 else None\n",
    "    else:\n",
    "        masked_acc_after = masked_model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "\n",
    "    # 8) structural pruning (permanent neuron removal)\n",
    "    print(\"Constructing structurally-pruned model (remove neurons)...\")\n",
    "    pruned_model = structurally_prune_fnn(model, masks, last_dense_name=last_dense_name)\n",
    "    pruned_model.compile(optimizer='adam', loss=loss_name, metrics=metrics)\n",
    "\n",
    "    print(\"Fine-tuning pruned model...\")\n",
    "    pruned_model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=ft_epochs, verbose=2)\n",
    "\n",
    "    # final evals\n",
    "    if model_type == \"regression\":\n",
    "        pruned_eval = pruned_model.evaluate(X_val, y_val, verbose=0)\n",
    "        pruned_acc = pruned_eval[0] if len(pruned_eval)>0 else None\n",
    "    else:\n",
    "        pruned_acc = pruned_model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "\n",
    "    pruned_flops = model_flops(pruned_model)\n",
    "\n",
    "    # compute GFLOPS / MFLOPS / inference times\n",
    "    baseline_gflops = flops_to_gflops(baseline_flops)\n",
    "    masked_gflops = flops_to_gflops(masked_flops)\n",
    "    pruned_gflops = flops_to_gflops(pruned_flops)\n",
    "\n",
    "    baseline_mflops = flops_to_mflops(baseline_flops)\n",
    "    masked_mflops = flops_to_mflops(masked_flops)\n",
    "    pruned_mflops = flops_to_mflops(pruned_flops)\n",
    "\n",
    "    baseline_time_ms = measure_inference_time(model, X_val)\n",
    "    masked_time_ms = measure_inference_time(masked_model, X_val)\n",
    "    pruned_time_ms = measure_inference_time(pruned_model, X_val)\n",
    "\n",
    "    print(\"\\n=== FINAL REPORT ===\")\n",
    "    print(f\"Model type: {model_type}\")\n",
    "    print(f\"Baseline:   Acc/metric={baseline_acc} | FLOPS={baseline_flops} | MFLOPS={baseline_mflops:.6f} | GFLOPS={baseline_gflops:.10f} | Time={baseline_time_ms:.4f} ms/sample\")\n",
    "    print(f\"Masked:     Acc/metric={masked_acc_after} | EFLOPS={masked_flops} | MFLOPS={masked_mflops:.6f} | GFLOPS={masked_gflops:.10f} | Time={masked_time_ms:.4f} ms/sample\")\n",
    "    print(f\"Pruned:     Acc/metric={pruned_acc} | FLOPS={pruned_flops} | MFLOPS={pruned_mflops:.6f} | GFLOPS={pruned_gflops:.10f} | Time={pruned_time_ms:.4f} ms/sample\")\n",
    "    if baseline_flops > 0:\n",
    "        print(f\"FLOPS reduction (pruned): {(baseline_flops - pruned_flops)/baseline_flops:.2%}\")\n",
    "    print(\"==============================================\\n\")\n",
    "\n",
    "    print(f\"Pruned:     Acc/metric={pruned_acc} | FLOPS={pruned_flops} | MFLOPS={pruned_mflops:.6f} | GFLOPS={pruned_gflops:.10f} | Time={pruned_time_ms:.4f} ms/sample\")\n",
    "\n",
    "    # ---- NEW METRIC REDUCTIONS ADDED BELOW ----\n",
    "    if baseline_flops > 0:\n",
    "        flop_reduction = (baseline_flops - pruned_flops) / baseline_flops\n",
    "        gflop_reduction = (baseline_gflops - pruned_gflops) / baseline_gflops if baseline_gflops > 0 else 0\n",
    "    else:\n",
    "        flop_reduction = 0\n",
    "        gflop_reduction = 0\n",
    "\n",
    "    acc_reduction = baseline_acc - pruned_acc if baseline_acc is not None else None\n",
    "\n",
    "    print(f\"FLOPS reduction (pruned): {flop_reduction:.2%}\")\n",
    "    print(f\"GFLOPS reduction (pruned): {gflop_reduction:.2%}\")\n",
    "    print(f\"Accuracy reduction: {acc_reduction}\")\n",
    "    # ---- END NEW LINES ----\n",
    "\n",
    "    print(\"==============================================\\n\")\n",
    "\n",
    "    # save masked/pruned models next to original\n",
    "    base = os.path.basename(model_path)\n",
    "    root = os.path.splitext(base)[0]\n",
    "    folder = os.path.dirname(model_path) or \".\"\n",
    "\n",
    "    masked_path = os.path.join(folder, root + \"_masked.h5\")\n",
    "    pruned_path = os.path.join(folder, root + \"_pruned.h5\")\n",
    "\n",
    "    try:\n",
    "        print(f\"[INFO] Saving masked model to: {masked_path}\")\n",
    "        masked_model.save(masked_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed to save masked model: {e}\")\n",
    "\n",
    "    try:\n",
    "        print(f\"[INFO] Saving pruned model to: {pruned_path}\")\n",
    "        pruned_model.save(pruned_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed to save pruned model: {e}\")\n",
    "\n",
    "    # return X_val for further external checks if desired\n",
    "    return model, masked_model, pruned_model, masks, X_val\n",
    "\n",
    "# =====================================================================\n",
    "# 9) RUN (example)\n",
    "# =====================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # change these to your files\n",
    "    model_path = r\"D:\\college\\sem-8\\models\\dementia_fnn_model.h5\"\n",
    "    dataset_path = r\"D:\\college\\sem-8\\dataset\\clean_dementia_dataset.csv\"\n",
    "\n",
    "    original_model, masked_model, pruned_model, masks, X_val = fnn_pruning_pipeline(\n",
    "        model_path=model_path,\n",
    "        dataset_path=dataset_path,\n",
    "        keep_ratio=0.8,\n",
    "        alpha=0.5, beta=0.3, gamma=0.2,\n",
    "        calib_batches=30, batch_size=64, ft_epochs=15\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
