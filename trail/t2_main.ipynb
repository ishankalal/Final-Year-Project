{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d8d3e01",
   "metadata": {},
   "source": [
    "# **Universal Data Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81cad352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# UNIVERSAL DATA PREPARER  (Auto CSV / Image)\n",
    "# ============================================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "def prepare(path: str,\n",
    "            target_col: str = \"y\",\n",
    "            img_size=(224,224),\n",
    "            flatten_images_for_ml: bool=True,\n",
    "            handle_missing_strategy=\"mean\",\n",
    "            encode_categorical=True,\n",
    "            normalize_numeric=True,\n",
    "            test_size=0.2,\n",
    "            val_size=0.1,\n",
    "            random_state=42):\n",
    "    \"\"\"\n",
    "    Universal data loader.\n",
    "    But for tabular CSVs like bank-full.csv, it matches EXACTLY the preprocessing\n",
    "    used during FNN model training:\n",
    "        - y cleaned (yes/no → 1/0)\n",
    "        - one-hot encoding with drop_first=True\n",
    "        - StandardScaler on numeric columns\n",
    "    \"\"\"\n",
    "\n",
    "    dtype = detect_dataset_type(path)\n",
    "    result = {\"dataset_type\": dtype}\n",
    "\n",
    "    # ============================\n",
    "    # ---- TABULAR DATA ----------\n",
    "    # ============================\n",
    "    if dtype in {\"csv\", \"excel\", \"json\"}:\n",
    "\n",
    "        df = load_tabular(path)\n",
    "\n",
    "        # --- CLEAN TARGET COLUMN LIKE TRAINING ---\n",
    "        if target_col not in df.columns:\n",
    "            raise ValueError(f\"Target column '{target_col}' not found. Available: {df.columns}\")\n",
    "\n",
    "        df[target_col] = df[target_col].astype(str).str.strip().str.lower()\n",
    "        df[target_col] = df[target_col].replace({\n",
    "            \"yes\": 1,\n",
    "            \"no\": 0,\n",
    "            \"unknown\": 0,\n",
    "            \"nan\": 0,\n",
    "        }).astype(int)\n",
    "\n",
    "        # Ensure no NaN in target\n",
    "        df[target_col].fillna(0, inplace=True)\n",
    "\n",
    "        # --- SEPARATE FEATURES / TARGET ---\n",
    "        y = df[target_col].values\n",
    "        X_raw = df.drop(columns=[target_col])\n",
    "\n",
    "        # --- ONE-HOT ENCODING (DROP FIRST) ---\n",
    "        X_encoded = pd.get_dummies(X_raw, drop_first=True)\n",
    "\n",
    "        # Store feature names (important for pruning input shape!)\n",
    "        result[\"feature_names\"] = list(X_encoded.columns)\n",
    "\n",
    "        # --- TRAIN-VAL-TEST SPLIT ---\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "            X_encoded, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "        )\n",
    "        val_ratio = val_size / (1 - test_size)\n",
    "\n",
    "        X_val, X_test, y_val, y_test = train_test_split(\n",
    "            X_temp, y_temp, test_size=val_ratio, random_state=random_state, stratify=y_temp\n",
    "        )\n",
    "\n",
    "        # --- STANDARD SCALING (NUMERIC ONLY) ---\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        result.update({\n",
    "            \"X_train\": X_train,\n",
    "            \"X_val\": X_val,\n",
    "            \"X_test\": X_test,\n",
    "            \"y_train\": y_train,\n",
    "            \"y_val\": y_val,\n",
    "            \"y_test\": y_test,\n",
    "            \"scaler\": scaler,\n",
    "        })\n",
    "\n",
    "        return result\n",
    "\n",
    "    # =========================================================\n",
    "    # ---- IMAGES (untouched; same as your original loader) ---\n",
    "    # =========================================================\n",
    "    elif dtype in {\"image_folder\", \"image_file\"}:\n",
    "\n",
    "        if dtype == \"image_file\":\n",
    "            img = load_image_file(path, img_size=img_size)\n",
    "            X = np.array([img])\n",
    "            y = np.array([0])\n",
    "            classes = [Path(path).stem]\n",
    "        else:\n",
    "            imgs = load_images_from_folder(path, img_size=img_size)\n",
    "            if not imgs:\n",
    "                raise RuntimeError(\"No images found or no image library available.\")\n",
    "            X = imgs[\"images\"]\n",
    "            y = imgs[\"labels\"]\n",
    "            classes = imgs[\"classes\"]\n",
    "\n",
    "        if flatten_images_for_ml:\n",
    "            X = X.reshape((len(X), -1))\n",
    "\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test = split_data(\n",
    "            X, y, test_size=test_size, val_size=val_size, random_state=random_state\n",
    "        )\n",
    "\n",
    "        result.update({\n",
    "            \"X_train\": X_train, \"X_val\": X_val, \"X_test\": X_test,\n",
    "            \"y_train\": y_train, \"y_val\": y_val, \"y_test\": y_test,\n",
    "            \"classes\": classes\n",
    "        })\n",
    "        return result\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported dataset type: {dtype}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0a23e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# AUTO DETECT DATASET TYPE (CSV → TABULAR, FOLDER → IMAGES)\n",
    "# -------------------------------------------------------\n",
    "import os\n",
    "\n",
    "def detect_dataset_type(path):\n",
    "    \"\"\"\n",
    "    Detect whether dataset is TABULAR (CSV) or IMAGE folder.\n",
    "    \"\"\"\n",
    "    if os.path.isfile(path):\n",
    "        if path.endswith(\".csv\"):\n",
    "            return \"tabular\"\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported file format: {path}\")\n",
    "\n",
    "    if os.path.isdir(path):\n",
    "        # folder → assume images\n",
    "        exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
    "        for root, dirs, files in os.walk(path):\n",
    "            for f in files:\n",
    "                if os.path.splitext(f)[1].lower() in exts:\n",
    "                    return \"image\"\n",
    "        raise ValueError(\"No image files found in folder.\")\n",
    "\n",
    "    raise ValueError(\"Dataset path is neither a file nor folder.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cb2952",
   "metadata": {},
   "source": [
    "# RUN for FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b5964a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,504</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m5,504\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,875</span> (62.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,875\u001b[0m (62.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,873</span> (62.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,873\u001b[0m (62.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ishan\\Documents\\sample_p1\\env\\Lib\\site-packages\\keras\\src\\models\\functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['input_layer']\n",
      "Received: inputs=Tensor(shape=(64, 42))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected BINARY classifier → using binary_crossentropy\n",
      "Epoch 1/3\n",
      "495/495 - 4s - 8ms/step - accuracy: 0.9117 - loss: 0.1953 - val_accuracy: 0.9144 - val_loss: 0.1944\n",
      "Epoch 2/3\n",
      "495/495 - 2s - 4ms/step - accuracy: 0.9189 - loss: 0.1777 - val_accuracy: 0.9179 - val_loss: 0.1906\n",
      "Epoch 3/3\n",
      "495/495 - 2s - 4ms/step - accuracy: 0.9211 - loss: 0.1736 - val_accuracy: 0.9184 - val_loss: 0.1897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE. Saved to: pruned_out\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# unified_pruning_pipeline.py  (UPDATED)\n",
    "# ============================================\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "from typing import Tuple, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Layer, Input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# DATASET LOADING (unchanged)\n",
    "# ====================================================\n",
    "def _is_image_folder(path: str) -> bool:\n",
    "    if not os.path.isdir(path):\n",
    "        return False\n",
    "    exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\"}\n",
    "    for root, _, files in os.walk(path):\n",
    "        for f in files:\n",
    "            if os.path.splitext(f)[1].lower() in exts:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def _detect_csv_delimiter(path: str) -> str:\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        sample = f.read(4096)\n",
    "    candidates = [\",\", \";\", \"\\t\", \"|\"]\n",
    "    counts = {c: sample.count(c) for c in candidates}\n",
    "    return max(counts, key=counts.get)\n",
    "\n",
    "def load_tabular_csv(path: str, target_col: Optional[str]=None, test_size=0.2, val_size=0.1, random_state=42):\n",
    "    sep = _detect_csv_delimiter(path)\n",
    "    df = pd.read_csv(path, sep=sep, engine=\"python\")\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "    if target_col is None:\n",
    "        for cand in [\"y\", \"target\", \"label\", \"class\"]:\n",
    "            if cand in df.columns:\n",
    "                target_col = cand\n",
    "                break\n",
    "    if target_col is None:\n",
    "        raise ValueError(\"target_col not provided and could not be inferred.\")\n",
    "\n",
    "    y_series = df[target_col].astype(str).str.strip().str.lower()\n",
    "\n",
    "    if set(y_series.unique()) <= {\"yes\",\"no\",\"y\",\"n\",\"true\",\"false\",\"1\",\"0\"}:\n",
    "        y_series = y_series.replace({\"yes\":\"1\",\"no\":\"0\",\"y\":\"1\",\"n\":\"0\",\"true\":\"1\",\"false\":\"0\"})\n",
    "\n",
    "    try:\n",
    "        y = y_series.astype(int).values\n",
    "    except:\n",
    "        y = pd.factorize(y_series)[0]\n",
    "\n",
    "    X_df = df.drop(columns=[target_col])\n",
    "    cat_cols = X_df.select_dtypes(include=[\"object\",\"category\"]).columns.tolist()\n",
    "    if len(cat_cols) > 0:\n",
    "        X_df = pd.get_dummies(X_df, columns=cat_cols, drop_first=True)\n",
    "\n",
    "    X_df = X_df.apply(pd.to_numeric, errors=\"coerce\").fillna(0.0)\n",
    "    feature_names = list(X_df.columns)\n",
    "    X = X_df.values.astype(float)\n",
    "\n",
    "    strat = y if len(np.unique(y)) > 1 else None\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=(test_size+val_size), random_state=random_state, stratify=strat\n",
    "    )\n",
    "\n",
    "    val_ratio = val_size/(test_size+val_size)\n",
    "    strat_temp = y_temp if len(np.unique(y_temp))>1 else None\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=1-val_ratio, random_state=random_state, stratify=strat_temp\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    return {\n",
    "        \"X_train\": X_train, \"y_train\": y_train,\n",
    "        \"X_val\": X_val, \"y_val\": y_val,\n",
    "        \"feature_names\": feature_names,\n",
    "        \"scaler\": scaler,\n",
    "    }\n",
    "\n",
    "def load_image_folder(path: str, image_size=(224,224), batch_size=64, val_split=0.1):\n",
    "    ds_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        path, image_size=image_size, batch_size=batch_size,\n",
    "        label_mode=\"int\", validation_split=val_split,\n",
    "        subset=\"training\", seed=123\n",
    "    )\n",
    "    ds_val = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        path, image_size=image_size, batch_size=batch_size,\n",
    "        label_mode=\"int\", validation_split=val_split,\n",
    "        subset=\"validation\", seed=123\n",
    "    )\n",
    "    return ds_train, ds_val\n",
    "\n",
    "def auto_load_dataset(path, target_col, image_size, batch_size):\n",
    "    if os.path.isdir(path) and _is_image_folder(path):\n",
    "        t, v = load_image_folder(path, image_size=image_size, batch_size=batch_size)\n",
    "        return True, t, v, {\"input_shape\": (image_size[0], image_size[1], 3)}\n",
    "\n",
    "    if os.path.isfile(path) and path.endswith(\".csv\"):\n",
    "        tab = load_tabular_csv(path, target_col=target_col)\n",
    "        meta = {\n",
    "            \"feature_names\": tab[\"feature_names\"],\n",
    "            \"input_shape\": (len(tab[\"feature_names\"]),)\n",
    "        }\n",
    "        return False, (tab[\"X_train\"], tab[\"y_train\"]), (tab[\"X_val\"], tab[\"y_val\"]), meta\n",
    "\n",
    "    raise ValueError(\"Dataset must be CSV or image folder.\")\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# PRUNEABLE LAYERS\n",
    "# ====================================================\n",
    "def get_pruneable_layers(model):\n",
    "    out = []\n",
    "    for l in model.layers:\n",
    "        if isinstance(l, (tf.keras.layers.Dense, tf.keras.layers.Conv2D)):\n",
    "            out.append({\"name\": l.name, \"layer\": l})\n",
    "    return out\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# WEIGHT IMPORTANCE\n",
    "# ====================================================\n",
    "def per_unit_weight_importance(layer):\n",
    "    try:\n",
    "        kernel = layer.get_weights()[0]\n",
    "    except:\n",
    "        return None\n",
    "    w = np.array(kernel)\n",
    "    if w.ndim == 2:\n",
    "        return np.sum(np.abs(w), axis=0)\n",
    "    elif w.ndim == 4:\n",
    "        return np.sum(np.abs(w), axis=(0,1,2))\n",
    "    return np.sum(np.abs(w.reshape(-1, w.shape[-1])), axis=0)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# ACTIVATION IMPORTANCE\n",
    "# ====================================================\n",
    "def build_activation_model(model, pruneable):\n",
    "    return Model(inputs=model.inputs, outputs=[p[\"layer\"].output for p in pruneable])\n",
    "\n",
    "def collect_activation_magnitudes(model, pruneable, X, batch_size, max_batches):\n",
    "    act_model = build_activation_model(model, pruneable)\n",
    "    n = len(X)\n",
    "    acc = [None]*len(pruneable)\n",
    "    count = [0]*len(pruneable)\n",
    "    b = 0\n",
    "\n",
    "    for i in range(0, n, batch_size):\n",
    "        if b >= max_batches:\n",
    "            break\n",
    "        xb = tf.cast(X[i:i+batch_size], tf.float32)\n",
    "        acts = act_model(xb, training=False)\n",
    "        if not isinstance(acts, list):\n",
    "            acts = [acts]\n",
    "\n",
    "        for idx, a in enumerate(acts):\n",
    "            a = a.numpy()\n",
    "            if a.ndim == 4:\n",
    "                val = np.mean(np.abs(a), axis=(0,1,2))\n",
    "            elif a.ndim == 2:\n",
    "                val = np.mean(np.abs(a), axis=0)\n",
    "            else:\n",
    "                flat = a.reshape(a.shape[0], -1)\n",
    "                val = np.mean(np.abs(flat), axis=0)\n",
    "\n",
    "            acc[idx] = val if acc[idx] is None else acc[idx] + val\n",
    "            count[idx] += 1\n",
    "\n",
    "        b += 1\n",
    "\n",
    "    return [(acc[i]/count[i] if acc[i] is not None else None) for i in range(len(acc))]\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# normalize + combine\n",
    "# ====================================================\n",
    "def normalize_vector(x):\n",
    "    x = x.astype(np.float32)\n",
    "    x -= x.min()\n",
    "    m = x.max()\n",
    "    return x/m if m > 0 else np.ones_like(x)\n",
    "\n",
    "def compute_combined_importance(w, a, alpha, beta):\n",
    "    if w is None and a is None:\n",
    "        return None\n",
    "    if w is None: w = np.ones_like(a)\n",
    "    if a is None: a = np.ones_like(w)\n",
    "    return alpha*normalize_vector(w) + beta*normalize_vector(a)\n",
    "\n",
    "def select_topk_mask(score, keep_ratio):\n",
    "    n = score.shape[0]\n",
    "    k = max(1, int(n*keep_ratio))\n",
    "    th = np.partition(score, -k)[-k]\n",
    "    return (score >= th).astype(np.float32)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# APPLY MASKS\n",
    "# ====================================================\n",
    "def apply_masks_to_model_weights(model, masks):\n",
    "    for layer in model.layers:\n",
    "        if layer.name not in masks:\n",
    "            continue\n",
    "        mask = masks[layer.name]\n",
    "        w = layer.get_weights()\n",
    "        if not w:\n",
    "            continue\n",
    "        k = np.array(w[0])\n",
    "        b = np.array(w[1]) if len(w)>1 else None\n",
    "\n",
    "        if k.ndim == 2:\n",
    "            k = k * mask.reshape(1,-1)\n",
    "            if b is not None: b = b * mask\n",
    "        elif k.ndim == 4:\n",
    "            k = k * mask.reshape(1,1,1,-1)\n",
    "            if b is not None: b = b * mask\n",
    "\n",
    "        if b is None: layer.set_weights([k])\n",
    "        else: layer.set_weights([k,b])\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# AUTO LOSS (IMPORTANT FIX)\n",
    "# ====================================================\n",
    "def choose_loss(model):\n",
    "    outputs = model.output_shape\n",
    "\n",
    "    if isinstance(outputs, list):   # not common\n",
    "        outputs = outputs[0]\n",
    "\n",
    "    if outputs[-1] == 1:\n",
    "        print(\"Detected BINARY classifier → using binary_crossentropy\")\n",
    "        return \"binary_crossentropy\"\n",
    "\n",
    "    print(\"Detected MULTI-CLASS classifier → using sparse_categorical_crossentropy\")\n",
    "    return \"sparse_categorical_crossentropy\"\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# MAIN PIPELINE\n",
    "# ====================================================\n",
    "def prune_pipeline(\n",
    "    model_path,\n",
    "    dataset_path,\n",
    "    target_col=None,\n",
    "    keep_ratio=0.7,\n",
    "    alpha=0.5,\n",
    "    beta=0.5,\n",
    "    calib_batches=20,\n",
    "    calib_batch_size=64,\n",
    "    finetune_epochs=3,\n",
    "    finetune_batch_size=64,\n",
    "    save_dir=\"pruned_out\",\n",
    "    image_size=(224,224),\n",
    "    batch_size=64\n",
    "):\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    base_model = load_model(model_path)\n",
    "    base_model.summary()\n",
    "\n",
    "    is_tf_ds, train_ds, val_ds, meta = auto_load_dataset(dataset_path, target_col, image_size, batch_size)\n",
    "\n",
    "    if is_tf_ds:\n",
    "        sample_batch = next(iter(val_ds.take(1)))[0]\n",
    "    else:\n",
    "        X_train, y_train = train_ds\n",
    "        X_val, y_val = val_ds\n",
    "        X_train = np.asarray(X_train)\n",
    "        X_val = np.asarray(X_val)\n",
    "        sample_batch = X_val[:batch_size]\n",
    "\n",
    "    pruneable = get_pruneable_layers(base_model)\n",
    "\n",
    "    weight_imps = [per_unit_weight_importance(p[\"layer\"]) for p in pruneable]\n",
    "\n",
    "    if is_tf_ds:\n",
    "        Xcal = []\n",
    "        c = 0\n",
    "        for xb, _ in train_ds:\n",
    "            Xcal.append(xb.numpy())\n",
    "            c += 1\n",
    "            if c >= calib_batches:\n",
    "                break\n",
    "        Xcal = np.concatenate(Xcal, axis=0)\n",
    "        Xcal = Xcal.reshape((-1,)+meta[\"input_shape\"])\n",
    "    else:\n",
    "        Xcal = X_train[:calib_batches*calib_batch_size]\n",
    "\n",
    "    act_imps = collect_activation_magnitudes(\n",
    "        base_model, pruneable,\n",
    "        Xcal,\n",
    "        batch_size=calib_batch_size,\n",
    "        max_batches=calib_batches\n",
    "    )\n",
    "\n",
    "    masks = {}\n",
    "    summary = {}\n",
    "    for info, w_imp, a_imp in zip(pruneable, weight_imps, act_imps):\n",
    "        score = compute_combined_importance(w_imp, a_imp, alpha, beta)\n",
    "        if score is None:\n",
    "            continue\n",
    "        mask = select_topk_mask(score, keep_ratio)\n",
    "        masks[info[\"name\"]] = mask\n",
    "        summary[info[\"name\"]] = {\n",
    "            \"kept\": int(mask.sum()),\n",
    "            \"total\": int(len(mask))\n",
    "        }\n",
    "\n",
    "    json.dump(summary, open(os.path.join(save_dir,\"importance.json\"),\"w\"), indent=2)\n",
    "\n",
    "    pruned = tf.keras.models.clone_model(base_model)\n",
    "    pruned.set_weights(base_model.get_weights())\n",
    "    apply_masks_to_model_weights(pruned, masks)\n",
    "\n",
    "    loss_fn = choose_loss(pruned)\n",
    "    pruned.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=loss_fn, metrics=[\"accuracy\"])\n",
    "\n",
    "    if is_tf_ds:\n",
    "        before = pruned.evaluate(val_ds, verbose=0)\n",
    "    else:\n",
    "        before = pruned.evaluate(X_val, y_val, verbose=0)\n",
    "\n",
    "    if finetune_epochs>0:\n",
    "        if is_tf_ds:\n",
    "            pruned.fit(train_ds, validation_data=val_ds, epochs=finetune_epochs, verbose=2)\n",
    "            after = pruned.evaluate(val_ds, verbose=0)\n",
    "        else:\n",
    "            pruned.fit(\n",
    "                X_train, y_train,\n",
    "                validation_data=(X_val, y_val),\n",
    "                batch_size=finetune_batch_size,\n",
    "                epochs=finetune_epochs,\n",
    "                verbose=2\n",
    "            )\n",
    "            after = pruned.evaluate(X_val, y_val, verbose=0)\n",
    "    else:\n",
    "        after = None\n",
    "\n",
    "    pruned.save(os.path.join(save_dir,\"pruned_model.h5\"))\n",
    "    json.dump({k:v.tolist() for k,v in masks.items()}, open(os.path.join(save_dir,\"masks.json\"),\"w\"), indent=2)\n",
    "\n",
    "    print(\"DONE. Saved to:\", save_dir)\n",
    "    return pruned, {\n",
    "        \"before\": before,\n",
    "        \"after\": after,\n",
    "        \"masks\": masks,\n",
    "        \"summary\": summary\n",
    "    }\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# EXAMPLE\n",
    "# ====================================================\n",
    "pruned_model, artifacts = prune_pipeline(\n",
    "    model_path=r\"D:\\college\\sem-8\\fnn_bank_marketing_model.h5\",\n",
    "    dataset_path=r\"D:\\college\\sem-8\\bank-full.csv\",\n",
    "    target_col=\"y\",\n",
    "    keep_ratio=0.7,\n",
    "    alpha=0.5, beta=0.5,\n",
    "    calib_batches=20,\n",
    "    finetune_epochs=3,\n",
    "    save_dir=\"pruned_out\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30b27ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# FLOPS: For Dense (FNN)\n",
    "# ---------------------------------------------------------\n",
    "def dense_flops(input_units, output_units, use_bias=True):\n",
    "    flops = input_units * output_units\n",
    "    if use_bias:\n",
    "        flops += output_units\n",
    "    return flops\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# FLOPS: For Conv2D (CNN)\n",
    "# ---------------------------------------------------------\n",
    "def conv2d_flops(layer, input_shape):\n",
    "    filters = layer.filters\n",
    "    kernel_h, kernel_w = layer.kernel_size\n",
    "    in_channels = input_shape[-1]\n",
    "    stride_h, stride_w = layer.strides\n",
    "\n",
    "    # Output feature map size\n",
    "    if layer.padding == \"same\":\n",
    "        out_h = input_shape[0] // stride_h\n",
    "        out_w = input_shape[1] // stride_w\n",
    "    else:  # valid\n",
    "        out_h = (input_shape[0] - kernel_h + 1) // stride_h\n",
    "        out_w = (input_shape[1] - kernel_w + 1) // stride_w\n",
    "\n",
    "    flops = out_h * out_w * filters * (kernel_h * kernel_w * in_channels)\n",
    "    if layer.use_bias:\n",
    "        flops += out_h * out_w * filters\n",
    "    return flops, (out_h, out_w, filters)\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# FLOPS ESTIMATOR for ANY MODEL (FNN + CNN)\n",
    "# ---------------------------------------------------------\n",
    "def calculate_model_flops(model, input_shape, verbose=True):\n",
    "    total_flops = 0\n",
    "    current_shape = input_shape\n",
    "\n",
    "    if verbose:\n",
    "        print(\"\\nFLOPS Breakdown:\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "    for layer in model.layers:\n",
    "        layer_flops = 0\n",
    "\n",
    "        # --------------------------\n",
    "        # Conv2D (CNN)\n",
    "        # --------------------------\n",
    "        if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "            layer_flops, current_shape = conv2d_flops(layer, current_shape)\n",
    "            total_flops += layer_flops\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"{layer.name:20s}  (Conv2D)   FLOPS = {layer_flops:,}\")\n",
    "\n",
    "        # --------------------------\n",
    "        # Dense (FNN)\n",
    "        # --------------------------\n",
    "        elif isinstance(layer, tf.keras.layers.Dense):\n",
    "            if len(current_shape) > 1:\n",
    "                input_units = np.prod(current_shape)\n",
    "            else:\n",
    "                input_units = current_shape[0]\n",
    "\n",
    "            output_units = layer.units\n",
    "            layer_flops = dense_flops(input_units, output_units, layer.use_bias)\n",
    "            total_flops += layer_flops\n",
    "            current_shape = (output_units,)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"{layer.name:20s}  (Dense)    FLOPS = {layer_flops:,}\")\n",
    "\n",
    "        # --------------------------\n",
    "        # Flatten\n",
    "        # --------------------------\n",
    "        elif isinstance(layer, tf.keras.layers.Flatten):\n",
    "            current_shape = (np.prod(current_shape),)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"{layer.name:20s}  (Flatten)\")\n",
    "\n",
    "        # --------------------------\n",
    "        # MaxPooling2D\n",
    "        # --------------------------\n",
    "        elif isinstance(layer, tf.keras.layers.MaxPooling2D):\n",
    "            pool = layer.pool_size[0]\n",
    "            h, w, c = current_shape\n",
    "            current_shape = (h // pool, w // pool, c)\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"{layer.name:20s}  (MaxPool2D)\")\n",
    "\n",
    "        # --------------------------\n",
    "        # Minimal FLOPs layers\n",
    "        # --------------------------\n",
    "        elif isinstance(layer, (tf.keras.layers.BatchNormalization, tf.keras.layers.Dropout)):\n",
    "            if verbose:\n",
    "                print(f\"{layer.name:20s}  ({layer.__class__.__name__}) minimal FLOPS\")\n",
    "\n",
    "    if verbose:\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"Total FLOPS = {total_flops:,}\")\n",
    "        print(f\"Total GFLOPS = {total_flops/1e9:.6f}\")\n",
    "\n",
    "    return total_flops\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# INFERENCE TIME\n",
    "# ---------------------------------------------------------\n",
    "def measure_inference_time(model, input_shape, runs=50):\n",
    "    dummy_input = np.random.rand(1, *input_shape).astype(np.float32)\n",
    "\n",
    "    # Warm-up\n",
    "    for _ in range(5):\n",
    "        model.predict(dummy_input, verbose=0)\n",
    "\n",
    "    start = time.time()\n",
    "    for _ in range(runs):\n",
    "        model.predict(dummy_input, verbose=0)\n",
    "    end = time.time()\n",
    "\n",
    "    avg_time = (end - start) / runs\n",
    "    return avg_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "097a1f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FLOPS Breakdown:\n",
      "------------------------------------------------------------\n",
      "dense                 (Dense)    FLOPS = 5,504\n",
      "dense_1               (Dense)    FLOPS = 8,256\n",
      "dense_2               (Dense)    FLOPS = 2,080\n",
      "dense_3               (Dense)    FLOPS = 33\n",
      "------------------------------------------------------------\n",
      "Total FLOPS = 15,873\n",
      "Total GFLOPS = 0.000016\n",
      "\n",
      "FLOPS Breakdown:\n",
      "------------------------------------------------------------\n",
      "dense                 (Dense)    FLOPS = 5,504\n",
      "dense_1               (Dense)    FLOPS = 8,256\n",
      "dense_2               (Dense)    FLOPS = 2,080\n",
      "dense_3               (Dense)    FLOPS = 33\n",
      "------------------------------------------------------------\n",
      "Total FLOPS = 15,873\n",
      "Total GFLOPS = 0.000016\n",
      "Orig FLOPS: 15873\n",
      "Pruned FLOPS: 15873\n",
      "Orig Time: 0.13581624031066894\n",
      "Pruned Time: 0.13804460048675538\n"
     ]
    }
   ],
   "source": [
    "orig = tf.keras.models.load_model(r\"D:\\college\\sem-8\\fnn_bank_marketing_model.h5\")\n",
    "pruned = tf.keras.models.load_model(r\"D:\\college\\sem-8\\final\\pruned_out\\pruned_model.h5\")\n",
    "\n",
    "input_shape = (orig.input_shape[1],)\n",
    "\n",
    "flops_orig = calculate_model_flops(orig, input_shape)\n",
    "flops_pruned = calculate_model_flops(pruned, input_shape)\n",
    "\n",
    "time_orig = measure_inference_time(orig, input_shape)\n",
    "time_pruned = measure_inference_time(pruned, input_shape)\n",
    "\n",
    "print(\"Orig FLOPS:\", flops_orig)\n",
    "print(\"Pruned FLOPS:\", flops_pruned)\n",
    "print(\"Orig Time:\", time_orig)\n",
    "print(\"Pruned Time:\", time_pruned)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e312d3",
   "metadata": {},
   "source": [
    "# **FNN as user input working**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d128d0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: D:\\college\\sem-8\\models\\dementia_fnn_model.h5\n",
      "[INFO] Detected model type: binary\n",
      "[INFO] Using loss='binary_crossentropy', metrics=['accuracy']\n",
      "Loading dataset: D:\\college\\sem-8\\dataset\\clean_dementia_dataset.csv\n",
      "[INFO] Loading CSV with automatic delimiter detection...\n",
      "[INFO] Columns detected: ['Age', 'EDUC', 'SES', 'MMSE', 'CDR', 'eTIV', 'nWBV', 'ASF', 'M/F_M', 'Group']\n",
      "[INFO] Auto-detected target column = Group\n",
      "[INFO] No categorical predictor columns to encode.\n",
      "Dense layers: ['dense_14', 'dense_15', 'dense_16', 'dense_17', 'dense_18', 'dense_19'] | last_dense: dense_19\n",
      "Computing activation & gradient stats...\n",
      "dense_14 -> kept units: 102/128\n",
      "dense_15 -> kept units: 51/64\n",
      "dense_16 -> kept units: 51/64\n",
      "dense_17 -> kept units: 51/64\n",
      "dense_18 -> kept units: 25/32\n",
      "dense_19 -> kept units: 1/1\n",
      "Building masked model (DNAGate zeroing)...\n",
      "Baseline Acc: 0.59375 | FLOPS: 39585\n",
      "Masked Acc (before FT): 0.59375 | Effective FLOPS: 25525\n",
      "Fine-tuning masked model...\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:5 out of the last 79 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x0000022327BC1760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 79 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x0000022327BC1760> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 2s - 552ms/step - accuracy: 0.5837 - loss: 6.7050 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 2/15\n",
      "4/4 - 0s - 85ms/step - accuracy: 0.6244 - loss: 5.9836 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 3/15\n",
      "4/4 - 0s - 28ms/step - accuracy: 0.5656 - loss: 6.8380 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 4/15\n",
      "4/4 - 0s - 26ms/step - accuracy: 0.5973 - loss: 6.4779 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 5/15\n",
      "4/4 - 0s - 23ms/step - accuracy: 0.5973 - loss: 6.4910 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 6/15\n",
      "4/4 - 0s - 22ms/step - accuracy: 0.5928 - loss: 6.5631 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 7/15\n",
      "4/4 - 0s - 28ms/step - accuracy: 0.5973 - loss: 6.4910 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 8/15\n",
      "4/4 - 0s - 26ms/step - accuracy: 0.5973 - loss: 6.4910 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 9/15\n",
      "4/4 - 0s - 27ms/step - accuracy: 0.5928 - loss: 6.5631 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 10/15\n",
      "4/4 - 0s - 26ms/step - accuracy: 0.5973 - loss: 6.4910 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 11/15\n",
      "4/4 - 0s - 26ms/step - accuracy: 0.5973 - loss: 6.4910 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 12/15\n",
      "4/4 - 0s - 29ms/step - accuracy: 0.5973 - loss: 6.4910 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 13/15\n",
      "4/4 - 0s - 31ms/step - accuracy: 0.5973 - loss: 6.4910 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 14/15\n",
      "4/4 - 0s - 30ms/step - accuracy: 0.5973 - loss: 6.4910 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 15/15\n",
      "4/4 - 0s - 25ms/step - accuracy: 0.5973 - loss: 6.4910 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Constructing structurally-pruned model (remove neurons)...\n",
      "Fine-tuning pruned model...\n",
      "Epoch 1/15\n",
      "4/4 - 2s - 484ms/step - accuracy: 0.5973 - loss: 1214.8918 - val_accuracy: 0.5938 - val_loss: 823.1508\n",
      "Epoch 2/15\n",
      "4/4 - 0s - 28ms/step - accuracy: 0.5792 - loss: 569.7695 - val_accuracy: 0.5938 - val_loss: 193.8018\n",
      "Epoch 3/15\n",
      "4/4 - 0s - 26ms/step - accuracy: 0.5475 - loss: 238.4988 - val_accuracy: 0.4062 - val_loss: 245.6437\n",
      "Epoch 4/15\n",
      "4/4 - 0s - 25ms/step - accuracy: 0.5068 - loss: 225.9488 - val_accuracy: 0.4062 - val_loss: 254.6095\n",
      "Epoch 5/15\n",
      "4/4 - 0s - 22ms/step - accuracy: 0.4570 - loss: 208.6297 - val_accuracy: 0.4062 - val_loss: 184.6468\n",
      "Epoch 6/15\n",
      "4/4 - 0s - 27ms/step - accuracy: 0.4842 - loss: 156.2182 - val_accuracy: 0.4062 - val_loss: 108.9086\n",
      "Epoch 7/15\n",
      "4/4 - 0s - 29ms/step - accuracy: 0.5068 - loss: 97.6133 - val_accuracy: 0.4062 - val_loss: 44.6456\n",
      "Epoch 8/15\n",
      "4/4 - 0s - 25ms/step - accuracy: 0.5294 - loss: 83.1155 - val_accuracy: 0.4062 - val_loss: 2.9094\n",
      "Epoch 9/15\n",
      "4/4 - 0s - 24ms/step - accuracy: 0.5339 - loss: 63.9120 - val_accuracy: 0.5938 - val_loss: 12.7990\n",
      "Epoch 10/15\n",
      "4/4 - 0s - 23ms/step - accuracy: 0.4887 - loss: 71.8093 - val_accuracy: 0.5938 - val_loss: 13.8152\n",
      "Epoch 11/15\n",
      "4/4 - 0s - 22ms/step - accuracy: 0.5475 - loss: 57.5784 - val_accuracy: 0.5938 - val_loss: 12.8789\n",
      "Epoch 12/15\n",
      "4/4 - 0s - 24ms/step - accuracy: 0.5294 - loss: 48.5736 - val_accuracy: 0.5938 - val_loss: 12.4937\n",
      "Epoch 13/15\n",
      "4/4 - 0s - 26ms/step - accuracy: 0.4434 - loss: 44.4868 - val_accuracy: 0.5938 - val_loss: 10.8111\n",
      "Epoch 14/15\n",
      "4/4 - 0s - 26ms/step - accuracy: 0.4706 - loss: 35.1462 - val_accuracy: 0.5938 - val_loss: 10.0365\n",
      "Epoch 15/15\n",
      "4/4 - 0s - 32ms/step - accuracy: 0.6063 - loss: 25.9152 - val_accuracy: 0.5938 - val_loss: 10.2619\n",
      "\n",
      "=== FINAL REPORT ===\n",
      "Model type: binary\n",
      "Baseline:   Acc/metric=0.59375 | FLOPS=39585 | MFLOPS=0.039585 | GFLOPS=0.0000395850 | Time=2.9697 ms/sample\n",
      "Masked:     Acc/metric=0.59375 | EFLOPS=25525 | MFLOPS=0.025525 | GFLOPS=0.0000255250 | Time=3.8262 ms/sample\n",
      "Pruned:     Acc/metric=0.59375 | FLOPS=25525 | MFLOPS=0.025525 | GFLOPS=0.0000255250 | Time=4.7475 ms/sample\n",
      "FLOPS reduction (pruned): 35.52%\n",
      "==============================================\n",
      "\n",
      "Pruned:     Acc/metric=0.59375 | FLOPS=25525 | MFLOPS=0.025525 | GFLOPS=0.0000255250 | Time=4.7475 ms/sample\n",
      "FLOPS reduction (pruned): 35.52%\n",
      "GFLOPS reduction (pruned): 35.52%\n",
      "Accuracy reduction: 0.0\n",
      "==============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FNN-only pruning pipeline (auto-detect model type).\n",
    "- Detects model type from final layer (binary / multiclass / regression).\n",
    "- Adapts CSV loader accordingly.\n",
    "- Keeps final layer intact (never pruned).\n",
    "- Reports FLOPs, GFLOPs, MFLOPs and inference time.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -----------------------\n",
    "# Helper: detect model type\n",
    "# -----------------------\n",
    "def detect_model_type(model):\n",
    "    out = model.layers[-1]\n",
    "    units = getattr(out, \"units\", None)\n",
    "    act = getattr(out, \"activation\", None)\n",
    "    act_name = act.__name__ if act is not None else None\n",
    "\n",
    "    if units == 1 and act_name in (\"sigmoid\",):\n",
    "        return \"binary\"\n",
    "    if units == 1 and act_name in (\"linear\", \"relu\", \"tanh\"):\n",
    "        return \"regression\"\n",
    "    if units is not None and units > 1 and act_name == \"softmax\":\n",
    "        return \"multiclass\"\n",
    "    # fallback tries\n",
    "    if units == 1:\n",
    "        return \"binary\"\n",
    "    if units and units > 1:\n",
    "        return \"multiclass\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def get_loss_and_metrics_for_type(model_type):\n",
    "    if model_type == \"binary\":\n",
    "        return (\"binary_crossentropy\", [\"accuracy\"])\n",
    "    if model_type == \"multiclass\":\n",
    "        # use sparse labels to avoid forcing one-hot encoding\n",
    "        return (\"sparse_categorical_crossentropy\", [\"sparse_categorical_accuracy\"])\n",
    "    if model_type == \"regression\":\n",
    "        return (\"mse\", [\"mse\"])\n",
    "    raise ValueError(\"Unknown model type\")\n",
    "\n",
    "# =====================================================================\n",
    "# 1) UNIVERSAL CSV LOADER  (adapts target based on model_type)\n",
    "# =====================================================================\n",
    "def load_any_csv_dataset(csv_path, target=None, test_size=0.2, val_size=0.1, model_type=\"binary\"):\n",
    "    \"\"\"\n",
    "    Loads CSV (auto-detect delimiter). Adapts target processing to model_type:\n",
    "      - binary/regression: returns y as float32 shaped (n,1)\n",
    "      - multiclass: returns integer labels shaped (n,1) for sparse loss\n",
    "    \"\"\"\n",
    "    print(\"[INFO] Loading CSV with automatic delimiter detection...\")\n",
    "    df = pd.read_csv(csv_path, sep=None, engine=\"python\")\n",
    "    print(\"[INFO] Columns detected:\", list(df.columns))\n",
    "\n",
    "    if target is None:\n",
    "        target = df.columns[-1]\n",
    "        print(f\"[INFO] Auto-detected target column = {target}\")\n",
    "\n",
    "    if target not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target}' not found in dataset!\")\n",
    "\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    # Preprocess target based on model_type\n",
    "    if model_type == \"binary\":\n",
    "        # convert yes/no/true/false -> 1/0\n",
    "        if y.dtype == object:\n",
    "            y = y.astype(str).str.strip().str.lower()\n",
    "            y = y.replace({\"yes\": 1, \"no\": 0, \"true\": 1, \"false\": 0})\n",
    "        # ensure numeric\n",
    "        y = y.astype(np.float32).values.reshape(-1, 1)\n",
    "\n",
    "    elif model_type == \"multiclass\":\n",
    "        # convert strings to categorical integer codes if needed\n",
    "        if y.dtype == object:\n",
    "            y = y.astype(\"category\").cat.codes\n",
    "        # ensure integer labels (sparse labels)\n",
    "        y = y.astype(np.int32).values.reshape(-1, 1)\n",
    "\n",
    "    elif model_type == \"regression\":\n",
    "        # numeric continuous\n",
    "        y = y.astype(np.float32).values.reshape(-1, 1)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model_type for loader\")\n",
    "\n",
    "    # One-hot encode only categorical predictors (keep numeric as-is)\n",
    "    cat_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "    if len(cat_cols) > 0:\n",
    "        print(\"[INFO] One-hot encoding predictors:\", list(cat_cols))\n",
    "        X = pd.get_dummies(X, drop_first=True)\n",
    "    else:\n",
    "        print(\"[INFO] No categorical predictor columns to encode.\")\n",
    "\n",
    "    # convert to float32 (features)\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    # Split\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=(test_size + val_size), random_state=42, stratify=y if model_type!=\"regression\" else None\n",
    "    )\n",
    "    # second split into val/test\n",
    "    val_ratio = val_size / (test_size + val_size)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=(1 - val_ratio), random_state=42,\n",
    "        stratify=y_temp if model_type!=\"regression\" else None\n",
    "    )\n",
    "\n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 2) GET DENSE LAYERS\n",
    "# =====================================================================\n",
    "def get_dense_layers(model):\n",
    "    return [layer for layer in model.layers if isinstance(layer, Dense)]\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 3) ACTIVATION + GRADIENT STATS  (SHAPE-SAFE)\n",
    "# =====================================================================\n",
    "def compute_activation_grad_stats(model, dense_layers, X, y, model_type,\n",
    "                                  batch_size=64, max_batches=30):\n",
    "    \"\"\"\n",
    "    Returns stats dict: {layer.name: (A_mean_per_neuron, G_mean_per_neuron, Var_per_neuron)}\n",
    "    Uses appropriate loss for model_type when computing gradients.\n",
    "    \"\"\"\n",
    "    # Convert X,y to numpy if DataFrame\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X_np = X.to_numpy()\n",
    "    else:\n",
    "        X_np = X\n",
    "    if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):\n",
    "        y_np = y.to_numpy()\n",
    "    else:\n",
    "        y_np = y\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X_np, y_np)).batch(batch_size)\n",
    "    acc_A = {l.name: [] for l in dense_layers}\n",
    "    acc_G = {l.name: [] for l in dense_layers}\n",
    "    acc_V = {l.name: [] for l in dense_layers}\n",
    "\n",
    "    # choose loss for gradient computation\n",
    "    if model_type == \"binary\":\n",
    "        loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False, reduction=tf.keras.losses.Reduction.NONE)\n",
    "    elif model_type == \"multiclass\":\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction=tf.keras.losses.Reduction.NONE)\n",
    "    elif model_type == \"regression\":\n",
    "        loss_fn = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model_type for stats\")\n",
    "\n",
    "    batch_count = 0\n",
    "    for xb, yb in ds:\n",
    "        if batch_count >= max_batches:\n",
    "            break\n",
    "        batch_count += 1\n",
    "\n",
    "        # ensure shapes consistent\n",
    "        x = tf.cast(xb, tf.float32)\n",
    "        # For sparse multiclass loss, yb should be shape (batch,) ints\n",
    "        if model_type == \"multiclass\":\n",
    "            yb_proc = tf.cast(tf.squeeze(yb, axis=-1), tf.int32)\n",
    "        else:\n",
    "            # binary/regression: keep shape (batch,1) as float32\n",
    "            yb_proc = tf.cast(yb, tf.float32)\n",
    "\n",
    "        layer_outputs = {}\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            for layer in model.layers:\n",
    "                x = layer(x)\n",
    "                if layer in dense_layers:\n",
    "                    tape.watch(x)\n",
    "                    layer_outputs[layer.name] = x\n",
    "            preds = x\n",
    "            # compute per-sample loss (shape [batch,] or [batch, ...])\n",
    "            per_sample_loss = loss_fn(yb_proc, preds)\n",
    "            # compute scalar loss for gradient direction\n",
    "            loss = tf.reduce_mean(per_sample_loss)\n",
    "\n",
    "        for layer in dense_layers:\n",
    "            name = layer.name\n",
    "            if name not in layer_outputs:\n",
    "                continue\n",
    "            a = layer_outputs[name]            # shape (batch, units)\n",
    "            A = tf.reduce_mean(tf.abs(a), axis=0).numpy()\n",
    "            V = tf.math.reduce_variance(a, axis=0).numpy()\n",
    "\n",
    "            g = tape.gradient(loss, a)\n",
    "            if g is None:\n",
    "                G = np.zeros_like(A)\n",
    "            else:\n",
    "                G = tf.reduce_mean(tf.abs(g), axis=0).numpy()\n",
    "\n",
    "            acc_A[name].append(A)\n",
    "            acc_G[name].append(G)\n",
    "            acc_V[name].append(V)\n",
    "\n",
    "        del tape\n",
    "\n",
    "    # Aggregate\n",
    "    stats = {}\n",
    "    for layer in dense_layers:\n",
    "        name = layer.name\n",
    "        if len(acc_A[name]) == 0:\n",
    "            stats[name] = (np.array([]), np.array([]), np.array([]))\n",
    "            continue\n",
    "        A = np.mean(np.stack(acc_A[name], axis=0), axis=0)\n",
    "        G = np.mean(np.stack(acc_G[name], axis=0), axis=0)\n",
    "        V = np.mean(np.stack(acc_V[name], axis=0), axis=0)\n",
    "        stats[name] = (A, G, V)\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 4) IMPORTANCE MASKS (protect last Dense layer)\n",
    "# =====================================================================\n",
    "def compute_importance_mask(\n",
    "        stats,\n",
    "        keep_ratio=0.7,\n",
    "        alpha=0.5,\n",
    "        beta=0.3,\n",
    "        gamma=0.2,\n",
    "        last_dense_name=None,\n",
    "        min_units=4  # <-- increase minimum neurons per layer\n",
    "    ):\n",
    "    \n",
    "    masks = {}\n",
    "    for name, (A, G, V) in stats.items():\n",
    "        if A.size == 0:\n",
    "            masks[name] = np.array([], dtype=np.float32)\n",
    "            continue\n",
    "\n",
    "        def normalize(x):\n",
    "            x2 = x - np.min(x)\n",
    "            mx = np.max(x2)\n",
    "            return x2 / (mx + 1e-12)\n",
    "\n",
    "        # compute score\n",
    "        score = alpha * normalize(A) + beta * normalize(G) + gamma * normalize(V)\n",
    "\n",
    "        # ---- NEVER prune final Dense layer ----\n",
    "        if last_dense_name is not None and name == last_dense_name:\n",
    "            masks[name] = np.ones_like(score, dtype=np.float32)\n",
    "            continue\n",
    "\n",
    "        # ---- compute K ----\n",
    "        k = int(len(score) * keep_ratio)\n",
    "        k = max(k, min_units)        # enforce minimum\n",
    "        k = min(k, len(score))       # safety\n",
    "\n",
    "        # ---- If all scores are zero → randomly pick k neurons ----\n",
    "        if np.all(score == 0):\n",
    "            sel = np.random.choice(len(score), size=k, replace=False)\n",
    "            mask = np.zeros_like(score)\n",
    "            mask[sel] = 1\n",
    "            masks[name] = mask.astype(np.float32)\n",
    "            continue\n",
    "\n",
    "        # normal path\n",
    "        thresh = np.partition(score, -k)[-k]\n",
    "        mask = (score >= thresh).astype(np.float32)\n",
    "\n",
    "        # final safety: ensure >= min_units survive\n",
    "        if np.sum(mask) < min_units:\n",
    "            topk = np.argsort(score)[-min_units:]\n",
    "            mask = np.zeros_like(score)\n",
    "            mask[topk] = 1\n",
    "\n",
    "        masks[name] = mask.astype(np.float32)\n",
    "\n",
    "    return masks\n",
    "\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 5) DNAGate Layer (Zeroing)\n",
    "# =====================================================================\n",
    "class DNAGate(tf.keras.layers.Layer):\n",
    "    def __init__(self, mask=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._mask_np = np.array(mask, dtype=np.float32) if mask is not None else None\n",
    "        self.mask = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self._mask_np is None:\n",
    "            self.mask = None\n",
    "        else:\n",
    "            if input_shape[-1] != self._mask_np.shape[0]:\n",
    "                raise ValueError(f\"DNAGate mask length {self._mask_np.shape[0]} != layer units {input_shape[-1]}\")\n",
    "            self.mask = tf.constant(self._mask_np, dtype=self.dtype)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        if self.mask is None:\n",
    "            return x\n",
    "        return x * self.mask\n",
    "\n",
    "\n",
    "def build_masked_model(orig_model, masks):\n",
    "    inp = Input(shape=orig_model.input_shape[1:])\n",
    "    x = inp\n",
    "    for layer in orig_model.layers:\n",
    "        x = layer(x)\n",
    "        if layer.name in masks:\n",
    "            x = DNAGate(mask=masks[layer.name], name=layer.name + \"_dna\")(x)\n",
    "    new_model = Model(inp, x)\n",
    "    # copy weights where possible\n",
    "    for l in orig_model.layers:\n",
    "        try:\n",
    "            new_model.get_layer(l.name).set_weights(l.get_weights())\n",
    "        except Exception:\n",
    "            pass\n",
    "    return new_model\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 6) FLOPS + INFERENCE TIME\n",
    "# =====================================================================\n",
    "def dense_flops(in_size, out_size, bias=True):\n",
    "    # multiply-adds counted as 2 ops per MAC\n",
    "    return int(in_size * out_size * 2 + (out_size if bias else 0))\n",
    "\n",
    "def model_flops(model):\n",
    "    total = 0\n",
    "    in_size = int(model.input_shape[1])\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, Dense):\n",
    "            total += dense_flops(in_size, layer.units, layer.use_bias)\n",
    "            in_size = layer.units\n",
    "    return total\n",
    "\n",
    "def effective_flops(model, masks):\n",
    "    total = 0\n",
    "    in_size = int(model.input_shape[1])\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, Dense):\n",
    "            if layer.name in masks and masks[layer.name].size > 0:\n",
    "                units = int(np.sum(masks[layer.name]))\n",
    "            else:\n",
    "                units = layer.units\n",
    "            total += dense_flops(in_size, units, layer.use_bias)\n",
    "            in_size = units\n",
    "    return total\n",
    "\n",
    "def flops_to_gflops(f):\n",
    "    return f / 1e9\n",
    "\n",
    "def flops_to_mflops(f):\n",
    "    return f / 1e6\n",
    "\n",
    "def measure_inference_time(model, X, runs=200):\n",
    "    \"\"\"Return average inference time in milliseconds per sample.\n",
    "       Accepts X as pandas DataFrame or numpy array.\"\"\"\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X_np = X.to_numpy()\n",
    "    else:\n",
    "        X_np = X\n",
    "    if len(X_np) == 0:\n",
    "        return float(\"nan\")\n",
    "    # pick random indices\n",
    "    idx = np.random.randint(0, len(X_np), size=min(runs, len(X_np)))\n",
    "    samples = X_np[idx]\n",
    "    # warm-up single predict\n",
    "    model.predict(samples[:1], verbose=0)\n",
    "    t0 = time.time()\n",
    "    model.predict(samples, verbose=0)\n",
    "    t1 = time.time()\n",
    "    total_ms = (t1 - t0) * 1000.0\n",
    "    return total_ms / len(samples)\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 7) STRUCTURAL PRUNING (REMOVE NEURONS) — protect final Dense layer\n",
    "# =====================================================================\n",
    "def structurally_prune_fnn(orig_model, masks, last_dense_name=None):\n",
    "    inp = Input(shape=orig_model.input_shape[1:])\n",
    "    x = inp\n",
    "    prev_sel = None\n",
    "\n",
    "    for layer in orig_model.layers:\n",
    "        if isinstance(layer, Dense):\n",
    "            W, b = layer.get_weights()\n",
    "\n",
    "            # If previous layer was pruned → prune rows\n",
    "            if prev_sel is not None:\n",
    "                W = W[prev_sel, :]\n",
    "\n",
    "            # ---- SAFETY: determine neurons to keep ----\n",
    "            if last_dense_name is not None and layer.name == last_dense_name:\n",
    "                # never prune final layer\n",
    "                sel = np.arange(layer.units)\n",
    "\n",
    "            else:\n",
    "                mask = masks.get(layer.name, None)\n",
    "                if mask is not None and mask.size > 0:\n",
    "                    sel = np.where(mask == 1)[0]\n",
    "\n",
    "                    # 💥 SAFETY FIX: ensure >=1 neuron survives\n",
    "                    if len(sel) == 0:\n",
    "                        sel = np.array([np.argmax(mask)])  \n",
    "                else:\n",
    "                    sel = None\n",
    "\n",
    "            # ---- Apply pruning ----\n",
    "            if sel is not None:\n",
    "                W_new = W[:, sel]\n",
    "                b_new = b[sel]\n",
    "                new_units = len(sel)\n",
    "            else:\n",
    "                W_new = W\n",
    "                b_new = b\n",
    "                new_units = W.shape[1]\n",
    "\n",
    "            new_layer = Dense(new_units, activation=layer.activation, name=layer.name)\n",
    "            x = new_layer(x)\n",
    "            new_layer.set_weights([W_new, b_new])\n",
    "\n",
    "            prev_sel = sel\n",
    "\n",
    "        else:\n",
    "            x = layer(x)\n",
    "\n",
    "    return Model(inp, x)\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 8) MAIN PIPELINE (auto-detect model type)\n",
    "# =====================================================================\n",
    "def fnn_pruning_pipeline(model_path, dataset_path,\n",
    "                         keep_ratio=0.7,\n",
    "                         alpha=0.5, beta=0.3, gamma=0.2,\n",
    "                         calib_batches=30, batch_size=64, ft_epochs=3):\n",
    "    # 1) load model and detect type\n",
    "    print(\"Loading model:\", model_path)\n",
    "    model = load_model(model_path)\n",
    "    model_type = detect_model_type(model)\n",
    "    print(f\"[INFO] Detected model type: {model_type}\")\n",
    "\n",
    "    loss_name, metrics = get_loss_and_metrics_for_type(model_type)\n",
    "    print(f\"[INFO] Using loss='{loss_name}', metrics={metrics}\")\n",
    "\n",
    "    # 2) load dataset adapted to model_type\n",
    "    print(\"Loading dataset:\", dataset_path)\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = load_any_csv_dataset(dataset_path, model_type=model_type)\n",
    "\n",
    "    # 3) find dense layers and the last Dense layer name\n",
    "    dense_layers = get_dense_layers(model)\n",
    "    last_dense_name = dense_layers[-1].name if len(dense_layers) > 0 else None\n",
    "    print(\"Dense layers:\", [l.name for l in dense_layers], \"| last_dense:\", last_dense_name)\n",
    "\n",
    "    # 4) compute stats (activation + gradient)\n",
    "    print(\"Computing activation & gradient stats...\")\n",
    "    stats = compute_activation_grad_stats(model, dense_layers, X_train, y_train, model_type,\n",
    "                                          batch_size=batch_size, max_batches=calib_batches)\n",
    "\n",
    "    # 5) compute masks (protect final layer)\n",
    "    masks = compute_importance_mask(stats, keep_ratio=keep_ratio, alpha=alpha, beta=beta, gamma=gamma, last_dense_name=last_dense_name)\n",
    "    for k,v in masks.items():\n",
    "        if v.size > 0:\n",
    "            print(f\"{k} -> kept units: {int(np.sum(v))}/{len(v)}\")\n",
    "\n",
    "    # 6) build masked model (zeroing) and compile with correct loss/metrics\n",
    "    print(\"Building masked model (DNAGate zeroing)...\")\n",
    "    masked_model = build_masked_model(model, masks)\n",
    "    masked_model.compile(optimizer='adam', loss=loss_name, metrics=metrics)\n",
    "\n",
    "    # compute baseline & masked flops/accuracy\n",
    "    baseline_acc = None\n",
    "    masked_acc_before = None\n",
    "    if model_type == \"regression\":\n",
    "        baseline_eval = model.evaluate(X_val, y_val, verbose=0)\n",
    "        baseline_acc = baseline_eval[0] if len(baseline_eval)>0 else None\n",
    "        masked_acc_before = masked_model.evaluate(X_val, y_val, verbose=0)[0]\n",
    "    else:\n",
    "        baseline_acc = model.evaluate(X_val, y_val, verbose=0)[1]  # accuracy or sparse_accuracy\n",
    "        masked_acc_before = masked_model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "\n",
    "    baseline_flops = model_flops(model)\n",
    "    masked_flops = effective_flops(model, masks)\n",
    "\n",
    "    print(f\"Baseline Acc: {baseline_acc} | FLOPS: {baseline_flops}\")\n",
    "    print(f\"Masked Acc (before FT): {masked_acc_before} | Effective FLOPS: {masked_flops}\")\n",
    "\n",
    "    # 7) fine-tune masked model\n",
    "    print(\"Fine-tuning masked model...\")\n",
    "    masked_model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=ft_epochs, verbose=2)\n",
    "\n",
    "    # evaluate masked after FT\n",
    "    if model_type == \"regression\":\n",
    "        masked_eval = masked_model.evaluate(X_val, y_val, verbose=0)\n",
    "        masked_acc_after = masked_eval[0] if len(masked_eval)>0 else None\n",
    "    else:\n",
    "        masked_acc_after = masked_model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "\n",
    "    # 8) structural pruning (permanent neuron removal)\n",
    "    print(\"Constructing structurally-pruned model (remove neurons)...\")\n",
    "    pruned_model = structurally_prune_fnn(model, masks, last_dense_name=last_dense_name)\n",
    "    pruned_model.compile(optimizer='adam', loss=loss_name, metrics=metrics)\n",
    "\n",
    "    print(\"Fine-tuning pruned model...\")\n",
    "    pruned_model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=ft_epochs, verbose=2)\n",
    "\n",
    "    # final evals\n",
    "    if model_type == \"regression\":\n",
    "        pruned_eval = pruned_model.evaluate(X_val, y_val, verbose=0)\n",
    "        pruned_acc = pruned_eval[0] if len(pruned_eval)>0 else None\n",
    "    else:\n",
    "        pruned_acc = pruned_model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "\n",
    "    pruned_flops = model_flops(pruned_model)\n",
    "\n",
    "    # compute GFLOPS / MFLOPS / inference times\n",
    "    baseline_gflops = flops_to_gflops(baseline_flops)\n",
    "    masked_gflops = flops_to_gflops(masked_flops)\n",
    "    pruned_gflops = flops_to_gflops(pruned_flops)\n",
    "\n",
    "    baseline_mflops = flops_to_mflops(baseline_flops)\n",
    "    masked_mflops = flops_to_mflops(masked_flops)\n",
    "    pruned_mflops = flops_to_mflops(pruned_flops)\n",
    "\n",
    "    baseline_time_ms = measure_inference_time(model, X_val)\n",
    "    masked_time_ms = measure_inference_time(masked_model, X_val)\n",
    "    pruned_time_ms = measure_inference_time(pruned_model, X_val)\n",
    "\n",
    "    print(\"\\n=== FINAL REPORT ===\")\n",
    "    print(f\"Model type: {model_type}\")\n",
    "    print(f\"Baseline:   Acc/metric={baseline_acc} | FLOPS={baseline_flops} | MFLOPS={baseline_mflops:.6f} | GFLOPS={baseline_gflops:.10f} | Time={baseline_time_ms:.4f} ms/sample\")\n",
    "    print(f\"Masked:     Acc/metric={masked_acc_after} | EFLOPS={masked_flops} | MFLOPS={masked_mflops:.6f} | GFLOPS={masked_gflops:.10f} | Time={masked_time_ms:.4f} ms/sample\")\n",
    "    print(f\"Pruned:     Acc/metric={pruned_acc} | FLOPS={pruned_flops} | MFLOPS={pruned_mflops:.6f} | GFLOPS={pruned_gflops:.10f} | Time={pruned_time_ms:.4f} ms/sample\")\n",
    "    if baseline_flops > 0:\n",
    "        print(f\"FLOPS reduction (pruned): {(baseline_flops - pruned_flops)/baseline_flops:.2%}\")\n",
    "    print(\"==============================================\\n\")\n",
    "\n",
    "    print(f\"Pruned:     Acc/metric={pruned_acc} | FLOPS={pruned_flops} | MFLOPS={pruned_mflops:.6f} | GFLOPS={pruned_gflops:.10f} | Time={pruned_time_ms:.4f} ms/sample\")\n",
    "\n",
    "    # ---- NEW METRIC REDUCTIONS ADDED BELOW ----\n",
    "    if baseline_flops > 0:\n",
    "        flop_reduction = (baseline_flops - pruned_flops) / baseline_flops\n",
    "        gflop_reduction = (baseline_gflops - pruned_gflops) / baseline_gflops if baseline_gflops > 0 else 0\n",
    "    else:\n",
    "        flop_reduction = 0\n",
    "        gflop_reduction = 0\n",
    "\n",
    "    acc_reduction = baseline_acc - pruned_acc if baseline_acc is not None else None\n",
    "\n",
    "    print(f\"FLOPS reduction (pruned): {flop_reduction:.2%}\")\n",
    "    print(f\"GFLOPS reduction (pruned): {gflop_reduction:.2%}\")\n",
    "    print(f\"Accuracy reduction: {acc_reduction}\")\n",
    "    # ---- END NEW LINES ----\n",
    "\n",
    "    print(\"==============================================\\n\")\n",
    "\n",
    "\n",
    "    # return X_val for further external checks if desired\n",
    "    return model, masked_model, pruned_model, masks, X_val\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 9) RUN (example)\n",
    "# =====================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # change these to your files\n",
    "    model_path = r\"D:\\college\\sem-8\\models\\dementia_fnn_model.h5\"\n",
    "    dataset_path = r\"D:\\college\\sem-8\\dataset\\clean_dementia_dataset.csv\"\n",
    "\n",
    "    original_model, masked_model, pruned_model, masks, X_val = fnn_pruning_pipeline(\n",
    "        model_path=model_path,\n",
    "        dataset_path=dataset_path,\n",
    "        keep_ratio=0.8,\n",
    "        alpha=0.5, beta=0.3, gamma=0.2,\n",
    "        calib_batches=30, batch_size=64, ft_epochs=15\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9614c597",
   "metadata": {},
   "source": [
    "# **FNN pruned model save**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49defc4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: D:\\college\\sem-8\\models\\dementia_fnn_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Detected model type: binary\n",
      "Loading dataset: D:\\college\\sem-8\\dataset\\clean_dementia_dataset.csv\n",
      "[INFO] Loading CSV with automatic delimiter detection...\n",
      "[INFO] Columns detected: ['Age', 'EDUC', 'SES', 'MMSE', 'CDR', 'eTIV', 'nWBV', 'ASF', 'M/F_M', 'Group']\n",
      "[INFO] Auto-detected target column = Group\n",
      "Dense layers: ['dense_14', 'dense_15', 'dense_16', 'dense_17', 'dense_18', 'dense_19']\n",
      "Computing activation & gradient stats...\n",
      "dense_14 → kept 89/128\n",
      "dense_15 → kept 44/64\n",
      "dense_16 → kept 44/64\n",
      "dense_17 → kept 44/64\n",
      "dense_18 → kept 22/32\n",
      "dense_19 → kept 1/1\n",
      "Building masked model...\n",
      "WARNING:tensorflow:From c:\\Users\\Ishan\\Documents\\sample_p1\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Ishan\\Documents\\sample_p1\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning masked model...\n",
      "Epoch 1/3\n",
      "4/4 - 2s - 438ms/step - accuracy: 0.5973 - loss: 6.4902 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 2/3\n",
      "4/4 - 0s - 21ms/step - accuracy: 0.5928 - loss: 6.5623 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 3/3\n",
      "4/4 - 0s - 26ms/step - accuracy: 0.5928 - loss: 6.5631 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Building permanent pruned model...\n",
      "Fine-tuning pruned model...\n",
      "Epoch 1/3\n",
      "4/4 - 1s - 332ms/step - accuracy: 0.5928 - loss: 747.1626 - val_accuracy: 0.5938 - val_loss: 289.3863\n",
      "Epoch 2/3\n",
      "4/4 - 0s - 22ms/step - accuracy: 0.5566 - loss: 301.4309 - val_accuracy: 0.4062 - val_loss: 210.6923\n",
      "Epoch 3/3\n",
      "4/4 - 0s - 21ms/step - accuracy: 0.4434 - loss: 223.3150 - val_accuracy: 0.4062 - val_loss: 233.4635\n",
      "[INFO] Saving masked model to: D:\\college\\sem-8\\models\\dementia_fnn_model_masked.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving pruned model to: D:\\college\\sem-8\\models\\dementia_fnn_model_pruned.h5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FNN-only pruning pipeline (auto-detect model type).\n",
    "- Detects model type from final layer (binary / multiclass / regression).\n",
    "- Adapts CSV loader accordingly.\n",
    "- Keeps final layer intact (never pruned).\n",
    "- Reports FLOPs, GFLOPs, MFLOPs and inference time.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Helper: detect model type\n",
    "# -----------------------\n",
    "def detect_model_type(model):\n",
    "    out = model.layers[-1]\n",
    "    units = getattr(out, \"units\", None)\n",
    "    act = getattr(out, \"activation\", None)\n",
    "    act_name = act.__name__ if act is not None else None\n",
    "\n",
    "    if units == 1 and act_name == \"sigmoid\":\n",
    "        return \"binary\"\n",
    "    if units == 1 and act_name in (\"linear\", \"relu\", \"tanh\"):\n",
    "        return \"regression\"\n",
    "    if units is not None and units > 1 and act_name == \"softmax\":\n",
    "        return \"multiclass\"\n",
    "\n",
    "    # fallback\n",
    "    if units == 1:\n",
    "        return \"binary\"\n",
    "    if units and units > 1:\n",
    "        return \"multiclass\"\n",
    "\n",
    "    return \"unknown\"\n",
    "\n",
    "\n",
    "def get_loss_and_metrics_for_type(model_type):\n",
    "    if model_type == \"binary\":\n",
    "        return (\"binary_crossentropy\", [\"accuracy\"])\n",
    "    if model_type == \"multiclass\":\n",
    "        return (\"sparse_categorical_crossentropy\", [\"sparse_categorical_accuracy\"])\n",
    "    if model_type == \"regression\":\n",
    "        return (\"mse\", [\"mse\"])\n",
    "    raise ValueError(\"Unknown model type\")\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 1) UNIVERSAL CSV LOADER\n",
    "# =====================================================================\n",
    "def load_any_csv_dataset(csv_path, target=None, test_size=0.2, val_size=0.1, model_type=\"binary\"):\n",
    "    print(\"[INFO] Loading CSV with automatic delimiter detection...\")\n",
    "    df = pd.read_csv(csv_path, sep=None, engine=\"python\")\n",
    "    print(\"[INFO] Columns detected:\", list(df.columns))\n",
    "\n",
    "    if target is None:\n",
    "        target = df.columns[-1]\n",
    "        print(f\"[INFO] Auto-detected target column = {target}\")\n",
    "\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    # Process target\n",
    "    if model_type == \"binary\":\n",
    "        if y.dtype == object:\n",
    "            y = y.astype(str).str.strip().str.lower().replace(\n",
    "                {\"yes\": 1, \"no\": 0, \"true\": 1, \"false\": 0}\n",
    "            )\n",
    "        y = y.astype(np.float32).values.reshape(-1, 1)\n",
    "\n",
    "    elif model_type == \"multiclass\":\n",
    "        if y.dtype == object:\n",
    "            y = y.astype(\"category\").cat.codes\n",
    "        y = y.astype(np.int32).values.reshape(-1, 1)\n",
    "\n",
    "    elif model_type == \"regression\":\n",
    "        y = y.astype(np.float32).values.reshape(-1, 1)\n",
    "\n",
    "    cat_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "    if len(cat_cols) > 0:\n",
    "        print(\"[INFO] One-hot encoding:\", list(cat_cols))\n",
    "        X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    # Split\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=(test_size + val_size), random_state=42,\n",
    "        stratify=y if model_type != \"regression\" else None\n",
    "    )\n",
    "    val_ratio = val_size / (test_size + val_size)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=(1 - val_ratio), random_state=42,\n",
    "        stratify=y_temp if model_type != \"regression\" else None\n",
    "    )\n",
    "\n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 2) GET DENSE LAYERS\n",
    "# =====================================================================\n",
    "def get_dense_layers(model):\n",
    "    return [layer for layer in model.layers if isinstance(layer, Dense)]\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 3) ACTIVATION + GRADIENT STATS\n",
    "# =====================================================================\n",
    "def compute_activation_grad_stats(model, dense_layers, X, y, model_type,\n",
    "                                  batch_size=64, max_batches=30):\n",
    "\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.to_numpy()\n",
    "    if isinstance(y, (pd.DataFrame, pd.Series)):\n",
    "        y = y.to_numpy()\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, y)).batch(batch_size)\n",
    "\n",
    "    acc_A = {l.name: [] for l in dense_layers}\n",
    "    acc_G = {l.name: [] for l in dense_layers}\n",
    "    acc_V = {l.name: [] for l in dense_layers}\n",
    "\n",
    "    if model_type == \"binary\":\n",
    "        loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False, reduction=\"none\")\n",
    "    elif model_type == \"multiclass\":\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction=\"none\")\n",
    "    else:\n",
    "        loss_fn = tf.keras.losses.MeanSquaredError(reduction=\"none\")\n",
    "\n",
    "    batch_count = 0\n",
    "\n",
    "    for xb, yb in ds:\n",
    "        if batch_count >= max_batches:\n",
    "            break\n",
    "        batch_count += 1\n",
    "\n",
    "        x = tf.cast(xb, tf.float32)\n",
    "\n",
    "        if model_type == \"multiclass\":\n",
    "            yb_proc = tf.cast(tf.squeeze(yb, axis=-1), tf.int32)\n",
    "        else:\n",
    "            yb_proc = tf.cast(yb, tf.float32)\n",
    "\n",
    "        layer_outputs = {}\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            for layer in model.layers:\n",
    "                x = layer(x)\n",
    "                if layer in dense_layers:\n",
    "                    tape.watch(x)\n",
    "                    layer_outputs[layer.name] = x\n",
    "\n",
    "            preds = x\n",
    "            per_sample_loss = loss_fn(yb_proc, preds)\n",
    "            loss = tf.reduce_mean(per_sample_loss)\n",
    "\n",
    "        for layer in dense_layers:\n",
    "            name = layer.name\n",
    "            a = layer_outputs[name]\n",
    "            A = tf.reduce_mean(tf.abs(a), axis=0).numpy()\n",
    "            V = tf.math.reduce_variance(a, axis=0).numpy()\n",
    "\n",
    "            g = tape.gradient(loss, a)\n",
    "            G = np.zeros_like(A) if g is None else tf.reduce_mean(tf.abs(g), axis=0).numpy()\n",
    "\n",
    "            acc_A[name].append(A)\n",
    "            acc_G[name].append(G)\n",
    "            acc_V[name].append(V)\n",
    "\n",
    "        del tape\n",
    "\n",
    "    stats = {}\n",
    "    for layer in dense_layers:\n",
    "        name = layer.name\n",
    "        if len(acc_A[name]) == 0:\n",
    "            stats[name] = (np.array([]), np.array([]), np.array([]))\n",
    "        else:\n",
    "            stats[name] = (\n",
    "                np.mean(np.stack(acc_A[name]), axis=0),\n",
    "                np.mean(np.stack(acc_G[name]), axis=0),\n",
    "                np.mean(np.stack(acc_V[name]), axis=0)\n",
    "            )\n",
    "\n",
    "    return stats\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 4) IMPORTANCE MASK\n",
    "# =====================================================================\n",
    "def compute_importance_mask(stats, keep_ratio=0.7,\n",
    "                            alpha=0.5, beta=0.3, gamma=0.2,\n",
    "                            last_dense_name=None, min_units=4):\n",
    "\n",
    "    masks = {}\n",
    "\n",
    "    for name, (A, G, V) in stats.items():\n",
    "\n",
    "        if A.size == 0:\n",
    "            masks[name] = np.array([], dtype=np.float32)\n",
    "            continue\n",
    "\n",
    "        def normalize(x):\n",
    "            x2 = x - np.min(x)\n",
    "            mx = np.max(x2)\n",
    "            return x2 / (mx + 1e-12)\n",
    "\n",
    "        score = alpha * normalize(A) + beta * normalize(G) + gamma * normalize(V)\n",
    "\n",
    "        if last_dense_name is not None and name == last_dense_name:\n",
    "            masks[name] = np.ones_like(score, dtype=np.float32)\n",
    "            continue\n",
    "\n",
    "        k = max(int(len(score) * keep_ratio), min_units)\n",
    "        k = min(k, len(score))\n",
    "\n",
    "        if np.all(score == 0):\n",
    "            sel = np.random.choice(len(score), k, replace=False)\n",
    "            mask = np.zeros_like(score)\n",
    "            mask[sel] = 1\n",
    "            masks[name] = mask\n",
    "            continue\n",
    "\n",
    "        thresh = np.partition(score, -k)[-k]\n",
    "        mask = (score >= thresh).astype(np.float32)\n",
    "\n",
    "        if np.sum(mask) < min_units:\n",
    "            topk = np.argsort(score)[-min_units:]\n",
    "            mask = np.zeros_like(score)\n",
    "            mask[topk] = 1\n",
    "\n",
    "        masks[name] = mask\n",
    "\n",
    "    return masks\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 5) DNAGate Layer\n",
    "# =====================================================================\n",
    "class DNAGate(tf.keras.layers.Layer):\n",
    "    def __init__(self, gate, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.gate_init = np.array(gate, dtype=np.float32)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.gate = self.add_weight(\n",
    "            name=\"gate\",\n",
    "            shape=self.gate_init.shape,\n",
    "            initializer=tf.constant_initializer(self.gate_init),\n",
    "            trainable=False\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs * self.gate\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"gate\": self.gate.numpy().tolist()})\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        gate = config.pop(\"gate\")\n",
    "        return cls(gate=gate, **config)\n",
    "\n",
    "\n",
    "def build_masked_model(orig_model, masks):\n",
    "    inp = Input(shape=orig_model.input_shape[1:])\n",
    "    x = inp\n",
    "\n",
    "    for layer in orig_model.layers:\n",
    "        x = layer(x)\n",
    "        if layer.name in masks:\n",
    "            x = DNAGate(gate=masks[layer.name], name=layer.name + \"_dna\")(x)\n",
    "\n",
    "    new_model = Model(inp, x)\n",
    "\n",
    "    for l in orig_model.layers:\n",
    "        try:\n",
    "            new_model.get_layer(l.name).set_weights(l.get_weights())\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return new_model\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 6) FLOPS + INFERENCE TIME\n",
    "# =====================================================================\n",
    "def dense_flops(in_size, out_size, bias=True):\n",
    "    return int(in_size * out_size * 2 + (out_size if bias else 0))\n",
    "\n",
    "def model_flops(model):\n",
    "    total = 0\n",
    "    in_size = int(model.input_shape[1])\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, Dense):\n",
    "            total += dense_flops(in_size, layer.units, layer.use_bias)\n",
    "            in_size = layer.units\n",
    "    return total\n",
    "\n",
    "def effective_flops(model, masks):\n",
    "    total = 0\n",
    "    in_size = int(model.input_shape[1])\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, Dense):\n",
    "            units = np.sum(masks[layer.name]) if layer.name in masks else layer.units\n",
    "            total += dense_flops(in_size, int(units), layer.use_bias)\n",
    "            in_size = int(units)\n",
    "    return total\n",
    "\n",
    "def flops_to_gflops(f): return f / 1e9\n",
    "def flops_to_mflops(f): return f / 1e6\n",
    "\n",
    "\n",
    "def measure_inference_time(model, X, runs=200):\n",
    "\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X = X.to_numpy()\n",
    "\n",
    "    if len(X) == 0:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    idx = np.random.randint(0, len(X), size=min(runs, len(X)))\n",
    "    samples = X[idx]\n",
    "\n",
    "    model.predict(samples[:1], verbose=0)\n",
    "    t0 = time.time()\n",
    "    model.predict(samples, verbose=0)\n",
    "    t1 = time.time()\n",
    "\n",
    "    return (t1 - t0) * 1000 / len(samples)\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 7) STRUCTURAL PRUNING\n",
    "# =====================================================================\n",
    "def structurally_prune_fnn(orig_model, masks, last_dense_name=None):\n",
    "\n",
    "    inp = Input(shape=orig_model.input_shape[1:])\n",
    "    x = inp\n",
    "    prev_sel = None\n",
    "\n",
    "    for layer in orig_model.layers:\n",
    "\n",
    "        if isinstance(layer, Dense):\n",
    "            W, b = layer.get_weights()\n",
    "\n",
    "            if prev_sel is not None:\n",
    "                W = W[prev_sel, :]\n",
    "\n",
    "            if last_dense_name and layer.name == last_dense_name:\n",
    "                sel = np.arange(layer.units)\n",
    "            else:\n",
    "                mask = masks.get(layer.name, None)\n",
    "                if mask is None or mask.size == 0:\n",
    "                    sel = None\n",
    "                else:\n",
    "                    sel = np.where(mask == 1)[0]\n",
    "                    if len(sel) == 0:\n",
    "                        sel = np.array([np.argmax(mask)])\n",
    "\n",
    "            if sel is not None:\n",
    "                W_new = W[:, sel]\n",
    "                b_new = b[sel]\n",
    "                units_new = len(sel)\n",
    "            else:\n",
    "                W_new, b_new = W, b\n",
    "                units_new = W.shape[1]\n",
    "\n",
    "            new_layer = Dense(units_new, activation=layer.activation, name=layer.name)\n",
    "            x = new_layer(x)\n",
    "            new_layer.set_weights([W_new, b_new])\n",
    "\n",
    "            prev_sel = sel\n",
    "\n",
    "        else:\n",
    "            x = layer(x)\n",
    "\n",
    "    return Model(inp, x)\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 8) MAIN PIPELINE\n",
    "# =====================================================================\n",
    "def fnn_pruning_pipeline(model_path, dataset_path,\n",
    "                         keep_ratio=0.7,\n",
    "                         alpha=0.5, beta=0.3, gamma=0.2,\n",
    "                         calib_batches=30, batch_size=64, ft_epochs=3):\n",
    "\n",
    "    print(\"Loading model:\", model_path)\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    model_type = detect_model_type(model)\n",
    "    print(f\"[INFO] Detected model type: {model_type}\")\n",
    "\n",
    "    loss_name, metrics = get_loss_and_metrics_for_type(model_type)\n",
    "\n",
    "    print(\"Loading dataset:\", dataset_path)\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = load_any_csv_dataset(\n",
    "        dataset_path, model_type=model_type\n",
    "    )\n",
    "\n",
    "    dense_layers = get_dense_layers(model)\n",
    "    last_dense_name = dense_layers[-1].name if dense_layers else None\n",
    "    print(\"Dense layers:\", [l.name for l in dense_layers])\n",
    "\n",
    "    print(\"Computing activation & gradient stats...\")\n",
    "    stats = compute_activation_grad_stats(\n",
    "        model, dense_layers, X_train, y_train, model_type,\n",
    "        batch_size=batch_size, max_batches=calib_batches\n",
    "    )\n",
    "\n",
    "    masks = compute_importance_mask(\n",
    "        stats, keep_ratio, alpha, beta, gamma, last_dense_name\n",
    "    )\n",
    "\n",
    "    for k, v in masks.items():\n",
    "        if v.size > 0:\n",
    "            print(f\"{k} → kept {int(np.sum(v))}/{len(v)}\")\n",
    "\n",
    "    # ============================================================\n",
    "    # MASKED MODEL\n",
    "    # ============================================================\n",
    "    print(\"Building masked model...\")\n",
    "    masked_model = build_masked_model(model, masks)\n",
    "    masked_model.compile(optimizer=\"adam\", loss=loss_name, metrics=metrics)\n",
    "\n",
    "    print(\"Fine-tuning masked model...\")\n",
    "    masked_model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                     epochs=ft_epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "    # ============================================================\n",
    "    # STRUCTURAL PRUNING\n",
    "    # ============================================================\n",
    "    print(\"Building permanent pruned model...\")\n",
    "    pruned_model = structurally_prune_fnn(model, masks, last_dense_name)\n",
    "    pruned_model.compile(optimizer=\"adam\", loss=loss_name, metrics=metrics)\n",
    "\n",
    "    print(\"Fine-tuning pruned model...\")\n",
    "    pruned_model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
    "                     epochs=ft_epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "    # ============================================================\n",
    "    # SAVE MODELS\n",
    "    # ============================================================\n",
    "    import os\n",
    "\n",
    "    base = os.path.basename(model_path)\n",
    "    root = os.path.splitext(base)[0]\n",
    "    folder = os.path.dirname(model_path)\n",
    "\n",
    "    masked_path = os.path.join(folder, root + \"_masked.h5\")\n",
    "    pruned_path = os.path.join(folder, root + \"_pruned.h5\")\n",
    "\n",
    "    print(f\"[INFO] Saving masked model to: {masked_path}\")\n",
    "    masked_model.save(masked_path)\n",
    "\n",
    "    print(f\"[INFO] Saving pruned model to: {pruned_path}\")\n",
    "    pruned_model.save(pruned_path)\n",
    "\n",
    "    return model, masked_model, pruned_model, masks, X_val\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# 9) RUN\n",
    "# =====================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = r\"D:\\college\\sem-8\\models\\dementia_fnn_model.h5\"\n",
    "    dataset_path = r\"D:\\college\\sem-8\\dataset\\clean_dementia_dataset.csv\"\n",
    "\n",
    "    original_model, masked_model, pruned_model, masks, X_val = fnn_pruning_pipeline(\n",
    "        model_path=model_path,\n",
    "        dataset_path=dataset_path,\n",
    "        keep_ratio=0.7,\n",
    "        alpha=0.5, beta=0.3, gamma=0.2,\n",
    "        calib_batches=30, batch_size=64, ft_epochs=3\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef37ee5",
   "metadata": {},
   "source": [
    "# **Main FNN Prune Model Saved with Flops and Gflops**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "356388b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: D:\\college\\sem-8\\models\\dementia_fnn_model.h5\n",
      "[INFO] Detected model type: binary\n",
      "[INFO] Using loss='binary_crossentropy', metrics=['accuracy']\n",
      "Loading dataset: D:\\college\\sem-8\\dataset\\clean_dementia_dataset.csv\n",
      "[INFO] Loading CSV with automatic delimiter detection...\n",
      "[INFO] Columns detected: ['Age', 'EDUC', 'SES', 'MMSE', 'CDR', 'eTIV', 'nWBV', 'ASF', 'M/F_M', 'Group']\n",
      "[INFO] Auto-detected target column = Group\n",
      "[INFO] No categorical predictor columns to encode.\n",
      "Dense layers: ['dense_14', 'dense_15', 'dense_16', 'dense_17', 'dense_18', 'dense_19'] | last_dense: dense_19\n",
      "Computing activation & gradient stats...\n",
      "dense_14 -> kept units: 102/128\n",
      "dense_15 -> kept units: 51/64\n",
      "dense_16 -> kept units: 51/64\n",
      "dense_17 -> kept units: 51/64\n",
      "dense_18 -> kept units: 25/32\n",
      "dense_19 -> kept units: 1/1\n",
      "Building masked model (DNAGate zeroing)...\n",
      "Baseline Acc: 0.59375 | FLOPS: 39585\n",
      "Masked Acc (before FT): 0.59375 | Effective FLOPS: 25525\n",
      "Fine-tuning masked model...\n",
      "Epoch 1/15\n",
      "4/4 - 2s - 408ms/step - accuracy: 0.6244 - loss: 6.0117 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 2/15\n",
      "4/4 - 0s - 22ms/step - accuracy: 0.5928 - loss: 6.5584 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 3/15\n",
      "4/4 - 0s - 26ms/step - accuracy: 0.5973 - loss: 6.4761 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 4/15\n",
      "4/4 - 0s - 20ms/step - accuracy: 0.5701 - loss: 6.8838 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 5/15\n",
      "4/4 - 0s - 25ms/step - accuracy: 0.6154 - loss: 6.1913 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 6/15\n",
      "4/4 - 0s - 21ms/step - accuracy: 0.6290 - loss: 5.9087 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 7/15\n",
      "4/4 - 0s - 20ms/step - accuracy: 0.5973 - loss: 6.4561 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 8/15\n",
      "4/4 - 0s - 20ms/step - accuracy: 0.5973 - loss: 6.4719 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 9/15\n",
      "4/4 - 0s - 23ms/step - accuracy: 0.5973 - loss: 6.4910 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 10/15\n",
      "4/4 - 0s - 21ms/step - accuracy: 0.6018 - loss: 6.4181 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 11/15\n",
      "4/4 - 0s - 27ms/step - accuracy: 0.5973 - loss: 6.4910 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 12/15\n",
      "4/4 - 0s - 23ms/step - accuracy: 0.5973 - loss: 6.4910 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 13/15\n",
      "4/4 - 0s - 23ms/step - accuracy: 0.5973 - loss: 6.4910 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 14/15\n",
      "4/4 - 0s - 21ms/step - accuracy: 0.5973 - loss: 6.4910 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Epoch 15/15\n",
      "4/4 - 0s - 21ms/step - accuracy: 0.5973 - loss: 6.4910 - val_accuracy: 0.5938 - val_loss: 6.5480\n",
      "Constructing structurally-pruned model (remove neurons)...\n",
      "Fine-tuning pruned model...\n",
      "Epoch 1/15\n",
      "4/4 - 3s - 807ms/step - accuracy: 0.5973 - loss: 962.8984 - val_accuracy: 0.5938 - val_loss: 501.8147\n",
      "Epoch 2/15\n",
      "4/4 - 0s - 18ms/step - accuracy: 0.6199 - loss: 409.1724 - val_accuracy: 0.5312 - val_loss: 3.0252\n",
      "Epoch 3/15\n",
      "4/4 - 0s - 22ms/step - accuracy: 0.5113 - loss: 216.9611 - val_accuracy: 0.4062 - val_loss: 236.7726\n",
      "Epoch 4/15\n",
      "4/4 - 0s - 19ms/step - accuracy: 0.4570 - loss: 217.6302 - val_accuracy: 0.4062 - val_loss: 200.1623\n",
      "Epoch 5/15\n",
      "4/4 - 0s - 20ms/step - accuracy: 0.5385 - loss: 153.3853 - val_accuracy: 0.4062 - val_loss: 120.0289\n",
      "Epoch 6/15\n",
      "4/4 - 0s - 20ms/step - accuracy: 0.4570 - loss: 122.6667 - val_accuracy: 0.4062 - val_loss: 55.7780\n",
      "Epoch 7/15\n",
      "4/4 - 0s - 21ms/step - accuracy: 0.4480 - loss: 121.0288 - val_accuracy: 0.4062 - val_loss: 7.2710\n",
      "Epoch 8/15\n",
      "4/4 - 0s - 21ms/step - accuracy: 0.5294 - loss: 97.6969 - val_accuracy: 0.5938 - val_loss: 3.6239\n",
      "Epoch 9/15\n",
      "4/4 - 0s - 21ms/step - accuracy: 0.5023 - loss: 73.5304 - val_accuracy: 0.5938 - val_loss: 6.3570\n",
      "Epoch 10/15\n",
      "4/4 - 0s - 20ms/step - accuracy: 0.5837 - loss: 58.8665 - val_accuracy: 0.5938 - val_loss: 5.5571\n",
      "Epoch 11/15\n",
      "4/4 - 0s - 22ms/step - accuracy: 0.4525 - loss: 63.2512 - val_accuracy: 0.5938 - val_loss: 5.3491\n",
      "Epoch 12/15\n",
      "4/4 - 0s - 19ms/step - accuracy: 0.5656 - loss: 35.1923 - val_accuracy: 0.5938 - val_loss: 6.3662\n",
      "Epoch 13/15\n",
      "4/4 - 0s - 24ms/step - accuracy: 0.4796 - loss: 40.6481 - val_accuracy: 0.5938 - val_loss: 7.6285\n",
      "Epoch 14/15\n",
      "4/4 - 0s - 17ms/step - accuracy: 0.5249 - loss: 32.2718 - val_accuracy: 0.5938 - val_loss: 9.4576\n",
      "Epoch 15/15\n",
      "4/4 - 0s - 30ms/step - accuracy: 0.4796 - loss: 28.8690 - val_accuracy: 0.5938 - val_loss: 11.2391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FINAL REPORT ===\n",
      "Model type: binary\n",
      "Baseline:   Acc/metric=0.59375 | FLOPS=39585 | MFLOPS=0.039585 | GFLOPS=0.0000395850 | Time=3.1087 ms/sample\n",
      "Masked:     Acc/metric=0.59375 | EFLOPS=25525 | MFLOPS=0.025525 | GFLOPS=0.0000255250 | Time=3.4252 ms/sample\n",
      "Pruned:     Acc/metric=0.59375 | FLOPS=25525 | MFLOPS=0.025525 | GFLOPS=0.0000255250 | Time=3.1285 ms/sample\n",
      "FLOPS reduction (pruned): 35.52%\n",
      "==============================================\n",
      "\n",
      "Pruned:     Acc/metric=0.59375 | FLOPS=25525 | MFLOPS=0.025525 | GFLOPS=0.0000255250 | Time=3.1285 ms/sample\n",
      "FLOPS reduction (pruned): 35.52%\n",
      "GFLOPS reduction (pruned): 35.52%\n",
      "Accuracy reduction: 0.0\n",
      "==============================================\n",
      "\n",
      "[INFO] Saving masked model to: D:\\college\\sem-8\\models\\dementia_fnn_model_masked.h5\n",
      "[INFO] Saving pruned model to: D:\\college\\sem-8\\models\\dementia_fnn_model_pruned.h5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FNN-only pruning pipeline (auto-detect model type).\n",
    "- Detects model type from final layer (binary / multiclass / regression).\n",
    "- Adapts CSV loader accordingly.\n",
    "- Keeps final layer intact (never pruned).\n",
    "- Reports FLOPs, GFLOPs, MFLOPS and inference time.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "# -----------------------\n",
    "# Helper: detect model type\n",
    "# -----------------------\n",
    "def detect_model_type(model):\n",
    "    out = model.layers[-1]\n",
    "    units = getattr(out, \"units\", None)\n",
    "    act = getattr(out, \"activation\", None)\n",
    "    act_name = act.__name__ if act is not None else None\n",
    "\n",
    "    if units == 1 and act_name in (\"sigmoid\",):\n",
    "        return \"binary\"\n",
    "    if units == 1 and act_name in (\"linear\", \"relu\", \"tanh\"):\n",
    "        return \"regression\"\n",
    "    if units is not None and units > 1 and act_name == \"softmax\":\n",
    "        return \"multiclass\"\n",
    "    # fallback tries\n",
    "    if units == 1:\n",
    "        return \"binary\"\n",
    "    if units and units > 1:\n",
    "        return \"multiclass\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def get_loss_and_metrics_for_type(model_type):\n",
    "    if model_type == \"binary\":\n",
    "        return (\"binary_crossentropy\", [\"accuracy\"])\n",
    "    if model_type == \"multiclass\":\n",
    "        # use sparse labels to avoid forcing one-hot encoding\n",
    "        return (\"sparse_categorical_crossentropy\", [\"sparse_categorical_accuracy\"])\n",
    "    if model_type == \"regression\":\n",
    "        return (\"mse\", [\"mse\"])\n",
    "    raise ValueError(\"Unknown model type\")\n",
    "\n",
    "# =====================================================================\n",
    "# 1) UNIVERSAL CSV LOADER  (adapts target based on model_type)\n",
    "# =====================================================================\n",
    "def load_any_csv_dataset(csv_path, target=None, test_size=0.2, val_size=0.1, model_type=\"binary\"):\n",
    "    \"\"\"\n",
    "    Loads CSV (auto-detect delimiter). Adapts target processing to model_type:\n",
    "      - binary/regression: returns y as float32 shaped (n,1)\n",
    "      - multiclass: returns integer labels shaped (n,1) for sparse loss\n",
    "    \"\"\"\n",
    "    print(\"[INFO] Loading CSV with automatic delimiter detection...\")\n",
    "    df = pd.read_csv(csv_path, sep=None, engine=\"python\")\n",
    "    print(\"[INFO] Columns detected:\", list(df.columns))\n",
    "\n",
    "    if target is None:\n",
    "        target = df.columns[-1]\n",
    "        print(f\"[INFO] Auto-detected target column = {target}\")\n",
    "\n",
    "    if target not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target}' not found in dataset!\")\n",
    "\n",
    "    y = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    # Preprocess target based on model_type\n",
    "    if model_type == \"binary\":\n",
    "        # convert yes/no/true/false -> 1/0\n",
    "        if y.dtype == object:\n",
    "            y = y.astype(str).str.strip().str.lower()\n",
    "            y = y.replace({\"yes\": 1, \"no\": 0, \"true\": 1, \"false\": 0})\n",
    "        # ensure numeric\n",
    "        y = y.astype(np.float32).values.reshape(-1, 1)\n",
    "\n",
    "    elif model_type == \"multiclass\":\n",
    "        # convert strings to categorical integer codes if needed\n",
    "        if y.dtype == object:\n",
    "            y = y.astype(\"category\").cat.codes\n",
    "        # ensure integer labels (sparse labels)\n",
    "        y = y.astype(np.int32).values.reshape(-1, 1)\n",
    "\n",
    "    elif model_type == \"regression\":\n",
    "        # numeric continuous\n",
    "        y = y.astype(np.float32).values.reshape(-1, 1)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model_type for loader\")\n",
    "\n",
    "    # One-hot encode only categorical predictors (keep numeric as-is)\n",
    "    cat_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "    if len(cat_cols) > 0:\n",
    "        print(\"[INFO] One-hot encoding predictors:\", list(cat_cols))\n",
    "        X = pd.get_dummies(X, drop_first=True)\n",
    "    else:\n",
    "        print(\"[INFO] No categorical predictor columns to encode.\")\n",
    "\n",
    "    # convert to float32 (features)\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    # Split\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, test_size=(test_size + val_size), random_state=42, stratify=y if model_type!=\"regression\" else None\n",
    "    )\n",
    "    # second split into val/test\n",
    "    val_ratio = val_size / (test_size + val_size)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=(1 - val_ratio), random_state=42,\n",
    "        stratify=y_temp if model_type!=\"regression\" else None\n",
    "    )\n",
    "\n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "\n",
    "# =====================================================================\n",
    "# 2) GET DENSE LAYERS\n",
    "# =====================================================================\n",
    "def get_dense_layers(model):\n",
    "    return [layer for layer in model.layers if isinstance(layer, Dense)]\n",
    "\n",
    "# =====================================================================\n",
    "# 3) ACTIVATION + GRADIENT STATS  (SHAPE-SAFE)\n",
    "# =====================================================================\n",
    "def compute_activation_grad_stats(model, dense_layers, X, y, model_type,\n",
    "                                  batch_size=64, max_batches=30):\n",
    "    \"\"\"\n",
    "    Returns stats dict: {layer.name: (A_mean_per_neuron, G_mean_per_neuron, Var_per_neuron)}\n",
    "    Uses appropriate loss for model_type when computing gradients.\n",
    "    \"\"\"\n",
    "    # Convert X,y to numpy if DataFrame\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X_np = X.to_numpy()\n",
    "    else:\n",
    "        X_np = X\n",
    "    if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):\n",
    "        y_np = y.to_numpy()\n",
    "    else:\n",
    "        y_np = y\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X_np, y_np)).batch(batch_size)\n",
    "    acc_A = {l.name: [] for l in dense_layers}\n",
    "    acc_G = {l.name: [] for l in dense_layers}\n",
    "    acc_V = {l.name: [] for l in dense_layers}\n",
    "\n",
    "    # choose loss for gradient computation\n",
    "    if model_type == \"binary\":\n",
    "        loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False, reduction=tf.keras.losses.Reduction.NONE)\n",
    "    elif model_type == \"multiclass\":\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction=tf.keras.losses.Reduction.NONE)\n",
    "    elif model_type == \"regression\":\n",
    "        loss_fn = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model_type for stats\")\n",
    "\n",
    "    batch_count = 0\n",
    "    for xb, yb in ds:\n",
    "        if batch_count >= max_batches:\n",
    "            break\n",
    "        batch_count += 1\n",
    "\n",
    "        # ensure shapes consistent\n",
    "        x = tf.cast(xb, tf.float32)\n",
    "        # For sparse multiclass loss, yb should be shape (batch,) ints\n",
    "        if model_type == \"multiclass\":\n",
    "            yb_proc = tf.cast(tf.squeeze(yb, axis=-1), tf.int32)\n",
    "        else:\n",
    "            # binary/regression: keep shape (batch,1) as float32\n",
    "            yb_proc = tf.cast(yb, tf.float32)\n",
    "\n",
    "        layer_outputs = {}\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            for layer in model.layers:\n",
    "                x = layer(x)\n",
    "                if layer in dense_layers:\n",
    "                    tape.watch(x)\n",
    "                    layer_outputs[layer.name] = x\n",
    "            preds = x\n",
    "            # compute per-sample loss (shape [batch,] or [batch, ...])\n",
    "            per_sample_loss = loss_fn(yb_proc, preds)\n",
    "            # compute scalar loss for gradient direction\n",
    "            loss = tf.reduce_mean(per_sample_loss)\n",
    "\n",
    "        for layer in dense_layers:\n",
    "            name = layer.name\n",
    "            if name not in layer_outputs:\n",
    "                continue\n",
    "            a = layer_outputs[name]            # shape (batch, units)\n",
    "            A = tf.reduce_mean(tf.abs(a), axis=0).numpy()\n",
    "            V = tf.math.reduce_variance(a, axis=0).numpy()\n",
    "\n",
    "            g = tape.gradient(loss, a)\n",
    "            if g is None:\n",
    "                G = np.zeros_like(A)\n",
    "            else:\n",
    "                G = tf.reduce_mean(tf.abs(g), axis=0).numpy()\n",
    "\n",
    "            acc_A[name].append(A)\n",
    "            acc_G[name].append(G)\n",
    "            acc_V[name].append(V)\n",
    "\n",
    "        del tape\n",
    "\n",
    "    # Aggregate\n",
    "    stats = {}\n",
    "    for layer in dense_layers:\n",
    "        name = layer.name\n",
    "        if len(acc_A[name]) == 0:\n",
    "            stats[name] = (np.array([]), np.array([]), np.array([]))\n",
    "            continue\n",
    "        A = np.mean(np.stack(acc_A[name], axis=0), axis=0)\n",
    "        G = np.mean(np.stack(acc_G[name], axis=0), axis=0)\n",
    "        V = np.mean(np.stack(acc_V[name], axis=0), axis=0)\n",
    "        stats[name] = (A, G, V)\n",
    "\n",
    "    return stats\n",
    "\n",
    "# =====================================================================\n",
    "# 4) IMPORTANCE MASKS (protect last Dense layer)\n",
    "# =====================================================================\n",
    "def compute_importance_mask(\n",
    "        stats,\n",
    "        keep_ratio=0.7,\n",
    "        alpha=0.5,\n",
    "        beta=0.3,\n",
    "        gamma=0.2,\n",
    "        last_dense_name=None,\n",
    "        min_units=4  # <-- increase minimum neurons per layer\n",
    "    ):\n",
    "    \n",
    "    masks = {}\n",
    "    for name, (A, G, V) in stats.items():\n",
    "        if A.size == 0:\n",
    "            masks[name] = np.array([], dtype=np.float32)\n",
    "            continue\n",
    "\n",
    "        def normalize(x):\n",
    "            x2 = x - np.min(x)\n",
    "            mx = np.max(x2)\n",
    "            return x2 / (mx + 1e-12)\n",
    "\n",
    "        # compute score\n",
    "        score = alpha * normalize(A) + beta * normalize(G) + gamma * normalize(V)\n",
    "\n",
    "        # ---- NEVER prune final Dense layer ----\n",
    "        if last_dense_name is not None and name == last_dense_name:\n",
    "            masks[name] = np.ones_like(score, dtype=np.float32)\n",
    "            continue\n",
    "\n",
    "        # ---- compute K ----\n",
    "        k = int(len(score) * keep_ratio)\n",
    "        k = max(k, min_units)        # enforce minimum\n",
    "        k = min(k, len(score))       # safety\n",
    "\n",
    "        # ---- If all scores are zero → randomly pick k neurons ----\n",
    "        if np.all(score == 0):\n",
    "            sel = np.random.choice(len(score), size=k, replace=False)\n",
    "            mask = np.zeros_like(score)\n",
    "            mask[sel] = 1\n",
    "            masks[name] = mask.astype(np.float32)\n",
    "            continue\n",
    "\n",
    "        # normal path\n",
    "        thresh = np.partition(score, -k)[-k]\n",
    "        mask = (score >= thresh).astype(np.float32)\n",
    "\n",
    "        # final safety: ensure >= min_units survive\n",
    "        if np.sum(mask) < min_units:\n",
    "            topk = np.argsort(score)[-min_units:]\n",
    "            mask = np.zeros_like(score)\n",
    "            mask[topk] = 1\n",
    "\n",
    "        masks[name] = mask.astype(np.float32)\n",
    "\n",
    "    return masks\n",
    "\n",
    "# =====================================================================\n",
    "# 5) DNAGate Layer (Zeroing)\n",
    "# =====================================================================\n",
    "# =====================================================================\n",
    "# 5) DNAGate Layer (Zeroing) — NOW FULLY SERIALIZABLE\n",
    "# =====================================================================\n",
    "class DNAGate(tf.keras.layers.Layer):\n",
    "    def __init__(self, mask=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        # store original numpy mask (for config saving)\n",
    "        self._mask_np = None\n",
    "        if mask is not None:\n",
    "            self._mask_np = np.array(mask, dtype=np.float32)\n",
    "\n",
    "        # keras-serializable field (converted to list)\n",
    "        self.mask_list = self._mask_np.tolist() if self._mask_np is not None else None\n",
    "        self.mask = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self.mask_list is None:\n",
    "            self.mask = None\n",
    "        else:\n",
    "            # rebuild tensor mask\n",
    "            mask_np = np.array(self.mask_list, dtype=np.float32)\n",
    "            if input_shape[-1] != mask_np.shape[0]:\n",
    "                raise ValueError(\n",
    "                    f\"DNAGate mask length {mask_np.shape[0]} != layer units {input_shape[-1]}\"\n",
    "                )\n",
    "            self.mask = tf.constant(mask_np, dtype=self.dtype)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        if self.mask is None:\n",
    "            return x\n",
    "        return x * self.mask\n",
    "\n",
    "    # ⭐⭐ IMPORTANT — MAKES THE LAYER SAVEABLE ⭐⭐\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"mask\": self.mask_list,   # store mask as list\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # mask list gets restored automatically\n",
    "        return cls(**config)\n",
    "\n",
    "def build_masked_model(orig_model, masks):\n",
    "    inp = Input(shape=orig_model.input_shape[1:])\n",
    "    x = inp\n",
    "    for layer in orig_model.layers:\n",
    "        x = layer(x)\n",
    "        if layer.name in masks:\n",
    "            x = DNAGate(mask=masks[layer.name], name=layer.name + \"_dna\")(x)\n",
    "    new_model = Model(inp, x)\n",
    "    # copy weights where possible\n",
    "    for l in orig_model.layers:\n",
    "        try:\n",
    "            new_model.get_layer(l.name).set_weights(l.get_weights())\n",
    "        except Exception:\n",
    "            pass\n",
    "    return new_model\n",
    "\n",
    "# =====================================================================\n",
    "# 6) FLOPS + INFERENCE TIME\n",
    "# =====================================================================\n",
    "def dense_flops(in_size, out_size, bias=True):\n",
    "    # multiply-adds counted as 2 ops per MAC\n",
    "    return int(in_size * out_size * 2 + (out_size if bias else 0))\n",
    "\n",
    "def model_flops(model):\n",
    "    total = 0\n",
    "    in_size = int(model.input_shape[1])\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, Dense):\n",
    "            total += dense_flops(in_size, layer.units, layer.use_bias)\n",
    "            in_size = layer.units\n",
    "    return total\n",
    "\n",
    "def effective_flops(model, masks):\n",
    "    total = 0\n",
    "    in_size = int(model.input_shape[1])\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, Dense):\n",
    "            if layer.name in masks and masks[layer.name].size > 0:\n",
    "                units = int(np.sum(masks[layer.name]))\n",
    "            else:\n",
    "                units = layer.units\n",
    "            total += dense_flops(in_size, units, layer.use_bias)\n",
    "            in_size = units\n",
    "    return total\n",
    "\n",
    "def flops_to_gflops(f):\n",
    "    return f / 1e9\n",
    "\n",
    "def flops_to_mflops(f):\n",
    "    return f / 1e6\n",
    "\n",
    "def measure_inference_time(model, X, runs=200):\n",
    "    \"\"\"Return average inference time in milliseconds per sample.\n",
    "       Accepts X as pandas DataFrame or numpy array.\"\"\"\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X_np = X.to_numpy()\n",
    "    else:\n",
    "        X_np = X\n",
    "    if len(X_np) == 0:\n",
    "        return float(\"nan\")\n",
    "    # pick random indices\n",
    "    idx = np.random.randint(0, len(X_np), size=min(runs, len(X_np)))\n",
    "    samples = X_np[idx]\n",
    "    # warm-up single predict\n",
    "    model.predict(samples[:1], verbose=0)\n",
    "    t0 = time.time()\n",
    "    model.predict(samples, verbose=0)\n",
    "    t1 = time.time()\n",
    "    total_ms = (t1 - t0) * 1000.0\n",
    "    return total_ms / len(samples)\n",
    "\n",
    "# =====================================================================\n",
    "# 7) STRUCTURAL PRUNING (REMOVE NEURONS) — protect final Dense layer\n",
    "# =====================================================================\n",
    "def structurally_prune_fnn(orig_model, masks, last_dense_name=None):\n",
    "    inp = Input(shape=orig_model.input_shape[1:])\n",
    "    x = inp\n",
    "    prev_sel = None\n",
    "\n",
    "    for layer in orig_model.layers:\n",
    "        if isinstance(layer, Dense):\n",
    "            W, b = layer.get_weights()\n",
    "\n",
    "            # If previous layer was pruned → prune rows\n",
    "            if prev_sel is not None:\n",
    "                W = W[prev_sel, :]\n",
    "\n",
    "            # ---- SAFETY: determine neurons to keep ----\n",
    "            if last_dense_name is not None and layer.name == last_dense_name:\n",
    "                # never prune final layer\n",
    "                sel = np.arange(layer.units)\n",
    "\n",
    "            else:\n",
    "                mask = masks.get(layer.name, None)\n",
    "                if mask is not None and mask.size > 0:\n",
    "                    sel = np.where(mask == 1)[0]\n",
    "\n",
    "                    # 💥 SAFETY FIX: ensure >=1 neuron survives\n",
    "                    if len(sel) == 0:\n",
    "                        sel = np.array([np.argmax(mask)])  \n",
    "                else:\n",
    "                    sel = None\n",
    "\n",
    "            # ---- Apply pruning ----\n",
    "            if sel is not None:\n",
    "                W_new = W[:, sel]\n",
    "                b_new = b[sel]\n",
    "                new_units = len(sel)\n",
    "            else:\n",
    "                W_new = W\n",
    "                b_new = b\n",
    "                new_units = W.shape[1]\n",
    "\n",
    "            new_layer = Dense(new_units, activation=layer.activation, name=layer.name)\n",
    "            x = new_layer(x)\n",
    "            new_layer.set_weights([W_new, b_new])\n",
    "\n",
    "            prev_sel = sel\n",
    "\n",
    "        else:\n",
    "            x = layer(x)\n",
    "\n",
    "    return Model(inp, x)\n",
    "\n",
    "# =====================================================================\n",
    "# 8) MAIN PIPELINE (auto-detect model type)\n",
    "# =====================================================================\n",
    "def fnn_pruning_pipeline(model_path, dataset_path,\n",
    "                         keep_ratio=0.7,\n",
    "                         alpha=0.5, beta=0.3, gamma=0.2,\n",
    "                         calib_batches=30, batch_size=64, ft_epochs=3):\n",
    "    # 1) load model and detect type\n",
    "    print(\"Loading model:\", model_path)\n",
    "    model = load_model(model_path)\n",
    "    model_type = detect_model_type(model)\n",
    "    print(f\"[INFO] Detected model type: {model_type}\")\n",
    "\n",
    "    loss_name, metrics = get_loss_and_metrics_for_type(model_type)\n",
    "    print(f\"[INFO] Using loss='{loss_name}', metrics={metrics}\")\n",
    "\n",
    "    # 2) load dataset adapted to model_type\n",
    "    print(\"Loading dataset:\", dataset_path)\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = load_any_csv_dataset(dataset_path, model_type=model_type)\n",
    "\n",
    "    # 3) find dense layers and the last Dense layer name\n",
    "    dense_layers = get_dense_layers(model)\n",
    "    last_dense_name = dense_layers[-1].name if len(dense_layers) > 0 else None\n",
    "    print(\"Dense layers:\", [l.name for l in dense_layers], \"| last_dense:\", last_dense_name)\n",
    "\n",
    "    # 4) compute stats (activation + gradient)\n",
    "    print(\"Computing activation & gradient stats...\")\n",
    "    stats = compute_activation_grad_stats(model, dense_layers, X_train, y_train, model_type,\n",
    "                                          batch_size=batch_size, max_batches=calib_batches)\n",
    "\n",
    "    # 5) compute masks (protect final layer)\n",
    "    masks = compute_importance_mask(stats, keep_ratio=keep_ratio, alpha=alpha, beta=beta, gamma=gamma, last_dense_name=last_dense_name)\n",
    "    for k,v in masks.items():\n",
    "        if v.size > 0:\n",
    "            print(f\"{k} -> kept units: {int(np.sum(v))}/{len(v)}\")\n",
    "\n",
    "    # 6) build masked model (DNAGate zeroing) and compile with correct loss/metrics\n",
    "    print(\"Building masked model (DNAGate zeroing)...\")\n",
    "    masked_model = build_masked_model(model, masks)\n",
    "    masked_model.compile(optimizer='adam', loss=loss_name, metrics=metrics)\n",
    "\n",
    "    # compute baseline & masked flops/accuracy\n",
    "    baseline_acc = None\n",
    "    masked_acc_before = None\n",
    "    if model_type == \"regression\":\n",
    "        baseline_eval = model.evaluate(X_val, y_val, verbose=0)\n",
    "        baseline_acc = baseline_eval[0] if len(baseline_eval)>0 else None\n",
    "        masked_acc_before = masked_model.evaluate(X_val, y_val, verbose=0)[0]\n",
    "    else:\n",
    "        baseline_acc = model.evaluate(X_val, y_val, verbose=0)[1]  # accuracy or sparse_accuracy\n",
    "        masked_acc_before = masked_model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "\n",
    "    baseline_flops = model_flops(model)\n",
    "    masked_flops = effective_flops(model, masks)\n",
    "\n",
    "    print(f\"Baseline Acc: {baseline_acc} | FLOPS: {baseline_flops}\")\n",
    "    print(f\"Masked Acc (before FT): {masked_acc_before} | Effective FLOPS: {masked_flops}\")\n",
    "\n",
    "    # 7) fine-tune masked model\n",
    "    print(\"Fine-tuning masked model...\")\n",
    "    masked_model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=ft_epochs, verbose=2)\n",
    "\n",
    "    # evaluate masked after FT\n",
    "    if model_type == \"regression\":\n",
    "        masked_eval = masked_model.evaluate(X_val, y_val, verbose=0)\n",
    "        masked_acc_after = masked_eval[0] if len(masked_eval)>0 else None\n",
    "    else:\n",
    "        masked_acc_after = masked_model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "\n",
    "    # 8) structural pruning (permanent neuron removal)\n",
    "    print(\"Constructing structurally-pruned model (remove neurons)...\")\n",
    "    pruned_model = structurally_prune_fnn(model, masks, last_dense_name=last_dense_name)\n",
    "    pruned_model.compile(optimizer='adam', loss=loss_name, metrics=metrics)\n",
    "\n",
    "    print(\"Fine-tuning pruned model...\")\n",
    "    pruned_model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=ft_epochs, verbose=2)\n",
    "\n",
    "    # final evals\n",
    "    if model_type == \"regression\":\n",
    "        pruned_eval = pruned_model.evaluate(X_val, y_val, verbose=0)\n",
    "        pruned_acc = pruned_eval[0] if len(pruned_eval)>0 else None\n",
    "    else:\n",
    "        pruned_acc = pruned_model.evaluate(X_val, y_val, verbose=0)[1]\n",
    "\n",
    "    pruned_flops = model_flops(pruned_model)\n",
    "\n",
    "    # compute GFLOPS / MFLOPS / inference times\n",
    "    baseline_gflops = flops_to_gflops(baseline_flops)\n",
    "    masked_gflops = flops_to_gflops(masked_flops)\n",
    "    pruned_gflops = flops_to_gflops(pruned_flops)\n",
    "\n",
    "    baseline_mflops = flops_to_mflops(baseline_flops)\n",
    "    masked_mflops = flops_to_mflops(masked_flops)\n",
    "    pruned_mflops = flops_to_mflops(pruned_flops)\n",
    "\n",
    "    baseline_time_ms = measure_inference_time(model, X_val)\n",
    "    masked_time_ms = measure_inference_time(masked_model, X_val)\n",
    "    pruned_time_ms = measure_inference_time(pruned_model, X_val)\n",
    "\n",
    "    print(\"\\n=== FINAL REPORT ===\")\n",
    "    print(f\"Model type: {model_type}\")\n",
    "    print(f\"Baseline:   Acc/metric={baseline_acc} | FLOPS={baseline_flops} | MFLOPS={baseline_mflops:.6f} | GFLOPS={baseline_gflops:.10f} | Time={baseline_time_ms:.4f} ms/sample\")\n",
    "    print(f\"Masked:     Acc/metric={masked_acc_after} | EFLOPS={masked_flops} | MFLOPS={masked_mflops:.6f} | GFLOPS={masked_gflops:.10f} | Time={masked_time_ms:.4f} ms/sample\")\n",
    "    print(f\"Pruned:     Acc/metric={pruned_acc} | FLOPS={pruned_flops} | MFLOPS={pruned_mflops:.6f} | GFLOPS={pruned_gflops:.10f} | Time={pruned_time_ms:.4f} ms/sample\")\n",
    "    if baseline_flops > 0:\n",
    "        print(f\"FLOPS reduction (pruned): {(baseline_flops - pruned_flops)/baseline_flops:.2%}\")\n",
    "    print(\"==============================================\\n\")\n",
    "\n",
    "    print(f\"Pruned:     Acc/metric={pruned_acc} | FLOPS={pruned_flops} | MFLOPS={pruned_mflops:.6f} | GFLOPS={pruned_gflops:.10f} | Time={pruned_time_ms:.4f} ms/sample\")\n",
    "\n",
    "    # ---- NEW METRIC REDUCTIONS ADDED BELOW ----\n",
    "    if baseline_flops > 0:\n",
    "        flop_reduction = (baseline_flops - pruned_flops) / baseline_flops\n",
    "        gflop_reduction = (baseline_gflops - pruned_gflops) / baseline_gflops if baseline_gflops > 0 else 0\n",
    "    else:\n",
    "        flop_reduction = 0\n",
    "        gflop_reduction = 0\n",
    "\n",
    "    acc_reduction = baseline_acc - pruned_acc if baseline_acc is not None else None\n",
    "\n",
    "    print(f\"FLOPS reduction (pruned): {flop_reduction:.2%}\")\n",
    "    print(f\"GFLOPS reduction (pruned): {gflop_reduction:.2%}\")\n",
    "    print(f\"Accuracy reduction: {acc_reduction}\")\n",
    "    # ---- END NEW LINES ----\n",
    "\n",
    "    print(\"==============================================\\n\")\n",
    "\n",
    "    # save masked/pruned models next to original\n",
    "    base = os.path.basename(model_path)\n",
    "    root = os.path.splitext(base)[0]\n",
    "    folder = os.path.dirname(model_path) or \".\"\n",
    "\n",
    "    masked_path = os.path.join(folder, root + \"_masked.h5\")\n",
    "    pruned_path = os.path.join(folder, root + \"_pruned.h5\")\n",
    "\n",
    "    try:\n",
    "        print(f\"[INFO] Saving masked model to: {masked_path}\")\n",
    "        masked_model.save(masked_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed to save masked model: {e}\")\n",
    "\n",
    "    try:\n",
    "        print(f\"[INFO] Saving pruned model to: {pruned_path}\")\n",
    "        pruned_model.save(pruned_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Failed to save pruned model: {e}\")\n",
    "\n",
    "    # return X_val for further external checks if desired\n",
    "    return model, masked_model, pruned_model, masks, X_val\n",
    "\n",
    "# =====================================================================\n",
    "# 9) RUN (example)\n",
    "# =====================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # change these to your files\n",
    "    model_path = r\"D:\\college\\sem-8\\models\\dementia_fnn_model.h5\"\n",
    "    dataset_path = r\"D:\\college\\sem-8\\dataset\\clean_dementia_dataset.csv\"\n",
    "\n",
    "    original_model, masked_model, pruned_model, masks, X_val = fnn_pruning_pipeline(\n",
    "        model_path=model_path,\n",
    "        dataset_path=dataset_path,\n",
    "        keep_ratio=0.8,\n",
    "        alpha=0.5, beta=0.3, gamma=0.2,\n",
    "        calib_batches=30, batch_size=64, ft_epochs=15\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592a6738",
   "metadata": {},
   "source": [
    "# **FNN for alzihmerA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b904a8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: D:\\college\\sem-8\\models\\asthma_fnn_model (1).h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Detected model type: binary\n",
      "[INFO] Using loss='binary_crossentropy', metrics=['accuracy']\n",
      "Loading dataset: D:\\college\\sem-8\\dataset\\asthma_disease_data (1).csv\n",
      "[INFO] Loading CSV with automatic delimiter detection...\n",
      "[INFO] Columns detected: ['PatientID', 'Age', 'Gender', 'Ethnicity', 'EducationLevel', 'BMI', 'Smoking', 'PhysicalActivity', 'DietQuality', 'SleepQuality', 'PollutionExposure', 'PollenExposure', 'DustExposure', 'PetAllergy', 'FamilyHistoryAsthma', 'HistoryOfAllergies', 'Eczema', 'HayFever', 'GastroesophagealReflux', 'LungFunctionFEV1', 'LungFunctionFVC', 'Wheezing', 'ShortnessOfBreath', 'ChestTightness', 'Coughing', 'NighttimeSymptoms', 'ExerciseInduced', 'Unnamed: 27', 'DoctorInCharge', 'Diagnosis']\n",
      "[INFO] Auto-detected target column = Diagnosis\n",
      "[INFO] Target converted to numeric successfully.\n",
      "[INFO] One-hot encoding predictors: ['DoctorInCharge']\n",
      "Dense layers: ['dense_10', 'dense_11', 'dense_12', 'dense_13'] | last_dense: dense_13\n",
      "Computing activation & gradient stats...\n",
      "dense_10 -> kept units: 0/64\n",
      "dense_11 -> kept units: 0/32\n",
      "dense_12 -> kept units: 0/16\n",
      "dense_13 -> kept units: 1/1\n",
      "Building masked model (DNAGate zeroing)...\n",
      "Baseline Acc: 0.050209205597639084 | FLOPS: 8849\n",
      "Masked Acc (before FT): 0.050209205597639084 | Effective FLOPS: 1\n",
      "Fine-tuning masked model...\n",
      "Epoch 1/3\n",
      "27/27 - 1s - 36ms/step - accuracy: 0.0520 - loss: 0.7265 - val_accuracy: 0.0502 - val_loss: 0.7199\n",
      "Epoch 2/3\n",
      "27/27 - 0s - 5ms/step - accuracy: 0.0520 - loss: 0.7141 - val_accuracy: 0.0502 - val_loss: 0.7076\n",
      "Epoch 3/3\n",
      "27/27 - 0s - 5ms/step - accuracy: 0.0520 - loss: 0.7020 - val_accuracy: 0.0502 - val_loss: 0.6956\n",
      "Constructing structurally-pruned model (remove neurons)...\n",
      "Fine-tuning pruned model...\n",
      "Epoch 1/3\n",
      "27/27 - 1s - 38ms/step - accuracy: 0.9480 - loss: 0.6502 - val_accuracy: 0.9498 - val_loss: 0.6289\n",
      "Epoch 2/3\n",
      "27/27 - 0s - 5ms/step - accuracy: 0.9480 - loss: 0.6112 - val_accuracy: 0.9498 - val_loss: 0.5898\n",
      "Epoch 3/3\n",
      "27/27 - 0s - 4ms/step - accuracy: 0.9480 - loss: 0.5725 - val_accuracy: 0.9498 - val_loss: 0.5512\n",
      "\n",
      "=== FINAL REPORT ===\n",
      "Model type: binary\n",
      "Baseline:   Acc/metric=0.050209205597639084 | FLOPS=8849 | MFLOPS=0.008849 | GFLOPS=0.0000088490 | Time=0.5574 ms/sample\n",
      "Masked:     Acc/metric=0.050209205597639084 | EFLOPS=1 | MFLOPS=0.000001 | GFLOPS=0.0000000010 | Time=0.4996 ms/sample\n",
      "Pruned:     Acc/metric=0.9497907757759094 | FLOPS=66 | MFLOPS=0.000066 | GFLOPS=0.0000000660 | Time=0.4322 ms/sample\n",
      "\n",
      "=== REDUCTION SUMMARY ===\n",
      "FLOPS reduced (absolute) : 8783 ops\n",
      "FLOPS reduced (percent)  : 99.25%\n",
      "GFLOPS reduced (absolute): 0.0000087830 GFLOPS\n",
      "GFLOPS reduced (percent) : 99.25%\n",
      "Accuracy change (absolute): -0.899582\n",
      "Accuracy change (percent of baseline): -1791.67%\n",
      "=========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FNN-only pruning pipeline (auto-detect model type).\n",
    "- Detects model type from final layer (binary / multiclass / regression).\n",
    "- Adapts CSV loader accordingly.\n",
    "- Keeps final layer intact (never pruned).\n",
    "- Reports FLOPs, GFLOPs, MFLOPS and inference time.\n",
    "- Reports absolute + percent reductions for FLOPS, GFLOPS and Accuracy.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -----------------------\n",
    "# Helper: detect model type\n",
    "# -----------------------\n",
    "def detect_model_type(model):\n",
    "    out = model.layers[-1]\n",
    "    units = getattr(out, \"units\", None)\n",
    "    act = getattr(out, \"activation\", None)\n",
    "    act_name = act.__name__ if act is not None else None\n",
    "\n",
    "    if units == 1 and act_name in (\"sigmoid\",):\n",
    "        return \"binary\"\n",
    "    if units == 1 and act_name in (\"linear\", \"relu\", \"tanh\"):\n",
    "        return \"regression\"\n",
    "    if units is not None and units > 1 and act_name == \"softmax\":\n",
    "        return \"multiclass\"\n",
    "    # fallback tries\n",
    "    if units == 1:\n",
    "        return \"binary\"\n",
    "    if units and units > 1:\n",
    "        return \"multiclass\"\n",
    "    return \"unknown\"\n",
    "\n",
    "def get_loss_and_metrics_for_type(model_type):\n",
    "    if model_type == \"binary\":\n",
    "        return (\"binary_crossentropy\", [\"accuracy\"])\n",
    "    if model_type == \"multiclass\":\n",
    "        # use sparse labels to avoid forcing one-hot encoding\n",
    "        return (\"sparse_categorical_crossentropy\", [\"sparse_categorical_accuracy\"])\n",
    "    if model_type == \"regression\":\n",
    "        return (\"mse\", [\"mse\"])\n",
    "    raise ValueError(\"Unknown model type\")\n",
    "\n",
    "# =====================================================================\n",
    "# 1) UNIVERSAL CSV LOADER  (robust, factorizes non-numeric targets)\n",
    "# =====================================================================\n",
    "def load_any_csv_dataset(csv_path, target=None, test_size=0.2, val_size=0.1, model_type=\"binary\"):\n",
    "    \"\"\"\n",
    "    Loads CSV (auto-detect delimiter). Adapts target processing to model_type:\n",
    "      - binary/regression: returns y as float32 shaped (n,1)\n",
    "      - multiclass: returns integer labels shaped (n,1) for sparse loss\n",
    "    Also handles non-numeric targets by factorization, handles categorical predictors.\n",
    "    \"\"\"\n",
    "    print(\"[INFO] Loading CSV with automatic delimiter detection...\")\n",
    "    df = pd.read_csv(csv_path, sep=None, engine=\"python\")\n",
    "    print(\"[INFO] Columns detected:\", list(df.columns))\n",
    "\n",
    "    if target is None:\n",
    "        target = df.columns[-1]\n",
    "        print(f\"[INFO] Auto-detected target column = {target}\")\n",
    "\n",
    "    if target not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target}' not found in dataset!\")\n",
    "\n",
    "    y_raw = df[target]\n",
    "    X = df.drop(columns=[target])\n",
    "\n",
    "    # ---- Robust target processing ----\n",
    "    # Try numeric conversion first (works for regression or numeric-coded labels)\n",
    "    y_num = pd.to_numeric(y_raw, errors=\"coerce\")\n",
    "    if not y_num.isna().any():\n",
    "        y_proc = y_num\n",
    "        print(\"[INFO] Target converted to numeric successfully.\")\n",
    "    else:\n",
    "        # contains non-numeric values -> fallback to categorical factorization\n",
    "        print(\"[WARN] Target column contains non-numeric values; factorizing to integer codes.\")\n",
    "        codes, uniques = pd.factorize(y_raw.astype(str))\n",
    "        y_proc = pd.Series(codes)\n",
    "        print(f\"[INFO] Factorized target into {len(uniques)} unique codes.\")\n",
    "\n",
    "    # Now adapt shape & dtype by model_type\n",
    "    if model_type == \"binary\":\n",
    "        unique_vals = np.unique(y_proc)\n",
    "        if len(unique_vals) > 2:\n",
    "            print(f\"[WARN] Detected {len(unique_vals)} unique target values for model_type='binary'. Using numeric/factorized values as-is.\")\n",
    "        y = y_proc.astype(np.float32).values.reshape(-1, 1)\n",
    "\n",
    "    elif model_type == \"multiclass\":\n",
    "        # ensure integer labels (sparse labels)\n",
    "        if np.issubdtype(y_proc.dtype, np.floating):\n",
    "            if np.all(np.mod(y_proc.fillna(0).values, 1) == 0):\n",
    "                y = y_proc.astype(np.int32).values.reshape(-1, 1)\n",
    "            else:\n",
    "                codes, uniques = pd.factorize(y_raw.astype(str))\n",
    "                y = codes.astype(np.int32).reshape(-1, 1)\n",
    "                print(\"[WARN] Multiclass target had non-integer numeric values; factorized instead.\")\n",
    "        else:\n",
    "            y = y_proc.astype(np.int32).values.reshape(-1, 1)\n",
    "\n",
    "    elif model_type == \"regression\":\n",
    "        if np.any(pd.isna(y_proc)):\n",
    "            raise ValueError(\"Regression target contains non-numeric values that could not be converted.\")\n",
    "        y = y_proc.astype(np.float32).values.reshape(-1, 1)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model_type for loader\")\n",
    "    # ---- end target processing ----\n",
    "\n",
    "    # One-hot encode only categorical predictors (keep numeric as-is)\n",
    "    cat_cols = X.select_dtypes(include=[\"object\"]).columns\n",
    "    if len(cat_cols) > 0:\n",
    "        print(\"[INFO] One-hot encoding predictors:\", list(cat_cols))\n",
    "        X = pd.get_dummies(X, drop_first=True)\n",
    "    else:\n",
    "        print(\"[INFO] No categorical predictor columns to encode.\")\n",
    "\n",
    "    # convert to float32 (features)\n",
    "    X = X.astype(np.float32)\n",
    "\n",
    "    # ----- SAFER stratify handling -----\n",
    "    use_stratify = None\n",
    "    if model_type != \"regression\":\n",
    "        try:\n",
    "            y_flat = np.ravel(y).astype(np.int64)\n",
    "            class_counts = np.bincount(y_flat)\n",
    "            if np.all(class_counts >= 2):\n",
    "                use_stratify = y_flat\n",
    "            else:\n",
    "                print(\"[WARN] Some classes have < 2 samples, disabling stratify for train/val/test split.\")\n",
    "                use_stratify = None\n",
    "        except Exception:\n",
    "            print(\"[WARN] Could not prepare integer labels for stratify; disabling stratify.\")\n",
    "            use_stratify = None\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y,\n",
    "        test_size=(test_size + val_size),\n",
    "        random_state=42,\n",
    "        stratify=use_stratify\n",
    "    )\n",
    "\n",
    "    # second split into val/test\n",
    "    use_stratify2 = None\n",
    "    if model_type != \"regression\" and use_stratify is not None:\n",
    "        try:\n",
    "            y_temp_flat = np.ravel(y_temp).astype(np.int64)\n",
    "            class_counts2 = np.bincount(y_temp_flat)\n",
    "            if np.all(class_counts2 >= 2):\n",
    "                use_stratify2 = y_temp_flat\n",
    "            else:\n",
    "                print(\"[WARN] Validation/Test split: classes <2 detected, disabling stratify.\")\n",
    "                use_stratify2 = None\n",
    "        except Exception:\n",
    "            use_stratify2 = None\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp,\n",
    "        test_size=test_size/(test_size+val_size),\n",
    "        random_state=42,\n",
    "        stratify=use_stratify2\n",
    "    )\n",
    "\n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n",
    "\n",
    "# =====================================================================\n",
    "# 2) GET DENSE LAYERS\n",
    "# =====================================================================\n",
    "def get_dense_layers(model):\n",
    "    return [layer for layer in model.layers if isinstance(layer, Dense)]\n",
    "\n",
    "# =====================================================================\n",
    "# 3) ACTIVATION + GRADIENT STATS  (SHAPE-SAFE)\n",
    "# =====================================================================\n",
    "def compute_activation_grad_stats(model, dense_layers, X, y, model_type,\n",
    "                                  batch_size=64, max_batches=30):\n",
    "    \"\"\"\n",
    "    Returns stats dict: {layer.name: (A_mean_per_neuron, G_mean_per_neuron, Var_per_neuron)}\n",
    "    Uses appropriate loss for model_type when computing gradients.\n",
    "    \"\"\"\n",
    "    # Convert X,y to numpy if DataFrame\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X_np = X.to_numpy()\n",
    "    else:\n",
    "        X_np = X\n",
    "    if isinstance(y, pd.DataFrame) or isinstance(y, pd.Series):\n",
    "        y_np = y.to_numpy()\n",
    "    else:\n",
    "        y_np = y\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X_np, y_np)).batch(batch_size)\n",
    "    acc_A = {l.name: [] for l in dense_layers}\n",
    "    acc_G = {l.name: [] for l in dense_layers}\n",
    "    acc_V = {l.name: [] for l in dense_layers}\n",
    "\n",
    "    # choose loss for gradient computation\n",
    "    if model_type == \"binary\":\n",
    "        loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False, reduction=tf.keras.losses.Reduction.NONE)\n",
    "    elif model_type == \"multiclass\":\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction=tf.keras.losses.Reduction.NONE)\n",
    "    elif model_type == \"regression\":\n",
    "        loss_fn = tf.keras.losses.MeanSquaredError(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model_type for stats\")\n",
    "\n",
    "    batch_count = 0\n",
    "    for xb, yb in ds:\n",
    "        if batch_count >= max_batches:\n",
    "            break\n",
    "        batch_count += 1\n",
    "\n",
    "        # ensure shapes consistent\n",
    "        x = tf.cast(xb, tf.float32)\n",
    "        # For sparse multiclass loss, yb should be shape (batch,) ints\n",
    "        if model_type == \"multiclass\":\n",
    "            yb_proc = tf.cast(tf.squeeze(yb, axis=-1), tf.int32)\n",
    "        else:\n",
    "            # binary/regression: keep shape (batch,1) as float32\n",
    "            yb_proc = tf.cast(yb, tf.float32)\n",
    "\n",
    "        layer_outputs = {}\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            for layer in model.layers:\n",
    "                x = layer(x)\n",
    "                if layer in dense_layers:\n",
    "                    tape.watch(x)\n",
    "                    layer_outputs[layer.name] = x\n",
    "            preds = x\n",
    "            # compute per-sample loss (shape [batch,] or [batch, ...])\n",
    "            per_sample_loss = loss_fn(yb_proc, preds)\n",
    "            # compute scalar loss for gradient direction\n",
    "            loss = tf.reduce_mean(per_sample_loss)\n",
    "\n",
    "        for layer in dense_layers:\n",
    "            name = layer.name\n",
    "            if name not in layer_outputs:\n",
    "                continue\n",
    "            a = layer_outputs[name]            # shape (batch, units)\n",
    "            A = tf.reduce_mean(tf.abs(a), axis=0).numpy()\n",
    "            V = tf.math.reduce_variance(a, axis=0).numpy()\n",
    "\n",
    "            g = tape.gradient(loss, a)\n",
    "            if g is None:\n",
    "                G = np.zeros_like(A)\n",
    "            else:\n",
    "                G = tf.reduce_mean(tf.abs(g), axis=0).numpy()\n",
    "\n",
    "            acc_A[name].append(A)\n",
    "            acc_G[name].append(G)\n",
    "            acc_V[name].append(V)\n",
    "\n",
    "        del tape\n",
    "\n",
    "    # Aggregate\n",
    "    stats = {}\n",
    "    for layer in dense_layers:\n",
    "        name = layer.name\n",
    "        if len(acc_A[name]) == 0:\n",
    "            stats[name] = (np.array([]), np.array([]), np.array([]))\n",
    "            continue\n",
    "        A = np.mean(np.stack(acc_A[name], axis=0), axis=0)\n",
    "        G = np.mean(np.stack(acc_G[name], axis=0), axis=0)\n",
    "        V = np.mean(np.stack(acc_V[name], axis=0), axis=0)\n",
    "        stats[name] = (A, G, V)\n",
    "\n",
    "    return stats\n",
    "\n",
    "# =====================================================================\n",
    "# 4) IMPORTANCE MASKS (protect last Dense layer)\n",
    "# =====================================================================\n",
    "def compute_importance_mask(stats, keep_ratio=0.7, alpha=0.5, beta=0.3, gamma=0.2, last_dense_name=None):\n",
    "    \"\"\"\n",
    "    stats: dict layer.name -> (A,G,V)\n",
    "    last_dense_name: name of final Dense layer which must be preserved\n",
    "    \"\"\"\n",
    "    masks = {}\n",
    "    for name, (A, G, V) in stats.items():\n",
    "        if A.size == 0:\n",
    "            masks[name] = np.array([], dtype=np.float32)\n",
    "            continue\n",
    "\n",
    "        def normalize(x):\n",
    "            x2 = x - np.min(x)\n",
    "            mx = np.max(x2)\n",
    "            return x2 / (mx + 1e-12)\n",
    "\n",
    "        score = alpha * normalize(A) + beta * normalize(G) + gamma * normalize(V)\n",
    "\n",
    "        # protect final Dense layer: keep all units\n",
    "        if last_dense_name is not None and name == last_dense_name:\n",
    "            masks[name] = np.ones_like(score, dtype=np.float32)\n",
    "            continue\n",
    "\n",
    "        k = max(1, int(len(score) * keep_ratio))\n",
    "        thresh = np.partition(score, -k)[-k]\n",
    "        mask = (score >= thresh).astype(np.float32)\n",
    "        masks[name] = mask\n",
    "\n",
    "    return masks\n",
    "\n",
    "# =====================================================================\n",
    "# 5) DNAGate Layer (Zeroing)\n",
    "# =====================================================================\n",
    "class DNAGate(tf.keras.layers.Layer):\n",
    "    def __init__(self, mask=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._mask_np = np.array(mask, dtype=np.float32) if mask is not None else None\n",
    "        self.mask = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if self._mask_np is None:\n",
    "            self.mask = None\n",
    "        else:\n",
    "            if input_shape[-1] != self._mask_np.shape[0]:\n",
    "                raise ValueError(f\"DNAGate mask length {self._mask_np.shape[0]} != layer units {input_shape[-1]}\")\n",
    "            self.mask = tf.constant(self._mask_np, dtype=self.dtype)\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        if self.mask is None:\n",
    "            return x\n",
    "        return x * self.mask\n",
    "\n",
    "def build_masked_model(orig_model, masks):\n",
    "    inp = Input(shape=orig_model.input_shape[1:])\n",
    "    x = inp\n",
    "    for layer in orig_model.layers:\n",
    "        x = layer(x)\n",
    "        if layer.name in masks:\n",
    "            x = DNAGate(mask=masks[layer.name], name=layer.name + \"_dna\")(x)\n",
    "    new_model = Model(inp, x)\n",
    "    # copy weights where possible\n",
    "    for l in orig_model.layers:\n",
    "        try:\n",
    "            new_model.get_layer(l.name).set_weights(l.get_weights())\n",
    "        except Exception:\n",
    "            pass\n",
    "    return new_model\n",
    "\n",
    "# =====================================================================\n",
    "# 6) FLOPS + INFERENCE TIME\n",
    "# =====================================================================\n",
    "def dense_flops(in_size, out_size, bias=True):\n",
    "    # multiply-adds counted as 2 ops per MAC\n",
    "    return int(in_size * out_size * 2 + (out_size if bias else 0))\n",
    "\n",
    "def model_flops(model):\n",
    "    total = 0\n",
    "    # attempt to get input size robustly\n",
    "    in_shape = model.input_shape\n",
    "    if isinstance(in_shape, tuple):\n",
    "        in_size = int(in_shape[1])\n",
    "    else:\n",
    "        in_size = int(model.input_shape[1])\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, Dense):\n",
    "            total += dense_flops(in_size, layer.units, layer.use_bias)\n",
    "            in_size = layer.units\n",
    "    return total\n",
    "\n",
    "def effective_flops(model, masks):\n",
    "    total = 0\n",
    "    in_shape = model.input_shape\n",
    "    if isinstance(in_shape, tuple):\n",
    "        in_size = int(in_shape[1])\n",
    "    else:\n",
    "        in_size = int(model.input_shape[1])\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, Dense):\n",
    "            if layer.name in masks and masks[layer.name].size > 0:\n",
    "                units = int(np.sum(masks[layer.name]))\n",
    "            else:\n",
    "                units = layer.units\n",
    "            total += dense_flops(in_size, units, layer.use_bias)\n",
    "            in_size = units\n",
    "    return total\n",
    "\n",
    "def flops_to_gflops(f):\n",
    "    return f / 1e9\n",
    "\n",
    "def flops_to_mflops(f):\n",
    "    return f / 1e6\n",
    "\n",
    "def measure_inference_time(model, X, runs=200):\n",
    "    \"\"\"Return average inference time in milliseconds per sample.\n",
    "       Accepts X as pandas DataFrame or numpy array.\"\"\"\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X_np = X.to_numpy()\n",
    "    else:\n",
    "        X_np = X\n",
    "    if len(X_np) == 0:\n",
    "        return float(\"nan\")\n",
    "    idx = np.random.randint(0, len(X_np), size=min(runs, len(X_np)))\n",
    "    samples = X_np[idx]\n",
    "    # make sure the shape matches model input: model expects shape (batch, input_dim)\n",
    "    try:\n",
    "        model.predict(samples[:1], verbose=0)\n",
    "    except Exception:\n",
    "        # try flattening last axis or trimming/padding to required input dims externally\n",
    "        raise\n",
    "    t0 = time.time()\n",
    "    model.predict(samples, verbose=0)\n",
    "    t1 = time.time()\n",
    "    total_ms = (t1 - t0) * 1000.0\n",
    "    return total_ms / len(samples)\n",
    "\n",
    "# =====================================================================\n",
    "# 7) STRUCTURAL PRUNING (REMOVE NEURONS) — protect final Dense layer\n",
    "# =====================================================================\n",
    "def structurally_prune_fnn(orig_model, masks, last_dense_name=None):\n",
    "    inp = Input(shape=orig_model.input_shape[1:])\n",
    "    x = inp\n",
    "    prev_sel = None\n",
    "\n",
    "    for layer in orig_model.layers:\n",
    "        if isinstance(layer, Dense):\n",
    "            W, b = layer.get_weights()\n",
    "\n",
    "            # If previous layer was pruned → prune rows\n",
    "            if prev_sel is not None:\n",
    "                W = W[prev_sel, :]\n",
    "\n",
    "            # ---- SAFETY: determine neurons to keep ----\n",
    "            if last_dense_name is not None and layer.name == last_dense_name:\n",
    "                # never prune final layer\n",
    "                sel = np.arange(layer.units)\n",
    "            else:\n",
    "                mask = masks.get(layer.name, None)\n",
    "                if mask is not None and mask.size > 0:\n",
    "                    sel = np.where(mask == 1)[0]\n",
    "                    # ensure >=1 neuron survives\n",
    "                    if len(sel) == 0:\n",
    "                        sel = np.array([np.argmax(mask)])\n",
    "                else:\n",
    "                    sel = None\n",
    "\n",
    "            # ---- Apply pruning ----\n",
    "            if sel is not None:\n",
    "                W_new = W[:, sel]\n",
    "                b_new = b[sel]\n",
    "                new_units = len(sel)\n",
    "            else:\n",
    "                W_new = W\n",
    "                b_new = b\n",
    "                new_units = W.shape[1]\n",
    "\n",
    "            new_layer = Dense(new_units, activation=layer.activation, name=layer.name)\n",
    "            x = new_layer(x)\n",
    "            new_layer.set_weights([W_new, b_new])\n",
    "\n",
    "            prev_sel = sel\n",
    "\n",
    "        else:\n",
    "            x = layer(x)\n",
    "\n",
    "    return Model(inp, x)\n",
    "\n",
    "# =====================================================================\n",
    "# 8) MAIN PIPELINE (auto-detect model type)\n",
    "# =====================================================================\n",
    "def fnn_pruning_pipeline(model_path, dataset_path,\n",
    "                         keep_ratio=0.7,\n",
    "                         alpha=0.5, beta=0.3, gamma=0.2,\n",
    "                         calib_batches=30, batch_size=64, ft_epochs=3,\n",
    "                         save_pruned_path=None):\n",
    "    # 1) load model and detect type\n",
    "    print(\"Loading model:\", model_path)\n",
    "    model = load_model(model_path)\n",
    "    model_type = detect_model_type(model)\n",
    "    print(f\"[INFO] Detected model type: {model_type}\")\n",
    "\n",
    "    loss_name, metrics = get_loss_and_metrics_for_type(model_type)\n",
    "    print(f\"[INFO] Using loss='{loss_name}', metrics={metrics}\")\n",
    "\n",
    "    # 2) load dataset adapted to model_type\n",
    "    print(\"Loading dataset:\", dataset_path)\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = load_any_csv_dataset(dataset_path, model_type=model_type)\n",
    "\n",
    "    # --- ensure feature dimension matches model input by trimming or padding ---\n",
    "    model_input_dim = int(model.input_shape[1])\n",
    "    def ensure_feature_dim(X_df):\n",
    "        # X_df can be numpy or DataFrame\n",
    "        if isinstance(X_df, pd.DataFrame):\n",
    "            arr = X_df.to_numpy().astype(np.float32)\n",
    "        else:\n",
    "            arr = np.asarray(X_df, dtype=np.float32)\n",
    "        cur_dim = arr.shape[1]\n",
    "        if cur_dim == model_input_dim:\n",
    "            return arr\n",
    "        if cur_dim > model_input_dim:\n",
    "            print(f\"[WARN] Truncating features from {cur_dim} -> {model_input_dim} to match model input.\")\n",
    "            return arr[:, :model_input_dim]\n",
    "        # cur_dim < model_input_dim -> pad with zeros\n",
    "        print(f\"[WARN] Padding features from {cur_dim} -> {model_input_dim} to match model input.\")\n",
    "        pad = np.zeros((arr.shape[0], model_input_dim - cur_dim), dtype=np.float32)\n",
    "        return np.concatenate([arr, pad], axis=1)\n",
    "\n",
    "    X_train = ensure_feature_dim(X_train)\n",
    "    X_val = ensure_feature_dim(X_val)\n",
    "    X_test = ensure_feature_dim(X_test)\n",
    "\n",
    "    # 3) find dense layers and the last Dense layer name\n",
    "    dense_layers = get_dense_layers(model)\n",
    "    last_dense_name = dense_layers[-1].name if len(dense_layers) > 0 else None\n",
    "    print(\"Dense layers:\", [l.name for l in dense_layers], \"| last_dense:\", last_dense_name)\n",
    "\n",
    "    # 4) compute stats (activation + gradient)\n",
    "    print(\"Computing activation & gradient stats...\")\n",
    "    stats = compute_activation_grad_stats(model, dense_layers, X_train, y_train, model_type,\n",
    "                                          batch_size=batch_size, max_batches=calib_batches)\n",
    "\n",
    "    # 5) compute masks (protect final layer)\n",
    "    masks = compute_importance_mask(stats, keep_ratio=keep_ratio, alpha=alpha, beta=beta, gamma=gamma, last_dense_name=last_dense_name)\n",
    "    for k, v in masks.items():\n",
    "        if v.size > 0:\n",
    "            print(f\"{k} -> kept units: {int(np.sum(v))}/{len(v)}\")\n",
    "\n",
    "    # 6) build masked model (zeroing) and compile with correct loss/metrics\n",
    "    print(\"Building masked model (DNAGate zeroing)...\")\n",
    "    masked_model = build_masked_model(model, masks)\n",
    "    masked_model.compile(optimizer='adam', loss=loss_name, metrics=metrics)\n",
    "\n",
    "    # compute baseline & masked flops/accuracy\n",
    "    baseline_acc = None\n",
    "    masked_acc_before = None\n",
    "    if model_type == \"regression\":\n",
    "        baseline_eval = model.evaluate(X_val, y_val, verbose=0)\n",
    "        baseline_acc = baseline_eval[0] if len(baseline_eval) > 0 else None\n",
    "        masked_acc_before = masked_model.evaluate(X_val, y_val, verbose=0)[0]\n",
    "    else:\n",
    "        baseline_eval = model.evaluate(X_val, y_val, verbose=0)\n",
    "        masked_eval_before = masked_model.evaluate(X_val, y_val, verbose=0)\n",
    "        # baseline_eval may produce [loss, metric...] so metric index 1\n",
    "        baseline_acc = baseline_eval[1] if len(baseline_eval) > 1 else (baseline_eval[0] if len(baseline_eval)==1 else None)\n",
    "        masked_acc_before = masked_eval_before[1] if len(masked_eval_before) > 1 else (masked_eval_before[0] if len(masked_eval_before)==1 else None)\n",
    "\n",
    "    baseline_flops = model_flops(model)\n",
    "    masked_flops = effective_flops(model, masks)\n",
    "\n",
    "    print(f\"Baseline Acc: {baseline_acc} | FLOPS: {baseline_flops}\")\n",
    "    print(f\"Masked Acc (before FT): {masked_acc_before} | Effective FLOPS: {masked_flops}\")\n",
    "\n",
    "    # 7) fine-tune masked model\n",
    "    print(\"Fine-tuning masked model...\")\n",
    "    masked_model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=ft_epochs, verbose=2)\n",
    "\n",
    "    # evaluate masked after FT\n",
    "    if model_type == \"regression\":\n",
    "        masked_eval = masked_model.evaluate(X_val, y_val, verbose=0)\n",
    "        masked_acc_after = masked_eval[0] if len(masked_eval) > 0 else None\n",
    "    else:\n",
    "        masked_eval = masked_model.evaluate(X_val, y_val, verbose=0)\n",
    "        masked_acc_after = masked_eval[1] if len(masked_eval) > 1 else (masked_eval[0] if len(masked_eval)==1 else None)\n",
    "\n",
    "    # 8) structural pruning (permanent neuron removal)\n",
    "    print(\"Constructing structurally-pruned model (remove neurons)...\")\n",
    "    pruned_model = structurally_prune_fnn(model, masks, last_dense_name=last_dense_name)\n",
    "    pruned_model.compile(optimizer='adam', loss=loss_name, metrics=metrics)\n",
    "\n",
    "    print(\"Fine-tuning pruned model...\")\n",
    "    pruned_model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=ft_epochs, verbose=2)\n",
    "\n",
    "    # final evals\n",
    "    if model_type == \"regression\":\n",
    "        pruned_eval = pruned_model.evaluate(X_val, y_val, verbose=0)\n",
    "        pruned_acc = pruned_eval[0] if len(pruned_eval) > 0 else None\n",
    "    else:\n",
    "        pruned_eval = pruned_model.evaluate(X_val, y_val, verbose=0)\n",
    "        pruned_acc = pruned_eval[1] if len(pruned_eval) > 1 else (pruned_eval[0] if len(pruned_eval)==1 else None)\n",
    "\n",
    "    pruned_flops = model_flops(pruned_model)\n",
    "\n",
    "    # compute GFLOPS / MFLOPS / inference times\n",
    "    baseline_gflops = flops_to_gflops(baseline_flops)\n",
    "    masked_gflops = flops_to_gflops(masked_flops)\n",
    "    pruned_gflops = flops_to_gflops(pruned_flops)\n",
    "\n",
    "    baseline_mflops = flops_to_mflops(baseline_flops)\n",
    "    masked_mflops = flops_to_mflops(masked_flops)\n",
    "    pruned_mflops = flops_to_mflops(pruned_flops)\n",
    "\n",
    "    baseline_time_ms = measure_inference_time(model, X_val)\n",
    "    masked_time_ms = measure_inference_time(masked_model, X_val)\n",
    "    pruned_time_ms = measure_inference_time(pruned_model, X_val)\n",
    "\n",
    "    print(\"\\n=== FINAL REPORT ===\")\n",
    "    print(f\"Model type: {model_type}\")\n",
    "    print(f\"Baseline:   Acc/metric={baseline_acc} | FLOPS={baseline_flops} | MFLOPS={baseline_mflops:.6f} | GFLOPS={baseline_gflops:.10f} | Time={baseline_time_ms:.4f} ms/sample\")\n",
    "    print(f\"Masked:     Acc/metric={masked_acc_after} | EFLOPS={masked_flops} | MFLOPS={masked_mflops:.6f} | GFLOPS={masked_gflops:.10f} | Time={masked_time_ms:.4f} ms/sample\")\n",
    "    print(f\"Pruned:     Acc/metric={pruned_acc} | FLOPS={pruned_flops} | MFLOPS={pruned_mflops:.6f} | GFLOPS={pruned_gflops:.10f} | Time={pruned_time_ms:.4f} ms/sample\")\n",
    "\n",
    "    # ---- NEW METRIC REDUCTIONS ADDED BELOW ----\n",
    "    # FLOPS reduction (absolute and percent)\n",
    "    if baseline_flops > 0:\n",
    "        flop_reduction_abs = baseline_flops - pruned_flops\n",
    "        flop_reduction_pct = flop_reduction_abs / baseline_flops\n",
    "    else:\n",
    "        flop_reduction_abs = 0\n",
    "        flop_reduction_pct = 0.0\n",
    "\n",
    "    # GFLOPS reduction (absolute and percent)\n",
    "    if baseline_gflops > 0:\n",
    "        gflop_reduction_abs = baseline_gflops - pruned_gflops\n",
    "        gflop_reduction_pct = gflop_reduction_abs / baseline_gflops\n",
    "    else:\n",
    "        gflop_reduction_abs = 0.0\n",
    "        gflop_reduction_pct = 0.0\n",
    "\n",
    "    # Accuracy reduction (absolute + percent relative to baseline if available)\n",
    "    acc_abs_reduction = None\n",
    "    acc_pct_reduction = None\n",
    "    if baseline_acc is not None and pruned_acc is not None:\n",
    "        acc_abs_reduction = baseline_acc - pruned_acc\n",
    "        if baseline_acc != 0:\n",
    "            acc_pct_reduction = acc_abs_reduction / baseline_acc\n",
    "        else:\n",
    "            acc_pct_reduction = None\n",
    "\n",
    "    # Print nicely\n",
    "    print(\"\\n=== REDUCTION SUMMARY ===\")\n",
    "    print(f\"FLOPS reduced (absolute) : {flop_reduction_abs} ops\")\n",
    "    print(f\"FLOPS reduced (percent)  : {flop_reduction_pct:.2%}\")\n",
    "    print(f\"GFLOPS reduced (absolute): {gflop_reduction_abs:.10f} GFLOPS\")\n",
    "    print(f\"GFLOPS reduced (percent) : {gflop_reduction_pct:.2%}\")\n",
    "    if acc_abs_reduction is not None:\n",
    "        print(f\"Accuracy change (absolute): {acc_abs_reduction:.6f}\")\n",
    "        if acc_pct_reduction is not None:\n",
    "            print(f\"Accuracy change (percent of baseline): {acc_pct_reduction:.2%}\")\n",
    "        else:\n",
    "            print(\"Accuracy percent change: N/A (baseline is zero or unavailable)\")\n",
    "    else:\n",
    "        print(\"Accuracy change: N/A (baseline or pruned accuracy not available)\")\n",
    "    print(\"=========================\\n\")\n",
    "    # ---- END NEW LINES ----\n",
    "\n",
    "    # optional: save pruned model\n",
    "    if save_pruned_path:\n",
    "        pruned_model.save(save_pruned_path)\n",
    "        print(f\"[INFO] Saved pruned model to: {save_pruned_path}\")\n",
    "\n",
    "    return model, masked_model, pruned_model, masks, X_val\n",
    "\n",
    "# =====================================================================\n",
    "# 9) RUN (example)\n",
    "# =====================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    # change these to your files\n",
    "    model_path = r\"D:\\college\\sem-8\\models\\asthma_fnn_model (1).h5\"\n",
    "    dataset_path = r\"D:\\college\\sem-8\\dataset\\asthma_disease_data (1).csv\"\n",
    "\n",
    "    original_model, masked_model, pruned_model, masks, X_val = fnn_pruning_pipeline(\n",
    "        model_path=model_path,\n",
    "        dataset_path=dataset_path,\n",
    "        keep_ratio=0.9,\n",
    "        alpha=0.5, beta=0.3, gamma=0.2,\n",
    "        calib_batches=30, batch_size=64, ft_epochs=3,\n",
    "        save_pruned_path=None\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6da1db",
   "metadata": {},
   "source": [
    "# **CNN Structure Pruning 3 Epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f96ab63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading model: D:\\college\\sem-8\\models\\flower_cnn_model.h5\n",
      "[INFO] Loaded model directly.\n",
      "[INFO] Model loaded. Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">178</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">178</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m178\u001b[0m, \u001b[38;5;34m178\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m87\u001b[0m, \u001b[38;5;34m87\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m645\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">536,645</span> (2.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m536,645\u001b[0m (2.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">536,645</span> (2.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m536,645\u001b[0m (2.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inferred input shape: (180, 180, 3)\n",
      "[INFO] Loading dataset folder: D:\\college\\sem-8\\dataset\\flower_photos image_size: (180, 180)\n",
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2936 files for training.\n",
      "Found 3670 files belonging to 5 classes.\n",
      "Using 734 files for validation.\n",
      "[INFO] Layers considered for pruning: ['conv2d_5', 'conv2d_6', 'conv2d_7', 'conv2d_8', 'conv2d_9', 'dense_8']\n",
      "[INFO] Computing activation & gradient stats...\n",
      "[INFO] conv2d_5: len=32 meanA=1.511032e-02 meanG=1.405021e-07 meanV=1.319298e-03\n",
      "[INFO] conv2d_6: len=64 meanA=5.383006e-03 meanG=5.216569e-07 meanV=1.591178e-04\n",
      "[INFO] conv2d_7: len=128 meanA=6.080369e-04 meanG=4.130494e-06 meanV=8.204263e-06\n",
      "[INFO] conv2d_8: len=128 meanA=4.388310e-03 meanG=1.736445e-05 meanV=3.638908e-06\n",
      "[INFO] conv2d_9: len=128 meanA=1.463907e-02 meanG=6.194560e-05 meanV=3.875269e-06\n",
      "[INFO] dense_8: len=128 meanA=3.249157e-02 meanG=1.355336e-03 meanV=4.577056e-06\n",
      "[INFO] conv2d_5: keep 22/32\n",
      "[INFO] conv2d_6: keep 44/64\n",
      "[INFO] conv2d_7: keep 89/128\n",
      "[INFO] conv2d_8: keep 89/128\n",
      "[INFO] conv2d_9: keep 89/128\n",
      "[INFO] dense_8: keep 89/128\n",
      "[INFO] Saved masks to pruning_output\\masks.json\n",
      "[INFO] Building masked model with gates...\n",
      "[INFO] Masked model built.\n",
      "[INFO] Masked model pre-FT acc: 0.24375000596046448\n",
      "[INFO] Baseline FLOPS: 691,945,472, baseline time (avg batch): 0.1701s\n",
      "Epoch 1/3\n",
      "46/46 - 87s - 2s/step - accuracy: 0.2408 - loss: 1.6136 - val_accuracy: 0.2469 - val_loss: 1.5945\n",
      "Epoch 2/3\n",
      "46/46 - 70s - 2s/step - accuracy: 0.2602 - loss: 1.5712 - val_accuracy: 0.3531 - val_loss: 1.5069\n",
      "Epoch 3/3\n",
      "46/46 - 66s - 1s/step - accuracy: 0.3835 - loss: 1.3767 - val_accuracy: 0.4625 - val_loss: 1.2431\n",
      "[INFO] Structural pruning (safe) start...\n",
      "[INFO] Warning: couldn't set weights for conv2d_6_pruned : Layer conv2d_6_pruned weight shape (3, 3, 22, 44) is not compatible with provided weight shape (3, 3, 32, 44).\n",
      "[INFO] Warning: couldn't set weights for conv2d_7_pruned : Layer conv2d_7_pruned weight shape (3, 3, 44, 89) is not compatible with provided weight shape (3, 3, 64, 89).\n",
      "[INFO] Warning: couldn't set weights for conv2d_8_pruned : Layer conv2d_8_pruned weight shape (3, 3, 89, 89) is not compatible with provided weight shape (3, 3, 128, 89).\n",
      "[INFO] Warning: couldn't set weights for conv2d_9_pruned : Layer conv2d_9_pruned weight shape (3, 3, 89, 89) is not compatible with provided weight shape (3, 3, 128, 89).\n",
      "[INFO] Warning: couldn't set weights for dense_8_pruned : Layer dense_8_pruned weight shape (801, 89) is not compatible with provided weight shape (1152, 89).\n",
      "[INFO] Warning: couldn't set weights for dense_9_pruned : Layer dense_9_pruned weight shape (89, 5) is not compatible with provided weight shape (128, 5).\n",
      "[INFO] Structural pruning complete. New model summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2_struct_pruned\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2_struct_pruned\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_5_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">178</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">178</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">616</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,756</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">35,333</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">71,378</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">71,378</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">801</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">71,378</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">450</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_5_pruned (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m178\u001b[0m, \u001b[38;5;34m178\u001b[0m, \u001b[38;5;34m22\u001b[0m)   │           \u001b[38;5;34m616\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m22\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6_pruned (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m87\u001b[0m, \u001b[38;5;34m87\u001b[0m, \u001b[38;5;34m44\u001b[0m)     │         \u001b[38;5;34m8,756\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m44\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7_pruned (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m89\u001b[0m)     │        \u001b[38;5;34m35,333\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m89\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8_pruned (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m89\u001b[0m)     │        \u001b[38;5;34m71,378\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m89\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9_pruned (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m89\u001b[0m)       │        \u001b[38;5;34m71,378\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m89\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m801\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8_pruned (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m)             │        \u001b[38;5;34m71,378\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9_pruned (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m450\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">259,289</span> (1012.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m259,289\u001b[0m (1012.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">259,289</span> (1012.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m259,289\u001b[0m (1012.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Evaluating Original model:\n",
      "[INFO] Original acc: 0.4904632270336151\n",
      "[INFO] Evaluating Masked model (after FT):\n",
      "[INFO] Masked acc: 0.486376017332077\n",
      "[INFO] Evaluating Pruned model:\n",
      "[INFO] Pruned acc: 0.2220708429813385\n",
      "[INFO] Pruned FLOPS: 341,338,238, pruned time: 0.1162s\n",
      "[INFO] ============================================================\n",
      "[INFO] SUMMARY:\n",
      "[INFO] Baseline FLOPS: 691,945,472\n",
      "[INFO] Pruned FLOPS:   341,338,238\n",
      "[INFO] FLOPS reduction: 50.67%\n",
      "[INFO] Original acc: 0.4904632270336151, Masked acc: 0.486376017332077, Pruned acc: 0.2220708429813385\n",
      "[INFO] ============================================================\n",
      "[INFO] Save models failed: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=pruning_output\\model_baseline.\n",
      "[INFO] Pipeline finished. Outputs: dict_keys(['model', 'masked_model', 'pruned_model', 'masks', 'baseline_flops', 'pruned_flops', 'baseline_time', 'pruned_time', 'orig_acc', 'mask_acc', 'pruned_acc'])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "sequential_cnn_pruning_full.py\n",
    "Full Sequential CNN pruning pipeline (single-file)\n",
    "\n",
    "- Loads user Sequential CNN (.h5 / .keras / SavedModel)\n",
    "- Sanitizes layer names in .h5 if they contain '/'\n",
    "- Loads folder dataset (image_dataset_from_directory)\n",
    "- Computes activation/gradient/variance importance\n",
    "- Creates masks (keep_ratio)\n",
    "- Builds masked model (gating layer)\n",
    "- Fine-tunes masked model\n",
    "- Structurally prunes model (conv filter removal, prune Dense outputs only)\n",
    "- Computes FLOPS & timings, evaluates models\n",
    "- Saves models and masks\n",
    "\n",
    "Note: This is intended for Sequential CNN models (Conv2D -> ... -> Flatten -> Dense -> ... -> Dense output).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# ---------------------------\n",
    "# USER CONFIG\n",
    "# ---------------------------\n",
    "MODEL_PATH = r\"D:\\college\\sem-8\\models\\flower_cnn_model.h5\"   # path to model (.h5/.keras or SavedModel dir)\n",
    "DATASET_PATH = r\"D:\\college\\sem-8\\dataset\\flower_photos\"      # folder with subfolders per class\n",
    "SAVE_DIR = r\"pruning_output\"                                 # where outputs are saved\n",
    "\n",
    "KEEP_RATIO = 0.7            # fraction of channels/units to keep\n",
    "ALPHA, BETA, GAMMA = 0.4, 0.3, 0.3  # importance weights\n",
    "BATCH_SIZE = 64\n",
    "CALIB_BATCHES = 30\n",
    "FT_EPOCHS = 3\n",
    "FT_BATCHES_TO_USE = 150\n",
    "PLOT_RESULTS = True\n",
    "VERBOSE = True\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def log(*args):\n",
    "    if VERBOSE:\n",
    "        print(\"[INFO]\", *args)\n",
    "\n",
    "# ---------------------------\n",
    "# Safe load model (handles '/' in h5 layer names)\n",
    "# ---------------------------\n",
    "def safe_load_model(model_path):\n",
    "    \"\"\"\n",
    "    Try normal load_model; if fails (e.g., '/' in layer names in H5), sanitize model_config JSON and rebuild.\n",
    "    Returns a Keras model (compiled=False).\n",
    "    \"\"\"\n",
    "    log(\"Loading model:\", model_path)\n",
    "    # Try direct load first\n",
    "    try:\n",
    "        m = tf.keras.models.load_model(model_path, compile=False)\n",
    "        log(\"Loaded model directly.\")\n",
    "        return m\n",
    "    except Exception as e:\n",
    "        log(\"Direct load failed:\", e)\n",
    "\n",
    "    # If HDF5, attempt to sanitize layer names in model_config\n",
    "    try:\n",
    "        with h5py.File(model_path, \"r\") as f:\n",
    "            if \"model_config\" in f:\n",
    "                raw = f[\"model_config\"][()]\n",
    "                if isinstance(raw, bytes):\n",
    "                    raw = raw.decode(\"utf-8\")\n",
    "                cfg_json = json.loads(raw)\n",
    "                changed = False\n",
    "                for layer in cfg_json.get(\"config\", {}).get(\"layers\", []):\n",
    "                    cfg = layer.get(\"config\", {})\n",
    "                    name = cfg.get(\"name\")\n",
    "                    if isinstance(name, str) and \"/\" in name:\n",
    "                        new_name = name.replace(\"/\", \"_\")\n",
    "                        cfg[\"name\"] = new_name\n",
    "                        changed = True\n",
    "                        log(f\"[FIX] layer name: {name} -> {new_name}\")\n",
    "                if changed:\n",
    "                    fixed_json = json.dumps(cfg_json)\n",
    "                    model = tf.keras.models.model_from_json(fixed_json)\n",
    "                    model.load_weights(model_path)\n",
    "                    log(\"Loaded model from sanitized JSON + weights.\")\n",
    "                    return model\n",
    "    except Exception as e2:\n",
    "        log(\"H5 sanitization attempt failed:\", e2)\n",
    "\n",
    "    # final fallback: try load_model with safe_mode=False (older TF)\n",
    "    try:\n",
    "        m = tf.keras.models.load_model(model_path, compile=False, safe_mode=False)\n",
    "        log(\"Loaded model with safe_mode=False.\")\n",
    "        return m\n",
    "    except Exception as e3:\n",
    "        log(\"All load attempts failed:\", e3)\n",
    "        raise RuntimeError(\"Failed to load model. Ensure path and format are correct.\")\n",
    "\n",
    "# ---------------------------\n",
    "# Dataset loader (folder-based)\n",
    "# ---------------------------\n",
    "def load_image_folder_dataset(path, image_size, batch_size=BATCH_SIZE):\n",
    "    log(\"Loading dataset folder:\", path, \"image_size:\", image_size)\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        path,\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=42,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        path,\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        seed=42,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    rescaler = layers.Rescaling(1.0 / 255)\n",
    "    train_ds = train_ds.map(lambda x, y: (rescaler(x), y)).prefetch(tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.map(lambda x, y: (rescaler(x), y)).prefetch(tf.data.AUTOTUNE)\n",
    "    return train_ds, val_ds\n",
    "\n",
    "# ---------------------------\n",
    "# Activation & gradient stats\n",
    "# ---------------------------\n",
    "def compute_activation_grad_stats(model, layer_names, dataset, max_batches=CALIB_BATCHES):\n",
    "    \"\"\"\n",
    "    For each layer in layer_names, compute:\n",
    "      - A: mean(abs(activation)) per filter/unit\n",
    "      - G: mean(abs(grad wrt activation)) per filter/unit\n",
    "      - V: variance(activation) per filter/unit\n",
    "    Returns: dict name -> (A, G, V)\n",
    "    \"\"\"\n",
    "    log(\"Computing activation & gradient stats...\")\n",
    "    results = {n: [] for n in layer_names}\n",
    "    grad_results = {n: [] for n in layer_names}\n",
    "    var_results = {n: [] for n in layer_names}\n",
    "\n",
    "    batch_count = 0\n",
    "    for x_batch, y_batch in dataset:\n",
    "        if batch_count >= max_batches:\n",
    "            break\n",
    "        batch_count += 1\n",
    "        layer_acts = {}\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            a = x_batch\n",
    "            for layer in model.layers:\n",
    "                a = layer(a)\n",
    "                if layer.name in layer_names:\n",
    "                    tape.watch(a)\n",
    "                    layer_acts[layer.name] = a\n",
    "            preds = a\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(y_batch, preds)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "\n",
    "        for name in layer_names:\n",
    "            a = layer_acts[name]\n",
    "            if len(a.shape) == 4:\n",
    "                A = tf.reduce_mean(tf.abs(a), axis=(0,1,2)).numpy()\n",
    "                V = tf.math.reduce_variance(a, axis=(0,1,2)).numpy()\n",
    "            else:\n",
    "                A = tf.reduce_mean(tf.abs(a), axis=0).numpy()\n",
    "                V = tf.math.reduce_variance(a, axis=0).numpy()\n",
    "\n",
    "            grad = tape.gradient(loss, a)\n",
    "            if grad is None:\n",
    "                G = np.zeros_like(A)\n",
    "            else:\n",
    "                if len(grad.shape) == 4:\n",
    "                    G = tf.reduce_mean(tf.abs(grad), axis=(0,1,2)).numpy()\n",
    "                else:\n",
    "                    G = tf.reduce_mean(tf.abs(grad), axis=0).numpy()\n",
    "\n",
    "            results[name].append(A)\n",
    "            var_results[name].append(V)\n",
    "            grad_results[name].append(G)\n",
    "        del tape\n",
    "\n",
    "    stats = {}\n",
    "    for name in layer_names:\n",
    "        A = np.mean(results[name], axis=0)\n",
    "        V = np.mean(var_results[name], axis=0)\n",
    "        G = np.mean(grad_results[name], axis=0)\n",
    "        stats[name] = (A, G, V)\n",
    "        log(f\"{name}: len={len(A)} meanA={A.mean():.6e} meanG={G.mean():.6e} meanV={V.mean():.6e}\")\n",
    "    return stats\n",
    "\n",
    "# ---------------------------\n",
    "# Importance scores & masks\n",
    "# ---------------------------\n",
    "def compute_importance_scores(stats, alpha=ALPHA, beta=BETA, gamma=GAMMA):\n",
    "    def normalize(x):\n",
    "        x = x - x.min()\n",
    "        if x.max() > 0:\n",
    "            x = x / x.max()\n",
    "        return x\n",
    "    scores = {}\n",
    "    for name, (A, G, V) in stats.items():\n",
    "        scores[name] = alpha * normalize(A) + beta * normalize(G) + gamma * normalize(V)\n",
    "    return scores\n",
    "\n",
    "def make_masks_from_scores(score_map, keep_ratio=KEEP_RATIO):\n",
    "    masks = {}\n",
    "    for name, score in score_map.items():\n",
    "        k = max(1, int(len(score) * keep_ratio))\n",
    "        thresh = np.partition(score, -k)[-k]\n",
    "        mask = (score >= thresh).astype(np.float32)\n",
    "        masks[name] = mask\n",
    "        log(f\"{name}: keep {int(mask.sum())}/{len(mask)}\")\n",
    "    return masks\n",
    "\n",
    "# ---------------------------\n",
    "# Mask gate layer & masked model\n",
    "# ---------------------------\n",
    "class CNNGate(tf.keras.layers.Layer):\n",
    "    def __init__(self, mask=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mask = tf.constant(mask, dtype=tf.float32) if mask is not None else None\n",
    "    def call(self, x):\n",
    "        if self.mask is None:\n",
    "            return x\n",
    "        if len(x.shape) == 4:\n",
    "            return x * tf.reshape(self.mask, (1,1,1,-1))\n",
    "        else:\n",
    "            return x * self.mask\n",
    "\n",
    "def build_masked_model(orig_model, masks):\n",
    "    log(\"Building masked model with gates...\")\n",
    "    inp = tf.keras.Input(shape=orig_model.input_shape[1:])\n",
    "    x = inp\n",
    "    for layer in orig_model.layers:\n",
    "        x = layer(x)\n",
    "        if layer.name in masks:\n",
    "            x = CNNGate(mask=masks[layer.name], name=layer.name + \"_gate\")(x)\n",
    "    masked = tf.keras.Model(inputs=inp, outputs=x, name=orig_model.name + \"_masked\")\n",
    "    # copy weights (best-effort)\n",
    "    for layer in orig_model.layers:\n",
    "        try:\n",
    "            masked_layer = masked.get_layer(layer.name)\n",
    "            masked_layer.set_weights(layer.get_weights())\n",
    "        except Exception:\n",
    "            # layer might not exist by same name (e.g., InputLayer) -> ignore\n",
    "            pass\n",
    "    return masked\n",
    "\n",
    "# ---------------------------\n",
    "# Structural pruning (safe)\n",
    "# ---------------------------\n",
    "def prune_structural_sequential(orig_model, masks, input_shape):\n",
    "    \"\"\"\n",
    "    Structural pruning for Sequential models.\n",
    "    - Prune Conv2D output filters using masks[layer.name]\n",
    "    - Prune Dense output units only (do not slice Dense input rows that come from Flatten/Conv)\n",
    "    - Attempt to slice BatchNorm params to match conv outputs\n",
    "    \"\"\"\n",
    "    log(\"Structural pruning (safe) start...\")\n",
    "    new_layers = []\n",
    "    prev_was_conv_like = False  # indicates that Flatten/Conv preceded Dense inputs\n",
    "\n",
    "    for layer in orig_model.layers:\n",
    "        # Conv2D: slice output channels\n",
    "        if isinstance(layer, layers.Conv2D):\n",
    "            W, b = layer.get_weights()\n",
    "            orig_out = W.shape[-1]\n",
    "            mask = masks.get(layer.name, np.ones(orig_out, dtype=np.float32))\n",
    "            keep_idx = np.where(mask == 1)[0]\n",
    "            if keep_idx.size == 0:\n",
    "                keep_idx = np.array([int(np.argmax(mask))], dtype=np.int32)\n",
    "            W_new = W[:, :, :, keep_idx]\n",
    "            b_new = b[keep_idx]\n",
    "            new_conv = layers.Conv2D(\n",
    "                filters=len(keep_idx),\n",
    "                kernel_size=layer.kernel_size,\n",
    "                strides=layer.strides,\n",
    "                padding=layer.padding,\n",
    "                activation=layer.activation,\n",
    "                use_bias=layer.use_bias,\n",
    "                name=layer.name + \"_pruned\"\n",
    "            )\n",
    "            new_layers.append((new_conv, [W_new, b_new]))\n",
    "            prev_was_conv_like = True\n",
    "            continue\n",
    "\n",
    "        # BatchNorm: slice params if prev was conv-like\n",
    "        if isinstance(layer, layers.BatchNormalization):\n",
    "            try:\n",
    "                weights = layer.get_weights()\n",
    "                if prev_was_conv_like and new_layers:\n",
    "                    prev_layer_obj, prev_w = new_layers[-1]\n",
    "                    if prev_w is not None:\n",
    "                        out_ch = prev_w[0].shape[-1]  # kernel last dim\n",
    "                        gamma, beta, mean, var = weights\n",
    "                        gamma = gamma[:out_ch]\n",
    "                        beta = beta[:out_ch]\n",
    "                        mean = mean[:out_ch]\n",
    "                        var = var[:out_ch]\n",
    "                        new_bn = layers.BatchNormalization.from_config(layer.get_config())\n",
    "                        new_layers.append((new_bn, [gamma, beta, mean, var]))\n",
    "                        continue\n",
    "            except Exception:\n",
    "                pass\n",
    "            # fallback keep BN as-is\n",
    "            try:\n",
    "                new_bn = layers.BatchNormalization.from_config(layer.get_config())\n",
    "                new_layers.append((new_bn, layer.get_weights()))\n",
    "            except Exception:\n",
    "                new_layers.append((layer, layer.get_weights() if hasattr(layer, \"get_weights\") else None))\n",
    "            # prev_was_conv_like unchanged\n",
    "            continue\n",
    "\n",
    "        # MaxPool/Activation/Dropout/Flatten/GlobalAvgPool: clone or reuse\n",
    "        if isinstance(layer, (layers.MaxPooling2D, layers.Activation, layers.ReLU, layers.Dropout, layers.Flatten, layers.GlobalAveragePooling2D)):\n",
    "            try:\n",
    "                cloned = layer.__class__.from_config(layer.get_config())\n",
    "                w = layer.get_weights() if hasattr(layer, \"get_weights\") else None\n",
    "                new_layers.append((cloned, w if w else None))\n",
    "            except Exception:\n",
    "                new_layers.append((layer, layer.get_weights() if hasattr(layer, \"get_weights\") else None))\n",
    "            if isinstance(layer, layers.Flatten) or isinstance(layer, layers.GlobalAveragePooling2D):\n",
    "                prev_was_conv_like = True\n",
    "            continue\n",
    "\n",
    "        # Dense: prune outputs only (safe)\n",
    "        if isinstance(layer, layers.Dense):\n",
    "            W, b = layer.get_weights()  # shape (in_dim, out_dim)\n",
    "            out_mask = masks.get(layer.name, np.ones(W.shape[1], dtype=np.float32))\n",
    "            out_idx = np.where(out_mask == 1)[0]\n",
    "            if out_idx.size == 0:\n",
    "                out_idx = np.array([int(np.argmax(out_mask))], dtype=np.int32)\n",
    "            W_new = W[:, out_idx]   # keep all input rows (safe)\n",
    "            b_new = b[out_idx]\n",
    "            new_dense = layers.Dense(units=W_new.shape[1], activation=layer.activation, name=layer.name + \"_pruned\")\n",
    "            new_layers.append((new_dense, [W_new, b_new]))\n",
    "            prev_was_conv_like = False\n",
    "            continue\n",
    "\n",
    "        # Fallback for other layers\n",
    "        try:\n",
    "            cloned = layer.__class__.from_config(layer.get_config())\n",
    "            w = layer.get_weights() if hasattr(layer, \"get_weights\") else None\n",
    "            new_layers.append((cloned, w if w else None))\n",
    "        except Exception:\n",
    "            new_layers.append((layer, layer.get_weights() if hasattr(layer, \"get_weights\") else None))\n",
    "        prev_was_conv_like = False\n",
    "\n",
    "    # Build new Sequential model with InputLayer\n",
    "    seq = models.Sequential(name=orig_model.name + \"_struct_pruned\")\n",
    "    seq.add(layers.InputLayer(input_shape=tuple(input_shape)))\n",
    "    for lyr_obj, w in new_layers:\n",
    "        seq.add(lyr_obj)\n",
    "        if w is not None:\n",
    "            try:\n",
    "                seq.layers[-1].set_weights(w)\n",
    "            except Exception as e:\n",
    "                log(\"Warning: couldn't set weights for\", seq.layers[-1].name, \":\", e)\n",
    "    log(\"Structural pruning complete. New model summary:\")\n",
    "    seq.summary()\n",
    "    return seq\n",
    "\n",
    "# ---------------------------\n",
    "# FLOPS and timing helpers\n",
    "# ---------------------------\n",
    "def calculate_conv_flops(input_shape, kernel_shape, strides=(1,1), padding='same'):\n",
    "    h_in, w_in, c_in = input_shape\n",
    "    kh, kw, _, c_out = kernel_shape\n",
    "    if padding == 'same':\n",
    "        h_out = math.ceil(h_in / strides[0])\n",
    "        w_out = math.ceil(w_in / strides[1])\n",
    "    else:\n",
    "        h_out = math.ceil((h_in - kh + 1) / strides[0])\n",
    "        w_out = math.ceil((w_in - kw + 1) / strides[1])\n",
    "    flops = h_out * w_out * (kh * kw * c_in) * c_out * 2\n",
    "    return flops, (h_out, w_out, c_out)\n",
    "\n",
    "def calculate_dense_flops(in_size, out_size):\n",
    "    return in_size * out_size * 2\n",
    "\n",
    "def calculate_model_flops(model, input_shape):\n",
    "    total = 0\n",
    "    current_shape = tuple(input_shape)\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, layers.Conv2D):\n",
    "            weights = layer.get_weights()\n",
    "            if not weights:\n",
    "                continue\n",
    "            kernel_shape = weights[0].shape  # (kh, kw, in_c, out_c)\n",
    "            layer_flops, current_shape = calculate_conv_flops(current_shape, kernel_shape, strides=layer.strides, padding=layer.padding)\n",
    "            total += layer_flops\n",
    "        elif isinstance(layer, layers.Flatten):\n",
    "            current_shape = (int(np.prod(current_shape)),)\n",
    "        elif isinstance(layer, layers.Dense):\n",
    "            in_size = current_shape[0] if isinstance(current_shape, tuple) and len(current_shape)>0 else int(current_shape)\n",
    "            layer_flops = calculate_dense_flops(in_size, layer.units)\n",
    "            total += layer_flops\n",
    "            current_shape = (layer.units,)\n",
    "        elif isinstance(layer, layers.MaxPooling2D):\n",
    "            h,w,c = current_shape\n",
    "            pool = layer.pool_size[0] if hasattr(layer.pool_size, \"__getitem__\") else layer.pool_size\n",
    "            current_shape = (h//pool, w//pool, c)\n",
    "        else:\n",
    "            # ignore other layers for shape changes\n",
    "            pass\n",
    "    return total\n",
    "\n",
    "def measure_inference_time(model, sample_batch, steps=20):\n",
    "    model.predict(sample_batch, verbose=0)  # warmup\n",
    "    t0 = time.time()\n",
    "    for _ in range(steps):\n",
    "        model.predict(sample_batch, verbose=0)\n",
    "    t1 = time.time()\n",
    "    return (t1 - t0) / steps\n",
    "\n",
    "# ---------------------------\n",
    "# Save masks helper\n",
    "# ---------------------------\n",
    "def save_masks(masks, path):\n",
    "    serial = {k: v.tolist() for k,v in masks.items()}\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(serial, f, indent=2)\n",
    "    log(\"Saved masks to\", path)\n",
    "\n",
    "# ---------------------------\n",
    "# Plot helper\n",
    "# ---------------------------\n",
    "def plot_mask_histograms(masks, outdir=SAVE_DIR):\n",
    "    if not PLOT_RESULTS:\n",
    "        return\n",
    "    for name, mask in masks.items():\n",
    "        plt.figure(figsize=(5,2))\n",
    "        plt.title(name)\n",
    "        plt.hist(mask, bins=2)\n",
    "        plt.xlabel(\"0=pruned, 1=kept\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(outdir, f\"mask_{name}.png\"))\n",
    "        plt.close()\n",
    "\n",
    "# ---------------------------\n",
    "# MAIN pipeline\n",
    "# ---------------------------\n",
    "def full_pipeline(model_path, dataset_path):\n",
    "    # 1) load model (safe)\n",
    "    model = safe_load_model(model_path)\n",
    "    log(\"Model loaded. Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    # compile original so evaluate works (use small lr default)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # 2) infer input shape\n",
    "    input_shape = model.input_shape[1:]\n",
    "    log(\"Inferred input shape:\", input_shape)\n",
    "\n",
    "    # 3) load dataset\n",
    "    train_ds, val_ds = load_image_folder_dataset(dataset_path, image_size=input_shape[:2], batch_size=BATCH_SIZE)\n",
    "    # calibration subset\n",
    "    calib_ds = train_ds.take(CALIB_BATCHES)\n",
    "\n",
    "    # sample for timing\n",
    "    try:\n",
    "        sample_x, _ = next(iter(val_ds))\n",
    "    except Exception:\n",
    "        sample_x, _ = next(iter(train_ds))\n",
    "    sample_x_small = sample_x[:min(16, sample_x.shape[0])]\n",
    "\n",
    "    # 4) choose layers to prune (conv + hidden dense only)\n",
    "    dense_layers = [lyr for lyr in model.layers if isinstance(lyr, layers.Dense)]\n",
    "    last_dense = dense_layers[-1] if dense_layers else None\n",
    "\n",
    "    prune_layer_names = []\n",
    "    for lyr in model.layers:\n",
    "        if isinstance(lyr, layers.Conv2D):\n",
    "            prune_layer_names.append(lyr.name)\n",
    "        elif isinstance(lyr, layers.Dense) and lyr is not last_dense:\n",
    "            prune_layer_names.append(lyr.name)\n",
    "    log(\"Layers considered for pruning:\", prune_layer_names)\n",
    "\n",
    "    # 5) compute stats\n",
    "    stats = compute_activation_grad_stats(model, prune_layer_names, calib_ds, max_batches=CALIB_BATCHES)\n",
    "\n",
    "    # 6) importance & masks\n",
    "    score_map = compute_importance_scores(stats)\n",
    "    masks = make_masks_from_scores(score_map, keep_ratio=KEEP_RATIO)\n",
    "    save_masks(masks, os.path.join(SAVE_DIR, \"masks.json\"))\n",
    "    plot_mask_histograms(masks)\n",
    "\n",
    "    # 7) build masked model and compile\n",
    "    masked_model = build_masked_model(model, masks)\n",
    "    masked_model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    log(\"Masked model built.\")\n",
    "\n",
    "    # quick eval before FT\n",
    "    try:\n",
    "        loss0, acc0 = masked_model.evaluate(val_ds.take(5), verbose=0)\n",
    "        log(\"Masked model pre-FT acc:\", acc0)\n",
    "    except Exception as e:\n",
    "        log(\"Masked model pre-eval failed:\", e)\n",
    "\n",
    "    # 8) measure baseline flops & time\n",
    "    baseline_flops = calculate_model_flops(model, input_shape)\n",
    "    baseline_time = measure_inference_time(model, sample_x_small, steps=10)\n",
    "    log(f\"Baseline FLOPS: {baseline_flops:,}, baseline time (avg batch): {baseline_time:.4f}s\")\n",
    "\n",
    "    # 9) fine-tune masked model\n",
    "    try:\n",
    "        masked_model.fit(train_ds.take(FT_BATCHES_TO_USE), validation_data=val_ds.take(5), epochs=FT_EPOCHS, verbose=2)\n",
    "    except Exception as e:\n",
    "        log(\"Masked fine-tune failed/partial:\", e)\n",
    "\n",
    "    # 10) structural prune\n",
    "    pruned_model = prune_structural_sequential(model, masks, input_shape)\n",
    "    # compile pruned model for evaluation\n",
    "    pruned_model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # 11) evaluate models\n",
    "    log(\"Evaluating Original model:\")\n",
    "    orig_loss, orig_acc = model.evaluate(val_ds, verbose=0)\n",
    "    log(\"Original acc:\", orig_acc)\n",
    "\n",
    "    log(\"Evaluating Masked model (after FT):\")\n",
    "    try:\n",
    "        mask_loss, mask_acc = masked_model.evaluate(val_ds, verbose=0)\n",
    "        log(\"Masked acc:\", mask_acc)\n",
    "    except Exception as e:\n",
    "        log(\"Masked evaluate failed:\", e)\n",
    "        mask_acc = None\n",
    "\n",
    "    log(\"Evaluating Pruned model:\")\n",
    "    try:\n",
    "        pruned_loss, pruned_acc = pruned_model.evaluate(val_ds, verbose=0)\n",
    "        log(\"Pruned acc:\", pruned_acc)\n",
    "    except Exception as e:\n",
    "        log(\"Pruned evaluate failed:\", e)\n",
    "        pruned_acc = None\n",
    "\n",
    "    # 12) FLOPS & timing after prune\n",
    "    pruned_flops = calculate_model_flops(pruned_model, input_shape)\n",
    "    pruned_time = measure_inference_time(pruned_model, sample_x_small, steps=10)\n",
    "    log(f\"Pruned FLOPS: {pruned_flops:,}, pruned time: {pruned_time:.4f}s\")\n",
    "\n",
    "    # 13) summary & save\n",
    "    reduction = 1.0 - (pruned_flops / baseline_flops) if baseline_flops > 0 else 0.0\n",
    "    log(\"=\"*60)\n",
    "    log(\"SUMMARY:\")\n",
    "    log(f\"Baseline FLOPS: {baseline_flops:,}\")\n",
    "    log(f\"Pruned FLOPS:   {pruned_flops:,}\")\n",
    "    log(f\"FLOPS reduction: {reduction:.2%}\")\n",
    "    log(f\"Original acc: {orig_acc}, Masked acc: {mask_acc}, Pruned acc: {pruned_acc}\")\n",
    "    log(\"=\"*60)\n",
    "\n",
    "    # save artifacts\n",
    "    try:\n",
    "        model.save(os.path.join(SAVE_DIR, \"model_baseline\"))\n",
    "        masked_model.save(os.path.join(SAVE_DIR, \"model_masked\"))\n",
    "        pruned_model.save(os.path.join(SAVE_DIR, \"model_pruned\"))\n",
    "        log(\"Saved models to\", SAVE_DIR)\n",
    "    except Exception as e:\n",
    "        log(\"Save models failed:\", e)\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"masked_model\": masked_model,\n",
    "        \"pruned_model\": pruned_model,\n",
    "        \"masks\": masks,\n",
    "        \"baseline_flops\": baseline_flops,\n",
    "        \"pruned_flops\": pruned_flops,\n",
    "        \"baseline_time\": baseline_time,\n",
    "        \"pruned_time\": pruned_time,\n",
    "        \"orig_acc\": orig_acc,\n",
    "        \"mask_acc\": mask_acc,\n",
    "        \"pruned_acc\": pruned_acc\n",
    "    }\n",
    "\n",
    "# ---------------------------\n",
    "# Run\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    out = full_pipeline(MODEL_PATH, DATASET_PATH)\n",
    "    log(\"Pipeline finished. Outputs:\", out.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc04a3a",
   "metadata": {},
   "source": [
    "# **CNN structure Pruning with 5 Epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08f6d0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading model: D:\\college\\sem-8\\models\\garbage_cnn_model.h5\n",
      "[INFO] Loaded model directly.\n",
      "[INFO] Model loaded. Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36992</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">9,470,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,542</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36992\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m9,470,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │         \u001b[38;5;34m1,542\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,564,998</span> (36.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,564,998\u001b[0m (36.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,564,998</span> (36.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,564,998\u001b[0m (36.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inferred input shape: (150, 150, 3)\n",
      "[INFO] Loading dataset folder: D:\\college\\sem-8\\dataset\\reduced_garbage_dataset image_size: (150, 150)\n",
      "Found 756 files belonging to 6 classes.\n",
      "Using 605 files for training.\n",
      "Found 756 files belonging to 6 classes.\n",
      "Using 151 files for validation.\n",
      "[INFO] Layers to prune: ['conv2d_8', 'conv2d_9', 'conv2d_10', 'dense_4']\n",
      "[INFO] Computing activation & gradient stats...\n",
      "[INFO] conv2d_8: len=32 meanA=3.914551e-02 meanG=5.343915e-06 meanV=1.229239e-03\n",
      "[INFO] conv2d_9: len=64 meanA=1.608497e-02 meanG=1.140270e-05 meanV=7.512871e-04\n",
      "[INFO] conv2d_10: len=128 meanA=4.776659e-03 meanG=2.893262e-05 meanV=5.881802e-04\n",
      "[INFO] dense_4: len=256 meanA=1.979771e-01 meanG=7.181034e-04 meanV=2.772424e-01\n",
      "[INFO] conv2d_8: keep 22/32\n",
      "[INFO] conv2d_9: keep 44/64\n",
      "[INFO] conv2d_10: keep 89/128\n",
      "[INFO] dense_4: keep 179/256\n",
      "[INFO] Saved masks to pruning_output\\masks.json\n",
      "[INFO] Building masked model with gates...\n",
      "[INFO] Masked model pre-FT acc: 0.7682119011878967\n",
      "[INFO] Baseline FLOPS: 418,355,200 (0.418355 GFLOPS), baseline time (avg batch): 0.2519s\n",
      "Epoch 1/5\n",
      "10/10 - 15s - 1s/step - accuracy: 0.6397 - loss: 0.9974 - val_accuracy: 0.7881 - val_loss: 0.6619\n",
      "Epoch 2/5\n",
      "10/10 - 11s - 1s/step - accuracy: 0.6579 - loss: 0.9234 - val_accuracy: 0.7815 - val_loss: 0.6501\n",
      "Epoch 3/5\n",
      "10/10 - 14s - 1s/step - accuracy: 0.6744 - loss: 0.8784 - val_accuracy: 0.7881 - val_loss: 0.6497\n",
      "Epoch 4/5\n",
      "10/10 - 13s - 1s/step - accuracy: 0.6628 - loss: 0.8868 - val_accuracy: 0.7947 - val_loss: 0.6289\n",
      "Epoch 5/5\n",
      "10/10 - 10s - 1s/step - accuracy: 0.6711 - loss: 0.8536 - val_accuracy: 0.7881 - val_loss: 0.6167\n",
      "[INFO] Structural pruning (safe) start...\n",
      "[INFO] Warning: couldn't set weights for conv2d_9_pruned : Layer conv2d_9_pruned weight shape (3, 3, 22, 44) is not compatible with provided weight shape (3, 3, 32, 44).\n",
      "[INFO] Warning: couldn't set weights for conv2d_10_pruned : Layer conv2d_10_pruned weight shape (3, 3, 44, 89) is not compatible with provided weight shape (3, 3, 64, 89).\n",
      "[INFO] Warning: couldn't set weights for dense_4_pruned : Layer dense_4_pruned weight shape (25721, 179) is not compatible with provided weight shape (36992, 179).\n",
      "[INFO] Warning: couldn't set weights for dense_5_pruned : Layer dense_5_pruned weight shape (179, 6) is not compatible with provided weight shape (256, 6).\n",
      "[INFO] Structural pruning complete. New model summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ishan\\Documents\\sample_p1\\env\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2_struct_pruned\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2_struct_pruned\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_8_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">616</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,756</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">35,333</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25721</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">179</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,604,238</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">179</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,080</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_8_pruned (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m22\u001b[0m)   │           \u001b[38;5;34m616\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m22\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9_pruned (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m44\u001b[0m)     │         \u001b[38;5;34m8,756\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m44\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10_pruned (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m89\u001b[0m)     │        \u001b[38;5;34m35,333\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m89\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25721\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4_pruned (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m179\u001b[0m)            │     \u001b[38;5;34m4,604,238\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m179\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5_pruned (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │         \u001b[38;5;34m1,080\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,650,023</span> (17.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,650,023\u001b[0m (17.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,650,023</span> (17.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,650,023\u001b[0m (17.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Evaluating Original model:\n",
      "[INFO] Original acc: 0.7947019934654236\n",
      "[INFO] Evaluating Masked model (after FT):\n",
      "[INFO] Masked acc: 0.7880794405937195\n",
      "[INFO] Evaluating Pruned model:\n",
      "[INFO] Pruned acc: 0.13907285034656525\n",
      "[INFO] Pruned FLOPS: 207,042,362 (0.207042 GFLOPS), pruned time: 0.1718s\n",
      "[INFO] ======================================================================\n",
      "[INFO] FINAL SUMMARY\n",
      "[INFO] ======================================================================\n",
      "[INFO] Baseline GFLOPS: 0.418355 GFLOPS\n",
      "[INFO] Pruned GFLOPS:   0.207042 GFLOPS\n",
      "[INFO] FLOPS reduction: 50.51%\n",
      "[INFO] Baseline time (avg batch): 0.2519s\n",
      "[INFO] Pruned time (avg batch):   0.1718s\n",
      "[INFO] Speed-up ratio (baseline/pruned): 1.466x\n",
      "[INFO] Original acc: 0.7947, Pruned acc: 0.1391\n",
      "[INFO] Accuracy drop: 0.6556 (82.50%)\n",
      "[INFO] Original params: 9,564,998, Pruned params: 4,650,023\n",
      "[INFO] Parameter reduction: 51.39%\n",
      "[INFO] Per-layer remaining (kept/total):\n",
      "[INFO]   conv2d_8: 22/32 (68.75%)\n",
      "[INFO]   conv2d_9: 44/64 (68.75%)\n",
      "[INFO]   conv2d_10: 89/128 (69.53%)\n",
      "[INFO]   dense_4: 179/256 (69.92%)\n",
      "[INFO] ======================================================================\n",
      "[INFO] Saved model to pruning_output\\model_baseline.keras\n",
      "[INFO] Failed to save model to pruning_output\\model_masked.keras : \n",
      "Object CNNGate was created by passing\n",
      "non-serializable argument values in `__init__()`,\n",
      "and therefore the object must override `get_config()` in\n",
      "order to be serializable. Please implement `get_config()`.\n",
      "\n",
      "Example:\n",
      "\n",
      "class CustomLayer(keras.layers.Layer):\n",
      "    def __init__(self, arg1, arg2, **kwargs):\n",
      "        super().__init__(**kwargs)\n",
      "        self.arg1 = arg1\n",
      "        self.arg2 = arg2\n",
      "\n",
      "    def get_config(self):\n",
      "        config = super().get_config()\n",
      "        config.update({\n",
      "            \"arg1\": self.arg1,\n",
      "            \"arg2\": self.arg2,\n",
      "        })\n",
      "        return config\n",
      "[INFO] Saved model to pruning_output\\model_pruned.keras\n",
      "[INFO] Saved metadata to pruning_output\\prune_summary.json\n",
      "[INFO] Pipeline finished. Keys saved in metadata: dict_keys(['baseline_flops', 'pruned_flops', 'baseline_gflops', 'pruned_gflops', 'baseline_time', 'pruned_time', 'orig_acc', 'pruned_acc', 'mask_acc', 'orig_params', 'pruned_params', 'param_reduction_pct', 'per_layer_stats'])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "sequential_cnn_pruning_metrics.py\n",
    "Extended Sequential CNN pruning pipeline with detailed metrics:\n",
    "- GFLOPS (baseline & pruned)\n",
    "- Speed-up ratio\n",
    "- Accuracy drop %\n",
    "- Parameter reduction %\n",
    "- Per-layer remaining filters/neurons\n",
    "- Saves models with .keras extension\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# ---------------------------\n",
    "# USER CONFIG\n",
    "# ---------------------------\n",
    "MODEL_PATH = r\"D:\\college\\sem-8\\models\\garbage_cnn_model.h5\"   # path to model (.h5/.keras or SavedModel dir)\n",
    "DATASET_PATH = r\"D:\\college\\sem-8\\dataset\\reduced_garbage_dataset\"      # folder with subfolders per class\n",
    "SAVE_DIR = r\"pruning_output\"                                 # where outputs are saved\n",
    "MODEL_SAVE_EXT = \".keras\"   # use \".keras\" or \".h5\"\n",
    "\n",
    "KEEP_RATIO = 0.7            # fraction of channels/units to keep\n",
    "ALPHA, BETA, GAMMA = 0.4, 0.3, 0.3  # importance weights\n",
    "BATCH_SIZE = 64\n",
    "CALIB_BATCHES = 30\n",
    "FT_EPOCHS = 5\n",
    "FT_BATCHES_TO_USE = 150\n",
    "PLOT_RESULTS = True\n",
    "VERBOSE = True\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def log(*args):\n",
    "    if VERBOSE:\n",
    "        print(\"[INFO]\", *args)\n",
    "\n",
    "# ---------------------------\n",
    "# Safe load model (handles '/' in h5 layer names)\n",
    "# ---------------------------\n",
    "def safe_load_model(model_path):\n",
    "    log(\"Loading model:\", model_path)\n",
    "    try:\n",
    "        m = tf.keras.models.load_model(model_path, compile=False)\n",
    "        log(\"Loaded model directly.\")\n",
    "        return m\n",
    "    except Exception as e:\n",
    "        log(\"Direct load failed:\", e)\n",
    "\n",
    "    try:\n",
    "        with h5py.File(model_path, \"r\") as f:\n",
    "            if \"model_config\" in f:\n",
    "                raw = f[\"model_config\"][()]\n",
    "                if isinstance(raw, bytes):\n",
    "                    raw = raw.decode(\"utf-8\")\n",
    "                cfg_json = json.loads(raw)\n",
    "                changed = False\n",
    "                for layer in cfg_json.get(\"config\", {}).get(\"layers\", []):\n",
    "                    cfg = layer.get(\"config\", {})\n",
    "                    name = cfg.get(\"name\")\n",
    "                    if isinstance(name, str) and \"/\" in name:\n",
    "                        new_name = name.replace(\"/\", \"_\")\n",
    "                        cfg[\"name\"] = new_name\n",
    "                        changed = True\n",
    "                        log(f\"[FIX] layer name: {name} -> {new_name}\")\n",
    "                if changed:\n",
    "                    fixed_json = json.dumps(cfg_json)\n",
    "                    model = tf.keras.models.model_from_json(fixed_json)\n",
    "                    model.load_weights(model_path)\n",
    "                    log(\"Loaded model from sanitized JSON + weights.\")\n",
    "                    return model\n",
    "    except Exception as e2:\n",
    "        log(\"H5 sanitization attempt failed:\", e2)\n",
    "\n",
    "    try:\n",
    "        m = tf.keras.models.load_model(model_path, compile=False, safe_mode=False)\n",
    "        log(\"Loaded model with safe_mode=False.\")\n",
    "        return m\n",
    "    except Exception as e3:\n",
    "        log(\"All load attempts failed:\", e3)\n",
    "        raise RuntimeError(\"Failed to load model. Ensure path and format are correct.\")\n",
    "\n",
    "# ---------------------------\n",
    "# Dataset loader (folder-based)\n",
    "# ---------------------------\n",
    "def load_image_folder_dataset(path, image_size, batch_size=BATCH_SIZE):\n",
    "    log(\"Loading dataset folder:\", path, \"image_size:\", image_size)\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        path,\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=42,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        path,\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        seed=42,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    rescaler = layers.Rescaling(1.0 / 255)\n",
    "    train_ds = train_ds.map(lambda x, y: (rescaler(x), y)).prefetch(tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.map(lambda x, y: (rescaler(x), y)).prefetch(tf.data.AUTOTUNE)\n",
    "    return train_ds, val_ds\n",
    "\n",
    "# ---------------------------\n",
    "# Activation & gradient stats\n",
    "# ---------------------------\n",
    "def compute_activation_grad_stats(model, layer_names, dataset, max_batches=CALIB_BATCHES):\n",
    "    log(\"Computing activation & gradient stats...\")\n",
    "    results = {n: [] for n in layer_names}\n",
    "    grad_results = {n: [] for n in layer_names}\n",
    "    var_results = {n: [] for n in layer_names}\n",
    "    batch_count = 0\n",
    "    for x_batch, y_batch in dataset:\n",
    "        if batch_count >= max_batches:\n",
    "            break\n",
    "        batch_count += 1\n",
    "        layer_acts = {}\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            a = x_batch\n",
    "            for layer in model.layers:\n",
    "                a = layer(a)\n",
    "                if layer.name in layer_names:\n",
    "                    tape.watch(a)\n",
    "                    layer_acts[layer.name] = a\n",
    "            preds = a\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(y_batch, preds)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "        for name in layer_names:\n",
    "            a = layer_acts[name]\n",
    "            if len(a.shape) == 4:\n",
    "                A = tf.reduce_mean(tf.abs(a), axis=(0,1,2)).numpy()\n",
    "                V = tf.math.reduce_variance(a, axis=(0,1,2)).numpy()\n",
    "            else:\n",
    "                A = tf.reduce_mean(tf.abs(a), axis=0).numpy()\n",
    "                V = tf.math.reduce_variance(a, axis=0).numpy()\n",
    "            grad = tape.gradient(loss, a)\n",
    "            if grad is None:\n",
    "                G = np.zeros_like(A)\n",
    "            else:\n",
    "                if len(grad.shape) == 4:\n",
    "                    G = tf.reduce_mean(tf.abs(grad), axis=(0,1,2)).numpy()\n",
    "                else:\n",
    "                    G = tf.reduce_mean(tf.abs(grad), axis=0).numpy()\n",
    "            results[name].append(A)\n",
    "            var_results[name].append(V)\n",
    "            grad_results[name].append(G)\n",
    "        del tape\n",
    "    stats = {}\n",
    "    for name in layer_names:\n",
    "        A = np.mean(results[name], axis=0)\n",
    "        V = np.mean(var_results[name], axis=0)\n",
    "        G = np.mean(grad_results[name], axis=0)\n",
    "        stats[name] = (A, G, V)\n",
    "        log(f\"{name}: len={len(A)} meanA={A.mean():.6e} meanG={G.mean():.6e} meanV={V.mean():.6e}\")\n",
    "    return stats\n",
    "\n",
    "# ---------------------------\n",
    "# Importance scores & masks\n",
    "# ---------------------------\n",
    "def compute_importance_scores(stats, alpha=ALPHA, beta=BETA, gamma=GAMMA):\n",
    "    def normalize(x):\n",
    "        x = x - x.min()\n",
    "        if x.max() > 0:\n",
    "            x = x / x.max()\n",
    "        return x\n",
    "    scores = {}\n",
    "    for name, (A, G, V) in stats.items():\n",
    "        scores[name] = alpha * normalize(A) + beta * normalize(G) + gamma * normalize(V)\n",
    "    return scores\n",
    "\n",
    "def make_masks_from_scores(score_map, keep_ratio=KEEP_RATIO):\n",
    "    masks = {}\n",
    "    for name, score in score_map.items():\n",
    "        k = max(1, int(len(score) * keep_ratio))\n",
    "        thresh = np.partition(score, -k)[-k]\n",
    "        mask = (score >= thresh).astype(np.float32)\n",
    "        masks[name] = mask\n",
    "        log(f\"{name}: keep {int(mask.sum())}/{len(mask)}\")\n",
    "    return masks\n",
    "\n",
    "# ---------------------------\n",
    "# Mask gate layer & masked model\n",
    "# ---------------------------\n",
    "class CNNGate(tf.keras.layers.Layer):\n",
    "    def __init__(self, mask=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mask = tf.constant(mask, dtype=tf.float32) if mask is not None else None\n",
    "    def call(self, x):\n",
    "        if self.mask is None:\n",
    "            return x\n",
    "        if len(x.shape) == 4:\n",
    "            return x * tf.reshape(self.mask, (1,1,1,-1))\n",
    "        else:\n",
    "            return x * self.mask\n",
    "\n",
    "def build_masked_model(orig_model, masks):\n",
    "    log(\"Building masked model with gates...\")\n",
    "    inp = tf.keras.Input(shape=orig_model.input_shape[1:])\n",
    "    x = inp\n",
    "    for layer in orig_model.layers:\n",
    "        x = layer(x)\n",
    "        if layer.name in masks:\n",
    "            x = CNNGate(mask=masks[layer.name], name=layer.name + \"_gate\")(x)\n",
    "    masked = tf.keras.Model(inputs=inp, outputs=x, name=orig_model.name + \"_masked\")\n",
    "    for layer in orig_model.layers:\n",
    "        try:\n",
    "            masked_layer = masked.get_layer(layer.name)\n",
    "            masked_layer.set_weights(layer.get_weights())\n",
    "        except Exception:\n",
    "            pass\n",
    "    return masked\n",
    "\n",
    "# ---------------------------\n",
    "# Structural pruning (safe)\n",
    "# ---------------------------\n",
    "def prune_structural_sequential(orig_model, masks, input_shape):\n",
    "    log(\"Structural pruning (safe) start...\")\n",
    "    new_layers = []\n",
    "    prev_was_conv_like = False\n",
    "    for layer in orig_model.layers:\n",
    "        if isinstance(layer, layers.Conv2D):\n",
    "            W, b = layer.get_weights()\n",
    "            orig_out = W.shape[-1]\n",
    "            mask = masks.get(layer.name, np.ones(orig_out, dtype=np.float32))\n",
    "            keep_idx = np.where(mask == 1)[0]\n",
    "            if keep_idx.size == 0:\n",
    "                keep_idx = np.array([int(np.argmax(mask))], dtype=np.int32)\n",
    "            W_new = W[:, :, :, keep_idx]\n",
    "            b_new = b[keep_idx]\n",
    "            new_conv = layers.Conv2D(\n",
    "                filters=len(keep_idx),\n",
    "                kernel_size=layer.kernel_size,\n",
    "                strides=layer.strides,\n",
    "                padding=layer.padding,\n",
    "                activation=layer.activation,\n",
    "                use_bias=layer.use_bias,\n",
    "                name=layer.name + \"_pruned\"\n",
    "            )\n",
    "            new_layers.append((new_conv, [W_new, b_new]))\n",
    "            prev_was_conv_like = True\n",
    "            continue\n",
    "        if isinstance(layer, layers.BatchNormalization):\n",
    "            try:\n",
    "                weights = layer.get_weights()\n",
    "                if prev_was_conv_like and new_layers:\n",
    "                    prev_layer_obj, prev_w = new_layers[-1]\n",
    "                    if prev_w is not None:\n",
    "                        out_ch = prev_w[0].shape[-1]\n",
    "                        gamma, beta, mean, var = weights\n",
    "                        gamma = gamma[:out_ch]\n",
    "                        beta = beta[:out_ch]\n",
    "                        mean = mean[:out_ch]\n",
    "                        var = var[:out_ch]\n",
    "                        new_bn = layers.BatchNormalization.from_config(layer.get_config())\n",
    "                        new_layers.append((new_bn, [gamma, beta, mean, var]))\n",
    "                        continue\n",
    "            except Exception:\n",
    "                pass\n",
    "            try:\n",
    "                new_bn = layers.BatchNormalization.from_config(layer.get_config())\n",
    "                new_layers.append((new_bn, layer.get_weights()))\n",
    "            except Exception:\n",
    "                new_layers.append((layer, layer.get_weights() if hasattr(layer, \"get_weights\") else None))\n",
    "            continue\n",
    "        if isinstance(layer, (layers.MaxPooling2D, layers.Activation, layers.ReLU, layers.Dropout, layers.Flatten, layers.GlobalAveragePooling2D)):\n",
    "            try:\n",
    "                cloned = layer.__class__.from_config(layer.get_config())\n",
    "                w = layer.get_weights() if hasattr(layer, \"get_weights\") else None\n",
    "                new_layers.append((cloned, w if w else None))\n",
    "            except Exception:\n",
    "                new_layers.append((layer, layer.get_weights() if hasattr(layer, \"get_weights\") else None))\n",
    "            if isinstance(layer, layers.Flatten) or isinstance(layer, layers.GlobalAveragePooling2D):\n",
    "                prev_was_conv_like = True\n",
    "            continue\n",
    "        if isinstance(layer, layers.Dense):\n",
    "            W, b = layer.get_weights()\n",
    "            out_mask = masks.get(layer.name, np.ones(W.shape[1], dtype=np.float32))\n",
    "            out_idx = np.where(out_mask == 1)[0]\n",
    "            if out_idx.size == 0:\n",
    "                out_idx = np.array([int(np.argmax(out_mask))], dtype=np.int32)\n",
    "            W_new = W[:, out_idx]\n",
    "            b_new = b[out_idx]\n",
    "            new_dense = layers.Dense(units=W_new.shape[1], activation=layer.activation, name=layer.name + \"_pruned\")\n",
    "            new_layers.append((new_dense, [W_new, b_new]))\n",
    "            prev_was_conv_like = False\n",
    "            continue\n",
    "        try:\n",
    "            cloned = layer.__class__.from_config(layer.get_config())\n",
    "            w = layer.get_weights() if hasattr(layer, \"get_weights\") else None\n",
    "            new_layers.append((cloned, w if w else None))\n",
    "        except Exception:\n",
    "            new_layers.append((layer, layer.get_weights() if hasattr(layer, \"get_weights\") else None))\n",
    "        prev_was_conv_like = False\n",
    "    seq = models.Sequential(name=orig_model.name + \"_struct_pruned\")\n",
    "    seq.add(layers.InputLayer(input_shape=tuple(input_shape)))\n",
    "    for lyr_obj, w in new_layers:\n",
    "        seq.add(lyr_obj)\n",
    "        if w is not None:\n",
    "            try:\n",
    "                seq.layers[-1].set_weights(w)\n",
    "            except Exception as e:\n",
    "                log(\"Warning: couldn't set weights for\", seq.layers[-1].name, \":\", e)\n",
    "    log(\"Structural pruning complete. New model summary:\")\n",
    "    seq.summary()\n",
    "    return seq\n",
    "\n",
    "# ---------------------------\n",
    "# FLOPS and timing helpers\n",
    "# ---------------------------\n",
    "def calculate_conv_flops(input_shape, kernel_shape, strides=(1,1), padding='same'):\n",
    "    h_in, w_in, c_in = input_shape\n",
    "    kh, kw, _, c_out = kernel_shape\n",
    "    if padding == 'same':\n",
    "        h_out = math.ceil(h_in / strides[0])\n",
    "        w_out = math.ceil(w_in / strides[1])\n",
    "    else:\n",
    "        h_out = math.ceil((h_in - kh + 1) / strides[0])\n",
    "        w_out = math.ceil((w_in - kw + 1) / strides[1])\n",
    "    flops = h_out * w_out * (kh * kw * c_in) * c_out * 2\n",
    "    return flops, (h_out, w_out, c_out)\n",
    "\n",
    "def calculate_dense_flops(in_size, out_size):\n",
    "    return in_size * out_size * 2\n",
    "\n",
    "def calculate_model_flops(model, input_shape):\n",
    "    total = 0\n",
    "    current_shape = tuple(input_shape)\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, layers.Conv2D):\n",
    "            weights = layer.get_weights()\n",
    "            if not weights:\n",
    "                continue\n",
    "            kernel_shape = weights[0].shape\n",
    "            layer_flops, current_shape = calculate_conv_flops(current_shape, kernel_shape, strides=layer.strides, padding=layer.padding)\n",
    "            total += layer_flops\n",
    "        elif isinstance(layer, layers.Flatten):\n",
    "            current_shape = (int(np.prod(current_shape)),)\n",
    "        elif isinstance(layer, layers.Dense):\n",
    "            in_size = current_shape[0] if isinstance(current_shape, tuple) and len(current_shape)>0 else int(current_shape)\n",
    "            layer_flops = calculate_dense_flops(in_size, layer.units)\n",
    "            total += layer_flops\n",
    "            current_shape = (layer.units,)\n",
    "        elif isinstance(layer, layers.MaxPooling2D):\n",
    "            h,w,c = current_shape\n",
    "            pool = layer.pool_size[0] if hasattr(layer.pool_size, \"__getitem__\") else layer.pool_size\n",
    "            current_shape = (h//pool, w//pool, c)\n",
    "        else:\n",
    "            pass\n",
    "    return total\n",
    "\n",
    "def measure_inference_time(model, sample_batch, steps=20):\n",
    "    model.predict(sample_batch, verbose=0)\n",
    "    t0 = time.time()\n",
    "    for _ in range(steps):\n",
    "        model.predict(sample_batch, verbose=0)\n",
    "    t1 = time.time()\n",
    "    return (t1 - t0) / steps\n",
    "\n",
    "# ---------------------------\n",
    "# Save helpers\n",
    "# ---------------------------\n",
    "def save_masks(masks, path):\n",
    "    serial = {k: v.tolist() for k,v in masks.items()}\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(serial, f, indent=2)\n",
    "    log(\"Saved masks to\", path)\n",
    "\n",
    "def save_model_safe(model, path_no_ext):\n",
    "    # choose extension from global config\n",
    "    ext = MODEL_SAVE_EXT if MODEL_SAVE_EXT.startswith(\".\") else \".\" + MODEL_SAVE_EXT\n",
    "    fullpath = path_no_ext + ext\n",
    "    try:\n",
    "        model.save(fullpath)\n",
    "        log(\"Saved model to\", fullpath)\n",
    "    except Exception as e:\n",
    "        log(\"Failed to save model to\", fullpath, \":\", e)\n",
    "\n",
    "# ---------------------------\n",
    "# Plot helper\n",
    "# ---------------------------\n",
    "def plot_mask_histograms(masks, outdir=SAVE_DIR):\n",
    "    if not PLOT_RESULTS:\n",
    "        return\n",
    "    for name, mask in masks.items():\n",
    "        plt.figure(figsize=(5,2))\n",
    "        plt.title(name)\n",
    "        plt.hist(mask, bins=2)\n",
    "        plt.xlabel(\"0=pruned, 1=kept\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(outdir, f\"mask_{name}.png\"))\n",
    "        plt.close()\n",
    "\n",
    "# ---------------------------\n",
    "# Per-layer stat helper\n",
    "# ---------------------------\n",
    "def per_layer_remaining_stats(masks):\n",
    "    stats = {}\n",
    "    for name, mask in masks.items():\n",
    "        total = len(mask)\n",
    "        kept = int(mask.sum())\n",
    "        stats[name] = {\"kept\": kept, \"total\": total, \"ratio\": kept/total}\n",
    "    return stats\n",
    "\n",
    "# ---------------------------\n",
    "# MAIN pipeline\n",
    "# ---------------------------\n",
    "def full_pipeline(model_path, dataset_path):\n",
    "    model = safe_load_model(model_path)\n",
    "    log(\"Model loaded. Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    # compile original for evaluation\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    input_shape = model.input_shape[1:]\n",
    "    log(\"Inferred input shape:\", input_shape)\n",
    "\n",
    "    train_ds, val_ds = load_image_folder_dataset(dataset_path, image_size=input_shape[:2], batch_size=BATCH_SIZE)\n",
    "    calib_ds = train_ds.take(CALIB_BATCHES)\n",
    "\n",
    "    try:\n",
    "        sample_x, _ = next(iter(val_ds))\n",
    "    except Exception:\n",
    "        sample_x, _ = next(iter(train_ds))\n",
    "    sample_x_small = sample_x[:min(16, sample_x.shape[0])]\n",
    "\n",
    "    dense_layers = [lyr for lyr in model.layers if isinstance(lyr, layers.Dense)]\n",
    "    last_dense = dense_layers[-1] if dense_layers else None\n",
    "\n",
    "    prune_layer_names = []\n",
    "    for lyr in model.layers:\n",
    "        if isinstance(lyr, layers.Conv2D):\n",
    "            prune_layer_names.append(lyr.name)\n",
    "        elif isinstance(lyr, layers.Dense) and lyr is not last_dense:\n",
    "            prune_layer_names.append(lyr.name)\n",
    "    log(\"Layers to prune:\", prune_layer_names)\n",
    "\n",
    "    stats = compute_activation_grad_stats(model, prune_layer_names, calib_ds, max_batches=CALIB_BATCHES)\n",
    "    score_map = compute_importance_scores(stats)\n",
    "    masks = make_masks_from_scores(score_map, keep_ratio=KEEP_RATIO)\n",
    "    save_masks(masks, os.path.join(SAVE_DIR, \"masks.json\"))\n",
    "    plot_mask_histograms(masks)\n",
    "\n",
    "    masked_model = build_masked_model(model, masks)\n",
    "    masked_model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    try:\n",
    "        loss0, acc0 = masked_model.evaluate(val_ds.take(5), verbose=0)\n",
    "        log(\"Masked model pre-FT acc:\", acc0)\n",
    "    except Exception as e:\n",
    "        log(\"Masked model pre-eval failed:\", e)\n",
    "\n",
    "    baseline_flops = calculate_model_flops(model, input_shape)\n",
    "    baseline_gflops = baseline_flops / 1e9\n",
    "    baseline_time = measure_inference_time(model, sample_x_small, steps=10)\n",
    "    log(f\"Baseline FLOPS: {baseline_flops:,} ({baseline_gflops:.6f} GFLOPS), baseline time (avg batch): {baseline_time:.4f}s\")\n",
    "\n",
    "    try:\n",
    "        masked_model.fit(train_ds.take(FT_BATCHES_TO_USE), validation_data=val_ds.take(5), epochs=FT_EPOCHS, verbose=2)\n",
    "    except Exception as e:\n",
    "        log(\"Masked fine-tune failed/partial:\", e)\n",
    "\n",
    "    pruned_model = prune_structural_sequential(model, masks, input_shape)\n",
    "    pruned_model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    log(\"Evaluating Original model:\")\n",
    "    orig_loss, orig_acc = model.evaluate(val_ds, verbose=0)\n",
    "    log(\"Original acc:\", orig_acc)\n",
    "\n",
    "    log(\"Evaluating Masked model (after FT):\")\n",
    "    try:\n",
    "        mask_loss, mask_acc = masked_model.evaluate(val_ds, verbose=0)\n",
    "        log(\"Masked acc:\", mask_acc)\n",
    "    except Exception as e:\n",
    "        log(\"Masked evaluate failed:\", e)\n",
    "        mask_acc = None\n",
    "\n",
    "    log(\"Evaluating Pruned model:\")\n",
    "    try:\n",
    "        pruned_loss, pruned_acc = pruned_model.evaluate(val_ds, verbose=0)\n",
    "        log(\"Pruned acc:\", pruned_acc)\n",
    "    except Exception as e:\n",
    "        log(\"Pruned evaluate failed:\", e)\n",
    "        pruned_acc = None\n",
    "\n",
    "    pruned_flops = calculate_model_flops(pruned_model, input_shape)\n",
    "    pruned_gflops = pruned_flops / 1e9\n",
    "    pruned_time = measure_inference_time(pruned_model, sample_x_small, steps=10)\n",
    "    log(f\"Pruned FLOPS: {pruned_flops:,} ({pruned_gflops:.6f} GFLOPS), pruned time: {pruned_time:.4f}s\")\n",
    "\n",
    "    # Metrics: speedup, accuracy drop, parameter reduction\n",
    "    speedup = (baseline_time / pruned_time) if pruned_time > 0 else float(\"inf\")\n",
    "    acc_drop_abs = (orig_acc - pruned_acc) if (orig_acc is not None and pruned_acc is not None) else None\n",
    "    acc_drop_pct = (acc_drop_abs / orig_acc * 100) if (acc_drop_abs is not None and orig_acc != 0) else None\n",
    "\n",
    "    orig_params = model.count_params()\n",
    "    pruned_params = pruned_model.count_params()\n",
    "    param_reduction_pct = (1 - pruned_params / orig_params) * 100 if orig_params > 0 else None\n",
    "\n",
    "    # per-layer remaining stats\n",
    "    layer_stats = per_layer_remaining_stats(masks)\n",
    "\n",
    "    # Pretty print summary\n",
    "    log(\"=\"*70)\n",
    "    log(\"FINAL SUMMARY\")\n",
    "    log(\"=\"*70)\n",
    "    log(f\"Baseline GFLOPS: {baseline_gflops:.6f} GFLOPS\")\n",
    "    log(f\"Pruned GFLOPS:   {pruned_gflops:.6f} GFLOPS\")\n",
    "    log(f\"FLOPS reduction: {(1 - pruned_flops / baseline_flops) * 100:.2f}%\")\n",
    "    log(f\"Baseline time (avg batch): {baseline_time:.4f}s\")\n",
    "    log(f\"Pruned time (avg batch):   {pruned_time:.4f}s\")\n",
    "    log(f\"Speed-up ratio (baseline/pruned): {speedup:.3f}x\")\n",
    "    if acc_drop_abs is not None:\n",
    "        log(f\"Original acc: {orig_acc:.4f}, Pruned acc: {pruned_acc:.4f}\")\n",
    "        log(f\"Accuracy drop: {acc_drop_abs:.4f} ({acc_drop_pct:.2f}%)\")\n",
    "    else:\n",
    "        log(\"Accuracy numbers unavailable for drop computation.\")\n",
    "    log(f\"Original params: {orig_params:,}, Pruned params: {pruned_params:,}\")\n",
    "    log(f\"Parameter reduction: {param_reduction_pct:.2f}%\")\n",
    "    log(\"Per-layer remaining (kept/total):\")\n",
    "    for name, s in layer_stats.items():\n",
    "        log(f\"  {name}: {s['kept']}/{s['total']} ({s['ratio']:.2%})\")\n",
    "    log(\"=\"*70)\n",
    "\n",
    "    # Save outputs (models + masks + metadata)\n",
    "    try:\n",
    "        save_model_safe(model, os.path.join(SAVE_DIR, \"model_baseline\"))\n",
    "        save_model_safe(masked_model, os.path.join(SAVE_DIR, \"model_masked\"))\n",
    "        save_model_safe(pruned_model, os.path.join(SAVE_DIR, \"model_pruned\"))\n",
    "    except Exception as e:\n",
    "        log(\"Save models failed:\", e)\n",
    "\n",
    "    metadata = {\n",
    "        \"baseline_flops\": int(baseline_flops),\n",
    "        \"pruned_flops\": int(pruned_flops),\n",
    "        \"baseline_gflops\": float(baseline_gflops),\n",
    "        \"pruned_gflops\": float(pruned_gflops),\n",
    "        \"baseline_time\": float(baseline_time),\n",
    "        \"pruned_time\": float(pruned_time),\n",
    "        \"orig_acc\": float(orig_acc) if orig_acc is not None else None,\n",
    "        \"pruned_acc\": float(pruned_acc) if pruned_acc is not None else None,\n",
    "        \"mask_acc\": float(mask_acc) if mask_acc is not None else None,\n",
    "        \"orig_params\": int(orig_params),\n",
    "        \"pruned_params\": int(pruned_params),\n",
    "        \"param_reduction_pct\": float(param_reduction_pct) if param_reduction_pct is not None else None,\n",
    "        \"per_layer_stats\": layer_stats\n",
    "    }\n",
    "    with open(os.path.join(SAVE_DIR, \"prune_summary.json\"), \"w\") as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "\n",
    "    log(\"Saved metadata to\", os.path.join(SAVE_DIR, \"prune_summary.json\"))\n",
    "    return metadata\n",
    "\n",
    "# ---------------------------\n",
    "# Run\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    out = full_pipeline(MODEL_PATH, DATASET_PATH)\n",
    "    log(\"Pipeline finished. Keys saved in metadata:\", out.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4ace5f",
   "metadata": {},
   "source": [
    "# **CNN Structure Pruning with 90% keep ratio**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d852d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading model: D:\\college\\sem-8\\models\\flower_cnn_model.h5\n",
      "[INFO] Loaded model directly.\n",
      "[INFO] Model loaded. Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">178</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">178</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1152</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">645</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m178\u001b[0m, \u001b[38;5;34m178\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m87\u001b[0m, \u001b[38;5;34m87\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1152\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m645\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">536,645</span> (2.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m536,645\u001b[0m (2.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">536,645</span> (2.05 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m536,645\u001b[0m (2.05 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inferred input shape: (180, 180, 3)\n",
      "[INFO] Loading dataset folder: D:\\college\\sem-8\\dataset\\flower_photos image_size: (180, 180)\n",
      "Found 3670 files belonging to 5 classes.\n",
      "Using 2936 files for training.\n",
      "Found 3670 files belonging to 5 classes.\n",
      "Using 734 files for validation.\n",
      "[INFO] Layers considered for pruning: ['conv2d_5', 'conv2d_6', 'conv2d_7', 'conv2d_8', 'conv2d_9', 'dense_8']\n",
      "[INFO] Computing activation & gradient stats...\n",
      "[INFO] conv2d_5: len=32 meanA=1.511032e-02 meanG=1.405021e-07 meanV=1.319298e-03\n",
      "[INFO] conv2d_6: len=64 meanA=5.383006e-03 meanG=5.216569e-07 meanV=1.591178e-04\n",
      "[INFO] conv2d_7: len=128 meanA=6.080369e-04 meanG=4.130494e-06 meanV=8.204263e-06\n",
      "[INFO] conv2d_8: len=128 meanA=4.388310e-03 meanG=1.736445e-05 meanV=3.638908e-06\n",
      "[INFO] conv2d_9: len=128 meanA=1.463907e-02 meanG=6.194560e-05 meanV=3.875269e-06\n",
      "[INFO] dense_8: len=128 meanA=3.249157e-02 meanG=1.355336e-03 meanV=4.577056e-06\n",
      "[INFO] conv2d_5: keep 28/32\n",
      "[INFO] conv2d_6: keep 57/64\n",
      "[INFO] conv2d_7: keep 115/128\n",
      "[INFO] conv2d_8: keep 115/128\n",
      "[INFO] conv2d_9: keep 115/128\n",
      "[INFO] dense_8: keep 115/128\n",
      "[INFO] Saved masks to pruning_output\\masks.json\n",
      "[INFO] Building masked model with gates...\n",
      "[INFO] Masked model built.\n",
      "[INFO] Masked model pre-FT acc: 0.24375000596046448\n",
      "[INFO] Baseline FLOPS: 691,945,472, baseline time (avg batch): 0.2170s\n",
      "Epoch 1/3\n",
      "46/46 - 83s - 2s/step - accuracy: 0.2408 - loss: 1.6136 - val_accuracy: 0.2469 - val_loss: 1.5927\n",
      "Epoch 2/3\n",
      "46/46 - 58s - 1s/step - accuracy: 0.2783 - loss: 1.5586 - val_accuracy: 0.3656 - val_loss: 1.4667\n",
      "Epoch 3/3\n",
      "46/46 - 58s - 1s/step - accuracy: 0.4189 - loss: 1.3267 - val_accuracy: 0.5375 - val_loss: 1.1726\n",
      "[INFO] Structural pruning (safe) start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ishan\\Documents\\sample_p1\\env\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Warning: couldn't set weights for conv2d_6_pruned : Layer conv2d_6_pruned weight shape (3, 3, 28, 57) is not compatible with provided weight shape (3, 3, 32, 57).\n",
      "[INFO] Warning: couldn't set weights for conv2d_7_pruned : Layer conv2d_7_pruned weight shape (3, 3, 57, 115) is not compatible with provided weight shape (3, 3, 64, 115).\n",
      "[INFO] Warning: couldn't set weights for conv2d_8_pruned : Layer conv2d_8_pruned weight shape (3, 3, 115, 115) is not compatible with provided weight shape (3, 3, 128, 115).\n",
      "[INFO] Warning: couldn't set weights for conv2d_9_pruned : Layer conv2d_9_pruned weight shape (3, 3, 115, 115) is not compatible with provided weight shape (3, 3, 128, 115).\n",
      "[INFO] Warning: couldn't set weights for dense_8_pruned : Layer dense_8_pruned weight shape (1035, 115) is not compatible with provided weight shape (1152, 115).\n",
      "[INFO] Warning: couldn't set weights for dense_9_pruned : Layer dense_9_pruned weight shape (115, 5) is not compatible with provided weight shape (128, 5).\n",
      "[INFO] Structural pruning complete. New model summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2_struct_pruned\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2_struct_pruned\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_5_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">178</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">178</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">87</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,421</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">43</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">59,110</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">119,140</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">119,140</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1035</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">119,140</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">115</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">580</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_5_pruned (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m178\u001b[0m, \u001b[38;5;34m178\u001b[0m, \u001b[38;5;34m28\u001b[0m)   │           \u001b[38;5;34m784\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m28\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6_pruned (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m87\u001b[0m, \u001b[38;5;34m87\u001b[0m, \u001b[38;5;34m57\u001b[0m)     │        \u001b[38;5;34m14,421\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m43\u001b[0m, \u001b[38;5;34m57\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7_pruned (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m115\u001b[0m)    │        \u001b[38;5;34m59,110\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m115\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8_pruned (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m115\u001b[0m)    │       \u001b[38;5;34m119,140\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m115\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9_pruned (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m115\u001b[0m)      │       \u001b[38;5;34m119,140\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m115\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1035\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8_pruned (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115\u001b[0m)            │       \u001b[38;5;34m119,140\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m115\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9_pruned (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │           \u001b[38;5;34m580\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">432,315</span> (1.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m432,315\u001b[0m (1.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">432,315</span> (1.65 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m432,315\u001b[0m (1.65 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Evaluating Original model:\n",
      "[INFO] Original acc: 0.5435967445373535\n",
      "[INFO] Evaluating Masked model (after FT):\n",
      "[INFO] Masked acc: 0.5299727320671082\n",
      "[INFO] Evaluating Pruned model:\n",
      "[INFO] Pruned acc: 0.20572206377983093\n",
      "[INFO] Pruned FLOPS: 552,721,480, pruned time: 0.2008s\n",
      "[INFO] ============================================================\n",
      "[INFO] SUMMARY:\n",
      "[INFO] Baseline FLOPS: 691,945,472\n",
      "[INFO] Pruned FLOPS:   552,721,480\n",
      "[INFO] FLOPS reduction: 20.12%\n",
      "[INFO] Original acc: 0.5435967445373535, Masked acc: 0.5299727320671082, Pruned acc: 0.20572206377983093\n",
      "[INFO] ============================================================\n",
      "[INFO] Baseline GFLOPS: 0.6919\n",
      "[INFO] Pruned GFLOPS:   0.5527\n",
      "[INFO] GFLOPS reduction: 20.12%\n",
      "[INFO] Accuracy reduction: 0.3379\n",
      "[INFO] Save models failed: Invalid filepath extension for saving. Please add either a `.keras` extension for the native Keras format (recommended) or a `.h5` extension. Use `model.export(filepath)` if you want to export a SavedModel for use with TFLite/TFServing/etc. Received: filepath=pruning_output\\model_baseline.\n",
      "[INFO] Pipeline finished. Outputs: dict_keys(['model', 'masked_model', 'pruned_model', 'masks', 'baseline_flops', 'pruned_flops', 'baseline_time', 'pruned_time', 'orig_acc', 'mask_acc', 'pruned_acc'])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "sequential_cnn_pruning_full.py\n",
    "Full Sequential CNN pruning pipeline (single-file)\n",
    "\n",
    "- Loads user Sequential CNN (.h5 / .keras / SavedModel)\n",
    "- Sanitizes layer names in .h5 if they contain '/'\n",
    "- Loads folder dataset (image_dataset_from_directory)\n",
    "- Computes activation/gradient/variance importance\n",
    "- Creates masks (keep_ratio)\n",
    "- Builds masked model (gating layer)\n",
    "- Fine-tunes masked model\n",
    "- Structurally prunes model (conv filter removal, prune Dense outputs only)\n",
    "- Computes FLOPS & timings, evaluates models\n",
    "- Saves models and masks\n",
    "\n",
    "Note: This is intended for Sequential CNN models (Conv2D -> ... -> Flatten -> Dense -> ... -> Dense output).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# ---------------------------\n",
    "# USER CONFIG\n",
    "# ---------------------------\n",
    "MODEL_PATH = r\"D:\\college\\sem-8\\models\\flower_cnn_model.h5\"   # path to model (.h5/.keras or SavedModel dir)\n",
    "DATASET_PATH = r\"D:\\college\\sem-8\\dataset\\flower_photos\"      # folder with subfolders per class\n",
    "SAVE_DIR = r\"pruning_output\"                                 # where outputs are saved\n",
    "\n",
    "KEEP_RATIO = 0.9            # fraction of channels/units to keep\n",
    "ALPHA, BETA, GAMMA = 0.4, 0.3, 0.3  # importance weights\n",
    "BATCH_SIZE = 64\n",
    "CALIB_BATCHES = 30\n",
    "FT_EPOCHS = 3\n",
    "FT_BATCHES_TO_USE = 150\n",
    "PLOT_RESULTS = True\n",
    "VERBOSE = True\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def log(*args):\n",
    "    if VERBOSE:\n",
    "        print(\"[INFO]\", *args)\n",
    "\n",
    "# ---------------------------\n",
    "# Safe load model (handles '/' in h5 layer names)\n",
    "# ---------------------------\n",
    "def safe_load_model(model_path):\n",
    "    \"\"\"\n",
    "    Try normal load_model; if fails (e.g., '/' in layer names in H5), sanitize model_config JSON and rebuild.\n",
    "    Returns a Keras model (compiled=False).\n",
    "    \"\"\"\n",
    "    log(\"Loading model:\", model_path)\n",
    "    # Try direct load first\n",
    "    try:\n",
    "        m = tf.keras.models.load_model(model_path, compile=False)\n",
    "        log(\"Loaded model directly.\")\n",
    "        return m\n",
    "    except Exception as e:\n",
    "        log(\"Direct load failed:\", e)\n",
    "\n",
    "    # If HDF5, attempt to sanitize layer names in model_config\n",
    "    try:\n",
    "        with h5py.File(model_path, \"r\") as f:\n",
    "            if \"model_config\" in f:\n",
    "                raw = f[\"model_config\"][()]\n",
    "                if isinstance(raw, bytes):\n",
    "                    raw = raw.decode(\"utf-8\")\n",
    "                cfg_json = json.loads(raw)\n",
    "                changed = False\n",
    "                for layer in cfg_json.get(\"config\", {}).get(\"layers\", []):\n",
    "                    cfg = layer.get(\"config\", {})\n",
    "                    name = cfg.get(\"name\")\n",
    "                    if isinstance(name, str) and \"/\" in name:\n",
    "                        new_name = name.replace(\"/\", \"_\")\n",
    "                        cfg[\"name\"] = new_name\n",
    "                        changed = True\n",
    "                        log(f\"[FIX] layer name: {name} -> {new_name}\")\n",
    "                if changed:\n",
    "                    fixed_json = json.dumps(cfg_json)\n",
    "                    model = tf.keras.models.model_from_json(fixed_json)\n",
    "                    model.load_weights(model_path)\n",
    "                    log(\"Loaded model from sanitized JSON + weights.\")\n",
    "                    return model\n",
    "    except Exception as e2:\n",
    "        log(\"H5 sanitization attempt failed:\", e2)\n",
    "\n",
    "    # final fallback: try load_model with safe_mode=False (older TF)\n",
    "    try:\n",
    "        m = tf.keras.models.load_model(model_path, compile=False, safe_mode=False)\n",
    "        log(\"Loaded model with safe_mode=False.\")\n",
    "        return m\n",
    "    except Exception as e3:\n",
    "        log(\"All load attempts failed:\", e3)\n",
    "        raise RuntimeError(\"Failed to load model. Ensure path and format are correct.\")\n",
    "\n",
    "# ---------------------------\n",
    "# Dataset loader (folder-based)\n",
    "# ---------------------------\n",
    "def load_image_folder_dataset(path, image_size, batch_size=BATCH_SIZE):\n",
    "    log(\"Loading dataset folder:\", path, \"image_size:\", image_size)\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        path,\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=42,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        path,\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        seed=42,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    rescaler = layers.Rescaling(1.0 / 255)\n",
    "    train_ds = train_ds.map(lambda x, y: (rescaler(x), y)).prefetch(tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.map(lambda x, y: (rescaler(x), y)).prefetch(tf.data.AUTOTUNE)\n",
    "    return train_ds, val_ds\n",
    "\n",
    "# ---------------------------\n",
    "# Activation & gradient stats\n",
    "# ---------------------------\n",
    "def compute_activation_grad_stats(model, layer_names, dataset, max_batches=CALIB_BATCHES):\n",
    "    \"\"\"\n",
    "    For each layer in layer_names, compute:\n",
    "      - A: mean(abs(activation)) per filter/unit\n",
    "      - G: mean(abs(grad wrt activation)) per filter/unit\n",
    "      - V: variance(activation) per filter/unit\n",
    "    Returns: dict name -> (A, G, V)\n",
    "    \"\"\"\n",
    "    log(\"Computing activation & gradient stats...\")\n",
    "    results = {n: [] for n in layer_names}\n",
    "    grad_results = {n: [] for n in layer_names}\n",
    "    var_results = {n: [] for n in layer_names}\n",
    "\n",
    "    batch_count = 0\n",
    "    for x_batch, y_batch in dataset:\n",
    "        if batch_count >= max_batches:\n",
    "            break\n",
    "        batch_count += 1\n",
    "        layer_acts = {}\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            a = x_batch\n",
    "            for layer in model.layers:\n",
    "                a = layer(a)\n",
    "                if layer.name in layer_names:\n",
    "                    tape.watch(a)\n",
    "                    layer_acts[layer.name] = a\n",
    "            preds = a\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(y_batch, preds)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "\n",
    "        for name in layer_names:\n",
    "            a = layer_acts[name]\n",
    "            if len(a.shape) == 4:\n",
    "                A = tf.reduce_mean(tf.abs(a), axis=(0,1,2)).numpy()\n",
    "                V = tf.math.reduce_variance(a, axis=(0,1,2)).numpy()\n",
    "            else:\n",
    "                A = tf.reduce_mean(tf.abs(a), axis=0).numpy()\n",
    "                V = tf.math.reduce_variance(a, axis=0).numpy()\n",
    "\n",
    "            grad = tape.gradient(loss, a)\n",
    "            if grad is None:\n",
    "                G = np.zeros_like(A)\n",
    "            else:\n",
    "                if len(grad.shape) == 4:\n",
    "                    G = tf.reduce_mean(tf.abs(grad), axis=(0,1,2)).numpy()\n",
    "                else:\n",
    "                    G = tf.reduce_mean(tf.abs(grad), axis=0).numpy()\n",
    "\n",
    "            results[name].append(A)\n",
    "            var_results[name].append(V)\n",
    "            grad_results[name].append(G)\n",
    "        del tape\n",
    "\n",
    "    stats = {}\n",
    "    for name in layer_names:\n",
    "        A = np.mean(results[name], axis=0)\n",
    "        V = np.mean(var_results[name], axis=0)\n",
    "        G = np.mean(grad_results[name], axis=0)\n",
    "        stats[name] = (A, G, V)\n",
    "        log(f\"{name}: len={len(A)} meanA={A.mean():.6e} meanG={G.mean():.6e} meanV={V.mean():.6e}\")\n",
    "    return stats\n",
    "\n",
    "# ---------------------------\n",
    "# Importance scores & masks\n",
    "# ---------------------------\n",
    "def compute_importance_scores(stats, alpha=ALPHA, beta=BETA, gamma=GAMMA):\n",
    "    def normalize(x):\n",
    "        x = x - x.min()\n",
    "        if x.max() > 0:\n",
    "            x = x / x.max()\n",
    "        return x\n",
    "    scores = {}\n",
    "    for name, (A, G, V) in stats.items():\n",
    "        scores[name] = alpha * normalize(A) + beta * normalize(G) + gamma * normalize(V)\n",
    "    return scores\n",
    "\n",
    "def make_masks_from_scores(score_map, keep_ratio=KEEP_RATIO):\n",
    "    masks = {}\n",
    "    for name, score in score_map.items():\n",
    "        k = max(1, int(len(score) * keep_ratio))\n",
    "        thresh = np.partition(score, -k)[-k]\n",
    "        mask = (score >= thresh).astype(np.float32)\n",
    "        masks[name] = mask\n",
    "        log(f\"{name}: keep {int(mask.sum())}/{len(mask)}\")\n",
    "    return masks\n",
    "\n",
    "# ---------------------------\n",
    "# Mask gate layer & masked model\n",
    "# ---------------------------\n",
    "class CNNGate(tf.keras.layers.Layer):\n",
    "    def __init__(self, mask=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mask = tf.constant(mask, dtype=tf.float32) if mask is not None else None\n",
    "    def call(self, x):\n",
    "        if self.mask is None:\n",
    "            return x\n",
    "        if len(x.shape) == 4:\n",
    "            return x * tf.reshape(self.mask, (1,1,1,-1))\n",
    "        else:\n",
    "            return x * self.mask\n",
    "\n",
    "def build_masked_model(orig_model, masks):\n",
    "    log(\"Building masked model with gates...\")\n",
    "    inp = tf.keras.Input(shape=orig_model.input_shape[1:])\n",
    "    x = inp\n",
    "    for layer in orig_model.layers:\n",
    "        x = layer(x)\n",
    "        if layer.name in masks:\n",
    "            x = CNNGate(mask=masks[layer.name], name=layer.name + \"_gate\")(x)\n",
    "    masked = tf.keras.Model(inputs=inp, outputs=x, name=orig_model.name + \"_masked\")\n",
    "    # copy weights (best-effort)\n",
    "    for layer in orig_model.layers:\n",
    "        try:\n",
    "            masked_layer = masked.get_layer(layer.name)\n",
    "            masked_layer.set_weights(layer.get_weights())\n",
    "        except Exception:\n",
    "            # layer might not exist by same name (e.g., InputLayer) -> ignore\n",
    "            pass\n",
    "    return masked\n",
    "\n",
    "# ---------------------------\n",
    "# Structural pruning (safe)\n",
    "# ---------------------------\n",
    "def prune_structural_sequential(orig_model, masks, input_shape):\n",
    "    \"\"\"\n",
    "    Structural pruning for Sequential models.\n",
    "    - Prune Conv2D output filters using masks[layer.name]\n",
    "    - Prune Dense output units only (do not slice Dense input rows that come from Flatten/Conv)\n",
    "    - Attempt to slice BatchNorm params to match conv outputs\n",
    "    \"\"\"\n",
    "    log(\"Structural pruning (safe) start...\")\n",
    "    new_layers = []\n",
    "    prev_was_conv_like = False  # indicates that Flatten/Conv preceded Dense inputs\n",
    "\n",
    "    for layer in orig_model.layers:\n",
    "        # Conv2D: slice output channels\n",
    "        if isinstance(layer, layers.Conv2D):\n",
    "            W, b = layer.get_weights()\n",
    "            orig_out = W.shape[-1]\n",
    "            mask = masks.get(layer.name, np.ones(orig_out, dtype=np.float32))\n",
    "            keep_idx = np.where(mask == 1)[0]\n",
    "            if keep_idx.size == 0:\n",
    "                keep_idx = np.array([int(np.argmax(mask))], dtype=np.int32)\n",
    "            W_new = W[:, :, :, keep_idx]\n",
    "            b_new = b[keep_idx]\n",
    "            new_conv = layers.Conv2D(\n",
    "                filters=len(keep_idx),\n",
    "                kernel_size=layer.kernel_size,\n",
    "                strides=layer.strides,\n",
    "                padding=layer.padding,\n",
    "                activation=layer.activation,\n",
    "                use_bias=layer.use_bias,\n",
    "                name=layer.name + \"_pruned\"\n",
    "            )\n",
    "            new_layers.append((new_conv, [W_new, b_new]))\n",
    "            prev_was_conv_like = True\n",
    "            continue\n",
    "\n",
    "        # BatchNorm: slice params if prev was conv-like\n",
    "        if isinstance(layer, layers.BatchNormalization):\n",
    "            try:\n",
    "                weights = layer.get_weights()\n",
    "                if prev_was_conv_like and new_layers:\n",
    "                    prev_layer_obj, prev_w = new_layers[-1]\n",
    "                    if prev_w is not None:\n",
    "                        out_ch = prev_w[0].shape[-1]  # kernel last dim\n",
    "                        gamma, beta, mean, var = weights\n",
    "                        gamma = gamma[:out_ch]\n",
    "                        beta = beta[:out_ch]\n",
    "                        mean = mean[:out_ch]\n",
    "                        var = var[:out_ch]\n",
    "                        new_bn = layers.BatchNormalization.from_config(layer.get_config())\n",
    "                        new_layers.append((new_bn, [gamma, beta, mean, var]))\n",
    "                        continue\n",
    "            except Exception:\n",
    "                pass\n",
    "            # fallback keep BN as-is\n",
    "            try:\n",
    "                new_bn = layers.BatchNormalization.from_config(layer.get_config())\n",
    "                new_layers.append((new_bn, layer.get_weights()))\n",
    "            except Exception:\n",
    "                new_layers.append((layer, layer.get_weights() if hasattr(layer, \"get_weights\") else None))\n",
    "            # prev_was_conv_like unchanged\n",
    "            continue\n",
    "\n",
    "        # MaxPool/Activation/Dropout/Flatten/GlobalAvgPool: clone or reuse\n",
    "        if isinstance(layer, (layers.MaxPooling2D, layers.Activation, layers.ReLU, layers.Dropout, layers.Flatten, layers.GlobalAveragePooling2D)):\n",
    "            try:\n",
    "                cloned = layer.__class__.from_config(layer.get_config())\n",
    "                w = layer.get_weights() if hasattr(layer, \"get_weights\") else None\n",
    "                new_layers.append((cloned, w if w else None))\n",
    "            except Exception:\n",
    "                new_layers.append((layer, layer.get_weights() if hasattr(layer, \"get_weights\") else None))\n",
    "            if isinstance(layer, layers.Flatten) or isinstance(layer, layers.GlobalAveragePooling2D):\n",
    "                prev_was_conv_like = True\n",
    "            continue\n",
    "\n",
    "        # Dense: prune outputs only (safe)\n",
    "        if isinstance(layer, layers.Dense):\n",
    "            W, b = layer.get_weights()  # shape (in_dim, out_dim)\n",
    "            out_mask = masks.get(layer.name, np.ones(W.shape[1], dtype=np.float32))\n",
    "            out_idx = np.where(out_mask == 1)[0]\n",
    "            if out_idx.size == 0:\n",
    "                out_idx = np.array([int(np.argmax(out_mask))], dtype=np.int32)\n",
    "            W_new = W[:, out_idx]   # keep all input rows (safe)\n",
    "            b_new = b[out_idx]\n",
    "            new_dense = layers.Dense(units=W_new.shape[1], activation=layer.activation, name=layer.name + \"_pruned\")\n",
    "            new_layers.append((new_dense, [W_new, b_new]))\n",
    "            prev_was_conv_like = False\n",
    "            continue\n",
    "\n",
    "        # Fallback for other layers\n",
    "        try:\n",
    "            cloned = layer.__class__.from_config(layer.get_config())\n",
    "            w = layer.get_weights() if hasattr(layer, \"get_weights\") else None\n",
    "            new_layers.append((cloned, w if w else None))\n",
    "        except Exception:\n",
    "            new_layers.append((layer, layer.get_weights() if hasattr(layer, \"get_weights\") else None))\n",
    "        prev_was_conv_like = False\n",
    "\n",
    "    # Build new Sequential model with InputLayer\n",
    "    seq = models.Sequential(name=orig_model.name + \"_struct_pruned\")\n",
    "    seq.add(layers.InputLayer(input_shape=tuple(input_shape)))\n",
    "    for lyr_obj, w in new_layers:\n",
    "        seq.add(lyr_obj)\n",
    "        if w is not None:\n",
    "            try:\n",
    "                seq.layers[-1].set_weights(w)\n",
    "            except Exception as e:\n",
    "                log(\"Warning: couldn't set weights for\", seq.layers[-1].name, \":\", e)\n",
    "    log(\"Structural pruning complete. New model summary:\")\n",
    "    seq.summary()\n",
    "    return seq\n",
    "\n",
    "# ---------------------------\n",
    "# FLOPS and timing helpers\n",
    "# ---------------------------\n",
    "def calculate_conv_flops(input_shape, kernel_shape, strides=(1,1), padding='same'):\n",
    "    h_in, w_in, c_in = input_shape\n",
    "    kh, kw, _, c_out = kernel_shape\n",
    "    if padding == 'same':\n",
    "        h_out = math.ceil(h_in / strides[0])\n",
    "        w_out = math.ceil(w_in / strides[1])\n",
    "    else:\n",
    "        h_out = math.ceil((h_in - kh + 1) / strides[0])\n",
    "        w_out = math.ceil((w_in - kw + 1) / strides[1])\n",
    "    flops = h_out * w_out * (kh * kw * c_in) * c_out * 2\n",
    "    return flops, (h_out, w_out, c_out)\n",
    "\n",
    "def calculate_dense_flops(in_size, out_size):\n",
    "    return in_size * out_size * 2\n",
    "\n",
    "def calculate_model_flops(model, input_shape):\n",
    "    total = 0\n",
    "    current_shape = tuple(input_shape)\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, layers.Conv2D):\n",
    "            weights = layer.get_weights()\n",
    "            if not weights:\n",
    "                continue\n",
    "            kernel_shape = weights[0].shape  # (kh, kw, in_c, out_c)\n",
    "            layer_flops, current_shape = calculate_conv_flops(current_shape, kernel_shape, strides=layer.strides, padding=layer.padding)\n",
    "            total += layer_flops\n",
    "        elif isinstance(layer, layers.Flatten):\n",
    "            current_shape = (int(np.prod(current_shape)),)\n",
    "        elif isinstance(layer, layers.Dense):\n",
    "            in_size = current_shape[0] if isinstance(current_shape, tuple) and len(current_shape)>0 else int(current_shape)\n",
    "            layer_flops = calculate_dense_flops(in_size, layer.units)\n",
    "            total += layer_flops\n",
    "            current_shape = (layer.units,)\n",
    "        elif isinstance(layer, layers.MaxPooling2D):\n",
    "            h,w,c = current_shape\n",
    "            pool = layer.pool_size[0] if hasattr(layer.pool_size, \"__getitem__\") else layer.pool_size\n",
    "            current_shape = (h//pool, w//pool, c)\n",
    "        else:\n",
    "            # ignore other layers for shape changes\n",
    "            pass\n",
    "    return total\n",
    "\n",
    "def measure_inference_time(model, sample_batch, steps=20):\n",
    "    model.predict(sample_batch, verbose=0)  # warmup\n",
    "    t0 = time.time()\n",
    "    for _ in range(steps):\n",
    "        model.predict(sample_batch, verbose=0)\n",
    "    t1 = time.time()\n",
    "    return (t1 - t0) / steps\n",
    "\n",
    "# ---------------------------\n",
    "# Save masks helper\n",
    "# ---------------------------\n",
    "def save_masks(masks, path):\n",
    "    serial = {k: v.tolist() for k,v in masks.items()}\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(serial, f, indent=2)\n",
    "    log(\"Saved masks to\", path)\n",
    "\n",
    "# ---------------------------\n",
    "# Plot helper\n",
    "# ---------------------------\n",
    "def plot_mask_histograms(masks, outdir=SAVE_DIR):\n",
    "    if not PLOT_RESULTS:\n",
    "        return\n",
    "    for name, mask in masks.items():\n",
    "        plt.figure(figsize=(5,2))\n",
    "        plt.title(name)\n",
    "        plt.hist(mask, bins=2)\n",
    "        plt.xlabel(\"0=pruned, 1=kept\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(outdir, f\"mask_{name}.png\"))\n",
    "        plt.close()\n",
    "\n",
    "# ---------------------------\n",
    "# MAIN pipeline\n",
    "# ---------------------------\n",
    "def full_pipeline(model_path, dataset_path):\n",
    "    # 1) load model (safe)\n",
    "    model = safe_load_model(model_path)\n",
    "    log(\"Model loaded. Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    # compile original so evaluate works (use small lr default)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # 2) infer input shape\n",
    "    input_shape = model.input_shape[1:]\n",
    "    log(\"Inferred input shape:\", input_shape)\n",
    "\n",
    "    # 3) load dataset\n",
    "    train_ds, val_ds = load_image_folder_dataset(dataset_path, image_size=input_shape[:2], batch_size=BATCH_SIZE)\n",
    "    # calibration subset\n",
    "    calib_ds = train_ds.take(CALIB_BATCHES)\n",
    "\n",
    "    # sample for timing\n",
    "    try:\n",
    "        sample_x, _ = next(iter(val_ds))\n",
    "    except Exception:\n",
    "        sample_x, _ = next(iter(train_ds))\n",
    "    sample_x_small = sample_x[:min(16, sample_x.shape[0])]\n",
    "\n",
    "    # 4) choose layers to prune (conv + hidden dense only)\n",
    "    dense_layers = [lyr for lyr in model.layers if isinstance(lyr, layers.Dense)]\n",
    "    last_dense = dense_layers[-1] if dense_layers else None\n",
    "\n",
    "    prune_layer_names = []\n",
    "    for lyr in model.layers:\n",
    "        if isinstance(lyr, layers.Conv2D):\n",
    "            prune_layer_names.append(lyr.name)\n",
    "        elif isinstance(lyr, layers.Dense) and lyr is not last_dense:\n",
    "            prune_layer_names.append(lyr.name)\n",
    "    log(\"Layers considered for pruning:\", prune_layer_names)\n",
    "\n",
    "    # 5) compute stats\n",
    "    stats = compute_activation_grad_stats(model, prune_layer_names, calib_ds, max_batches=CALIB_BATCHES)\n",
    "\n",
    "    # 6) importance & masks\n",
    "    score_map = compute_importance_scores(stats)\n",
    "    masks = make_masks_from_scores(score_map, keep_ratio=KEEP_RATIO)\n",
    "    save_masks(masks, os.path.join(SAVE_DIR, \"masks.json\"))\n",
    "    plot_mask_histograms(masks)\n",
    "\n",
    "    # 7) build masked model and compile\n",
    "    masked_model = build_masked_model(model, masks)\n",
    "    masked_model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    log(\"Masked model built.\")\n",
    "\n",
    "    # quick eval before FT\n",
    "    try:\n",
    "        loss0, acc0 = masked_model.evaluate(val_ds.take(5), verbose=0)\n",
    "        log(\"Masked model pre-FT acc:\", acc0)\n",
    "    except Exception as e:\n",
    "        log(\"Masked model pre-eval failed:\", e)\n",
    "\n",
    "    # 8) measure baseline flops & time\n",
    "    baseline_flops = calculate_model_flops(model, input_shape)\n",
    "    baseline_time = measure_inference_time(model, sample_x_small, steps=10)\n",
    "    log(f\"Baseline FLOPS: {baseline_flops:,}, baseline time (avg batch): {baseline_time:.4f}s\")\n",
    "\n",
    "    # 9) fine-tune masked model\n",
    "    try:\n",
    "        masked_model.fit(train_ds.take(FT_BATCHES_TO_USE), validation_data=val_ds.take(5), epochs=FT_EPOCHS, verbose=2)\n",
    "    except Exception as e:\n",
    "        log(\"Masked fine-tune failed/partial:\", e)\n",
    "\n",
    "    # 10) structural prune\n",
    "    pruned_model = prune_structural_sequential(model, masks, input_shape)\n",
    "    # compile pruned model for evaluation\n",
    "    pruned_model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # 11) evaluate models\n",
    "    log(\"Evaluating Original model:\")\n",
    "    orig_loss, orig_acc = model.evaluate(val_ds, verbose=0)\n",
    "    log(\"Original acc:\", orig_acc)\n",
    "\n",
    "    log(\"Evaluating Masked model (after FT):\")\n",
    "    try:\n",
    "        mask_loss, mask_acc = masked_model.evaluate(val_ds, verbose=0)\n",
    "        log(\"Masked acc:\", mask_acc)\n",
    "    except Exception as e:\n",
    "        log(\"Masked evaluate failed:\", e)\n",
    "        mask_acc = None\n",
    "\n",
    "    log(\"Evaluating Pruned model:\")\n",
    "    try:\n",
    "        pruned_loss, pruned_acc = pruned_model.evaluate(val_ds, verbose=0)\n",
    "        log(\"Pruned acc:\", pruned_acc)\n",
    "    except Exception as e:\n",
    "        log(\"Pruned evaluate failed:\", e)\n",
    "        pruned_acc = None\n",
    "\n",
    "    # 12) FLOPS & timing after prune\n",
    "    pruned_flops = calculate_model_flops(pruned_model, input_shape)\n",
    "    pruned_time = measure_inference_time(pruned_model, sample_x_small, steps=10)\n",
    "    log(f\"Pruned FLOPS: {pruned_flops:,}, pruned time: {pruned_time:.4f}s\")\n",
    "\n",
    "    # 13) summary & save\n",
    "    reduction = 1.0 - (pruned_flops / baseline_flops) if baseline_flops > 0 else 0.0\n",
    "    log(\"=\"*60)\n",
    "    log(\"SUMMARY:\")\n",
    "    log(f\"Baseline FLOPS: {baseline_flops:,}\")\n",
    "    log(f\"Pruned FLOPS:   {pruned_flops:,}\")\n",
    "    log(f\"FLOPS reduction: {reduction:.2%}\")\n",
    "    log(f\"Original acc: {orig_acc}, Masked acc: {mask_acc}, Pruned acc: {pruned_acc}\")\n",
    "    log(\"=\"*60)\n",
    "\n",
    "    # ---- Extra Metrics: GFLOPS + Accuracy Reduction ----\n",
    "    baseline_gflops = baseline_flops / 1e9\n",
    "    pruned_gflops = pruned_flops / 1e9\n",
    "    gflops_reduction = 1.0 - (pruned_gflops / baseline_gflops) if baseline_gflops > 0 else 0.0\n",
    "\n",
    "    acc_reduction = (orig_acc - pruned_acc) if (orig_acc is not None and pruned_acc is not None) else None\n",
    "\n",
    "    log(f\"Baseline GFLOPS: {baseline_gflops:.4f}\")\n",
    "    log(f\"Pruned GFLOPS:   {pruned_gflops:.4f}\")\n",
    "    log(f\"GFLOPS reduction: {gflops_reduction:.2%}\")\n",
    "\n",
    "    if acc_reduction is not None:\n",
    "        log(f\"Accuracy reduction: {acc_reduction:.4f}\")\n",
    "    else:\n",
    "        log(\"Accuracy reduction: N/A\")\n",
    "\n",
    "\n",
    "    # save artifacts\n",
    "    try:\n",
    "        model.save(os.path.join(SAVE_DIR, \"model_baseline\"))\n",
    "        masked_model.save(os.path.join(SAVE_DIR, \"model_masked\"))\n",
    "        pruned_model.save(os.path.join(SAVE_DIR, \"model_pruned\"))\n",
    "        log(\"Saved models to\", SAVE_DIR)\n",
    "    except Exception as e:\n",
    "        log(\"Save models failed:\", e)\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"masked_model\": masked_model,\n",
    "        \"pruned_model\": pruned_model,\n",
    "        \"masks\": masks,\n",
    "        \"baseline_flops\": baseline_flops,\n",
    "        \"pruned_flops\": pruned_flops,\n",
    "        \"baseline_time\": baseline_time,\n",
    "        \"pruned_time\": pruned_time,\n",
    "        \"orig_acc\": orig_acc,\n",
    "        \"mask_acc\": mask_acc,\n",
    "        \"pruned_acc\": pruned_acc\n",
    "    }\n",
    "\n",
    "# ---------------------------\n",
    "# Run\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    out = full_pipeline(MODEL_PATH, DATASET_PATH)\n",
    "    log(\"Pipeline finished. Outputs:\", out.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbe53f0",
   "metadata": {},
   "source": [
    "# **CNN structure pruning with early call back with 100 epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74af6225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading model: D:\\college\\sem-8\\models\\cat_dog_cnn.h5\n",
      "[INFO] Loaded model directly.\n",
      "[INFO] Model loaded. Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">409,345</span> (1.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m409,345\u001b[0m (1.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">409,345</span> (1.56 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m409,345\u001b[0m (1.56 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inferred input shape: (150, 150, 3)\n",
      "[INFO] Loading dataset folder: D:\\college\\sem-8\\dataset\\reduced_pet_dataset image_size: (150, 150)\n",
      "Found 7498 files belonging to 2 classes.\n",
      "Using 5999 files for training.\n",
      "Found 7498 files belonging to 2 classes.\n",
      "Using 1499 files for validation.\n",
      "[INFO] Layers considered for pruning: ['conv2d', 'conv2d_1', 'conv2d_2', 'conv2d_3', 'conv2d_4', 'dense']\n",
      "[INFO] Computing activation & gradient stats...\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__SparseSoftmaxCrossEntropyWithLogits_device_/job:localhost/replica:0/task:0/device:CPU:0}} Received a label value of 1 which is outside the valid range of [0, 1).  Label values: 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 0 0 [Op:SparseSoftmaxCrossEntropyWithLogits] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 626\u001b[0m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[0;32m    623\u001b[0m \u001b[38;5;66;03m# Run\u001b[39;00m\n\u001b[0;32m    624\u001b[0m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 626\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfull_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATASET_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    627\u001b[0m     log(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline finished. Outputs:\u001b[39m\u001b[38;5;124m\"\u001b[39m, out\u001b[38;5;241m.\u001b[39mkeys())\n",
      "Cell \u001b[1;32mIn[50], line 486\u001b[0m, in \u001b[0;36mfull_pipeline\u001b[1;34m(model_path, dataset_path)\u001b[0m\n\u001b[0;32m    483\u001b[0m log(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayers considered for pruning:\u001b[39m\u001b[38;5;124m\"\u001b[39m, prune_layer_names)\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# 5) compute stats\u001b[39;00m\n\u001b[1;32m--> 486\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_activation_grad_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprune_layer_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalib_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCALIB_BATCHES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# 6) importance & masks\u001b[39;00m\n\u001b[0;32m    489\u001b[0m score_map \u001b[38;5;241m=\u001b[39m compute_importance_scores(stats)\n",
      "Cell \u001b[1;32mIn[50], line 161\u001b[0m, in \u001b[0;36mcompute_activation_grad_stats\u001b[1;34m(model, layer_names, dataset, max_batches)\u001b[0m\n\u001b[0;32m    159\u001b[0m             layer_acts[layer\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m a\n\u001b[0;32m    160\u001b[0m     preds \u001b[38;5;241m=\u001b[39m a\n\u001b[1;32m--> 161\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse_categorical_crossentropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m     loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_mean(loss)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m layer_names:\n",
      "File \u001b[1;32mc:\\Users\\Ishan\\Documents\\sample_p1\\env\\Lib\\site-packages\\keras\\src\\losses\\losses.py:2241\u001b[0m, in \u001b[0;36msparse_categorical_crossentropy\u001b[1;34m(y_true, y_pred, from_logits, ignore_class, axis)\u001b[0m\n\u001b[0;32m   2236\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m y_true \u001b[38;5;241m*\u001b[39m ops\u001b[38;5;241m.\u001b[39mcast(valid_mask, y_true\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m   2237\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m y_pred \u001b[38;5;241m*\u001b[39m ops\u001b[38;5;241m.\u001b[39mcast(\n\u001b[0;32m   2238\u001b[0m         ops\u001b[38;5;241m.\u001b[39mexpand_dims(valid_mask, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), y_pred\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m   2239\u001b[0m     )\n\u001b[1;32m-> 2241\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse_categorical_crossentropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2242\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2243\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2244\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_logits\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2245\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2246\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2249\u001b[0m     valid_mask \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mreshape(valid_mask, res_shape)\n",
      "File \u001b[1;32mc:\\Users\\Ishan\\Documents\\sample_p1\\env\\Lib\\site-packages\\keras\\src\\ops\\nn.py:1841\u001b[0m, in \u001b[0;36msparse_categorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m   1837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m any_symbolic_tensors((target, output)):\n\u001b[0;32m   1838\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparseCategoricalCrossentropy(\n\u001b[0;32m   1839\u001b[0m         from_logits\u001b[38;5;241m=\u001b[39mfrom_logits, axis\u001b[38;5;241m=\u001b[39maxis\n\u001b[0;32m   1840\u001b[0m     )\u001b[38;5;241m.\u001b[39msymbolic_call(target, output)\n\u001b[1;32m-> 1841\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse_categorical_crossentropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_logits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_logits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\n\u001b[0;32m   1843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ishan\\Documents\\sample_p1\\env\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:714\u001b[0m, in \u001b[0;36msparse_categorical_crossentropy\u001b[1;34m(target, output, from_logits, axis)\u001b[0m\n\u001b[0;32m    709\u001b[0m     output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mclip_by_value(\n\u001b[0;32m    710\u001b[0m         output, backend\u001b[38;5;241m.\u001b[39mepsilon(), \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m backend\u001b[38;5;241m.\u001b[39mepsilon()\n\u001b[0;32m    711\u001b[0m     )\n\u001b[0;32m    712\u001b[0m     output \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mlog(output)\n\u001b[1;32m--> 714\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse_softmax_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Ishan\\Documents\\sample_p1\\env\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Ishan\\Documents\\sample_p1\\env\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6002\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   6001\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 6002\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__SparseSoftmaxCrossEntropyWithLogits_device_/job:localhost/replica:0/task:0/device:CPU:0}} Received a label value of 1 which is outside the valid range of [0, 1).  Label values: 1 1 0 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 0 0 1 1 0 0 1 0 1 0 0 [Op:SparseSoftmaxCrossEntropyWithLogits] name: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "sequential_cnn_pruning_full.py\n",
    "Full Sequential CNN pruning pipeline (single-file)\n",
    "\n",
    "- Loads user Sequential CNN (.h5 / .keras / SavedModel)\n",
    "- Sanitizes layer names in .h5 if they contain '/'\n",
    "- Loads folder dataset (image_dataset_from_directory)\n",
    "- Computes activation/gradient/variance importance\n",
    "- Creates masks (keep_ratio)\n",
    "- Builds masked model (gating layer)\n",
    "- Fine-tunes masked model\n",
    "- Structurally prunes model (conv filter removal, prune Dense outputs only)\n",
    "- Computes FLOPS & timings, evaluates models\n",
    "- Saves models and masks\n",
    "\n",
    "Note: This is intended for Sequential CNN models (Conv2D -> ... -> Flatten -> Dense -> ... -> Dense output).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# ---------------------------\n",
    "# USER CONFIG\n",
    "# ---------------------------\n",
    "MODEL_PATH = r\"D:\\college\\sem-8\\models\\cat_dog_cnn.h5\"   # path to model (.h5/.keras or SavedModel dir)\n",
    "DATASET_PATH = r\"D:\\college\\sem-8\\dataset\\reduced_pet_dataset\"      # folder with subfolders per class\n",
    "SAVE_DIR = r\"pruning_output\"                                 # where outputs are saved\n",
    "\n",
    "KEEP_RATIO = 0.9            # fraction of channels/units to keep\n",
    "ALPHA, BETA, GAMMA = 0.4, 0.3, 0.3  # importance weights\n",
    "BATCH_SIZE = 64\n",
    "CALIB_BATCHES = 30\n",
    "FT_EPOCHS = 3\n",
    "FT_BATCHES_TO_USE = 150\n",
    "PLOT_RESULTS = True\n",
    "VERBOSE = True\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def log(*args):\n",
    "    if VERBOSE:\n",
    "        print(\"[INFO]\", *args)\n",
    "\n",
    "# ---------------------------\n",
    "# Safe load model (handles '/' in h5 layer names)\n",
    "# ---------------------------\n",
    "def safe_load_model(model_path):\n",
    "    \"\"\"\n",
    "    Try normal load_model; if fails (e.g., '/' in layer names in H5), sanitize model_config JSON and rebuild.\n",
    "    Returns a Keras model (compiled=False).\n",
    "    \"\"\"\n",
    "    log(\"Loading model:\", model_path)\n",
    "    # Try direct load first\n",
    "    try:\n",
    "        m = tf.keras.models.load_model(model_path, compile=False)\n",
    "        log(\"Loaded model directly.\")\n",
    "        return m\n",
    "    except Exception as e:\n",
    "        log(\"Direct load failed:\", e)\n",
    "\n",
    "    # If HDF5, attempt to sanitize layer names in model_config\n",
    "    try:\n",
    "        with h5py.File(model_path, \"r\") as f:\n",
    "            if \"model_config\" in f:\n",
    "                raw = f[\"model_config\"][()]\n",
    "                if isinstance(raw, bytes):\n",
    "                    raw = raw.decode(\"utf-8\")\n",
    "                cfg_json = json.loads(raw)\n",
    "                changed = False\n",
    "                for layer in cfg_json.get(\"config\", {}).get(\"layers\", []):\n",
    "                    cfg = layer.get(\"config\", {})\n",
    "                    name = cfg.get(\"name\")\n",
    "                    if isinstance(name, str) and \"/\" in name:\n",
    "                        new_name = name.replace(\"/\", \"_\")\n",
    "                        cfg[\"name\"] = new_name\n",
    "                        changed = True\n",
    "                        log(f\"[FIX] layer name: {name} -> {new_name}\")\n",
    "                if changed:\n",
    "                    fixed_json = json.dumps(cfg_json)\n",
    "                    model = tf.keras.models.model_from_json(fixed_json)\n",
    "                    model.load_weights(model_path)\n",
    "                    log(\"Loaded model from sanitized JSON + weights.\")\n",
    "                    return model\n",
    "    except Exception as e2:\n",
    "        log(\"H5 sanitization attempt failed:\", e2)\n",
    "\n",
    "    # final fallback: try load_model with safe_mode=False (older TF)\n",
    "    try:\n",
    "        m = tf.keras.models.load_model(model_path, compile=False, safe_mode=False)\n",
    "        log(\"Loaded model with safe_mode=False.\")\n",
    "        return m\n",
    "    except Exception as e3:\n",
    "        log(\"All load attempts failed:\", e3)\n",
    "        raise RuntimeError(\"Failed to load model. Ensure path and format are correct.\")\n",
    "\n",
    "# ---------------------------\n",
    "# Dataset loader (folder-based)\n",
    "# ---------------------------\n",
    "def load_image_folder_dataset(path, image_size, batch_size=BATCH_SIZE):\n",
    "    log(\"Loading dataset folder:\", path, \"image_size:\", image_size)\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        path,\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=42,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        path,\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        seed=42,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    rescaler = layers.Rescaling(1.0 / 255)\n",
    "    train_ds = train_ds.map(lambda x, y: (rescaler(x), y)).prefetch(tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.map(lambda x, y: (rescaler(x), y)).prefetch(tf.data.AUTOTUNE)\n",
    "    return train_ds, val_ds\n",
    "\n",
    "# ---------------------------\n",
    "# Activation & gradient stats\n",
    "# ---------------------------\n",
    "def compute_activation_grad_stats(model, layer_names, dataset, max_batches=CALIB_BATCHES):\n",
    "    \"\"\"\n",
    "    For each layer in layer_names, compute:\n",
    "      - A: mean(abs(activation)) per filter/unit\n",
    "      - G: mean(abs(grad wrt activation)) per filter/unit\n",
    "      - V: variance(activation) per filter/unit\n",
    "    Returns: dict name -> (A, G, V)\n",
    "    \"\"\"\n",
    "    log(\"Computing activation & gradient stats...\")\n",
    "    results = {n: [] for n in layer_names}\n",
    "    grad_results = {n: [] for n in layer_names}\n",
    "    var_results = {n: [] for n in layer_names}\n",
    "\n",
    "    batch_count = 0\n",
    "    for x_batch, y_batch in dataset:\n",
    "        if batch_count >= max_batches:\n",
    "            break\n",
    "        batch_count += 1\n",
    "        layer_acts = {}\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            a = x_batch\n",
    "            for layer in model.layers:\n",
    "                a = layer(a)\n",
    "                if layer.name in layer_names:\n",
    "                    tape.watch(a)\n",
    "                    layer_acts[layer.name] = a\n",
    "            preds = a\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(y_batch, preds)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "\n",
    "        for name in layer_names:\n",
    "            a = layer_acts[name]\n",
    "            if len(a.shape) == 4:\n",
    "                A = tf.reduce_mean(tf.abs(a), axis=(0,1,2)).numpy()\n",
    "                V = tf.math.reduce_variance(a, axis=(0,1,2)).numpy()\n",
    "            else:\n",
    "                A = tf.reduce_mean(tf.abs(a), axis=0).numpy()\n",
    "                V = tf.math.reduce_variance(a, axis=0).numpy()\n",
    "\n",
    "            grad = tape.gradient(loss, a)\n",
    "            if grad is None:\n",
    "                G = np.zeros_like(A)\n",
    "            else:\n",
    "                if len(grad.shape) == 4:\n",
    "                    G = tf.reduce_mean(tf.abs(grad), axis=(0,1,2)).numpy()\n",
    "                else:\n",
    "                    G = tf.reduce_mean(tf.abs(grad), axis=0).numpy()\n",
    "\n",
    "            results[name].append(A)\n",
    "            var_results[name].append(V)\n",
    "            grad_results[name].append(G)\n",
    "        del tape\n",
    "\n",
    "    stats = {}\n",
    "    for name in layer_names:\n",
    "        A = np.mean(results[name], axis=0)\n",
    "        V = np.mean(var_results[name], axis=0)\n",
    "        G = np.mean(grad_results[name], axis=0)\n",
    "        stats[name] = (A, G, V)\n",
    "        log(f\"{name}: len={len(A)} meanA={A.mean():.6e} meanG={G.mean():.6e} meanV={V.mean():.6e}\")\n",
    "    return stats\n",
    "\n",
    "# ---------------------------\n",
    "# Importance scores & masks\n",
    "# ---------------------------\n",
    "def compute_importance_scores(stats, alpha=ALPHA, beta=BETA, gamma=GAMMA):\n",
    "    def normalize(x):\n",
    "        x = x - x.min()\n",
    "        if x.max() > 0:\n",
    "            x = x / x.max()\n",
    "        return x\n",
    "    scores = {}\n",
    "    for name, (A, G, V) in stats.items():\n",
    "        scores[name] = alpha * normalize(A) + beta * normalize(G) + gamma * normalize(V)\n",
    "    return scores\n",
    "\n",
    "def make_masks_from_scores(score_map, keep_ratio=KEEP_RATIO):\n",
    "    masks = {}\n",
    "    for name, score in score_map.items():\n",
    "        k = max(1, int(len(score) * keep_ratio))\n",
    "        thresh = np.partition(score, -k)[-k]\n",
    "        mask = (score >= thresh).astype(np.float32)\n",
    "        masks[name] = mask\n",
    "        log(f\"{name}: keep {int(mask.sum())}/{len(mask)}\")\n",
    "    return masks\n",
    "\n",
    "# ---------------------------\n",
    "# Mask gate layer & masked model\n",
    "# ---------------------------\n",
    "class CNNGate(tf.keras.layers.Layer):\n",
    "    def __init__(self, mask=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mask = tf.constant(mask, dtype=tf.float32) if mask is not None else None\n",
    "    def call(self, x):\n",
    "        if self.mask is None:\n",
    "            return x\n",
    "        if len(x.shape) == 4:\n",
    "            return x * tf.reshape(self.mask, (1,1,1,-1))\n",
    "        else:\n",
    "            return x * self.mask\n",
    "\n",
    "def build_masked_model(orig_model, masks):\n",
    "    log(\"Building masked model with gates...\")\n",
    "    inp = tf.keras.Input(shape=orig_model.input_shape[1:])\n",
    "    x = inp\n",
    "    for layer in orig_model.layers:\n",
    "        x = layer(x)\n",
    "        if layer.name in masks:\n",
    "            x = CNNGate(mask=masks[layer.name], name=layer.name + \"_gate\")(x)\n",
    "    masked = tf.keras.Model(inputs=inp, outputs=x, name=orig_model.name + \"_masked\")\n",
    "    # copy weights (best-effort)\n",
    "    for layer in orig_model.layers:\n",
    "        try:\n",
    "            masked_layer = masked.get_layer(layer.name)\n",
    "            masked_layer.set_weights(layer.get_weights())\n",
    "        except Exception:\n",
    "            # layer might not exist by same name (e.g., InputLayer) -> ignore\n",
    "            pass\n",
    "    return masked\n",
    "\n",
    "# ---------------------------\n",
    "# Structural pruning (safe)\n",
    "# ---------------------------\n",
    "def prune_structural_sequential(orig_model, masks, input_shape):\n",
    "    \"\"\"\n",
    "    Structural pruning for Sequential models.\n",
    "    - Prune Conv2D output filters using masks[layer.name]\n",
    "    - Prune Dense output units only (do not slice Dense input rows that come from Flatten/Conv)\n",
    "    - Attempt to slice BatchNorm params to match conv outputs\n",
    "    \"\"\"\n",
    "    log(\"Structural pruning (safe) start...\")\n",
    "    new_layers = []\n",
    "    prev_was_conv_like = False  # indicates that Flatten/Conv preceded Dense inputs\n",
    "\n",
    "    for layer in orig_model.layers:\n",
    "        # Conv2D: slice output channels\n",
    "        if isinstance(layer, layers.Conv2D):\n",
    "            W, b = layer.get_weights()\n",
    "            orig_out = W.shape[-1]\n",
    "            mask = masks.get(layer.name, np.ones(orig_out, dtype=np.float32))\n",
    "            keep_idx = np.where(mask == 1)[0]\n",
    "            if keep_idx.size == 0:\n",
    "                keep_idx = np.array([int(np.argmax(mask))], dtype=np.int32)\n",
    "            W_new = W[:, :, :, keep_idx]\n",
    "            b_new = b[keep_idx]\n",
    "            new_conv = layers.Conv2D(\n",
    "                filters=len(keep_idx),\n",
    "                kernel_size=layer.kernel_size,\n",
    "                strides=layer.strides,\n",
    "                padding=layer.padding,\n",
    "                activation=layer.activation,\n",
    "                use_bias=layer.use_bias,\n",
    "                name=layer.name + \"_pruned\"\n",
    "            )\n",
    "            new_layers.append((new_conv, [W_new, b_new]))\n",
    "            prev_was_conv_like = True\n",
    "            continue\n",
    "\n",
    "        # BatchNorm: slice params if prev was conv-like\n",
    "        if isinstance(layer, layers.BatchNormalization):\n",
    "            try:\n",
    "                weights = layer.get_weights()\n",
    "                if prev_was_conv_like and new_layers:\n",
    "                    prev_layer_obj, prev_w = new_layers[-1]\n",
    "                    if prev_w is not None:\n",
    "                        out_ch = prev_w[0].shape[-1]  # kernel last dim\n",
    "                        gamma, beta, mean, var = weights\n",
    "                        gamma = gamma[:out_ch]\n",
    "                        beta = beta[:out_ch]\n",
    "                        mean = mean[:out_ch]\n",
    "                        var = var[:out_ch]\n",
    "                        new_bn = layers.BatchNormalization.from_config(layer.get_config())\n",
    "                        new_layers.append((new_bn, [gamma, beta, mean, var]))\n",
    "                        continue\n",
    "            except Exception:\n",
    "                pass\n",
    "            # fallback keep BN as-is\n",
    "            try:\n",
    "                new_bn = layers.BatchNormalization.from_config(layer.get_config())\n",
    "                new_layers.append((new_bn, layer.get_weights()))\n",
    "            except Exception:\n",
    "                new_layers.append((layer, layer.get_weights() if hasattr(layer, \"get_weights\") else None))\n",
    "            # prev_was_conv_like unchanged\n",
    "            continue\n",
    "\n",
    "        # MaxPool/Activation/Dropout/Flatten/GlobalAvgPool: clone or reuse\n",
    "        if isinstance(layer, (layers.MaxPooling2D, layers.Activation, layers.ReLU, layers.Dropout, layers.Flatten, layers.GlobalAveragePooling2D)):\n",
    "            try:\n",
    "                cloned = layer.__class__.from_config(layer.get_config())\n",
    "                w = layer.get_weights() if hasattr(layer, \"get_weights\") else None\n",
    "                new_layers.append((cloned, w if w else None))\n",
    "            except Exception:\n",
    "                new_layers.append((layer, layer.get_weights() if hasattr(layer, \"get_weights\") else None))\n",
    "            if isinstance(layer, layers.Flatten) or isinstance(layer, layers.GlobalAveragePooling2D):\n",
    "                prev_was_conv_like = True\n",
    "            continue\n",
    "\n",
    "        # Dense: prune outputs only (safe)\n",
    "        if isinstance(layer, layers.Dense):\n",
    "            W, b = layer.get_weights()  # shape (in_dim, out_dim)\n",
    "            out_mask = masks.get(layer.name, np.ones(W.shape[1], dtype=np.float32))\n",
    "            out_idx = np.where(out_mask == 1)[0]\n",
    "            if out_idx.size == 0:\n",
    "                out_idx = np.array([int(np.argmax(out_mask))], dtype=np.int32)\n",
    "            W_new = W[:, out_idx]   # keep all input rows (safe)\n",
    "            b_new = b[out_idx]\n",
    "            new_dense = layers.Dense(units=W_new.shape[1], activation=layer.activation, name=layer.name + \"_pruned\")\n",
    "            new_layers.append((new_dense, [W_new, b_new]))\n",
    "            prev_was_conv_like = False\n",
    "            continue\n",
    "\n",
    "        # Fallback for other layers\n",
    "        try:\n",
    "            cloned = layer.__class__.from_config(layer.get_config())\n",
    "            w = layer.get_weights() if hasattr(layer, \"get_weights\") else None\n",
    "            new_layers.append((cloned, w if w else None))\n",
    "        except Exception:\n",
    "            new_layers.append((layer, layer.get_weights() if hasattr(layer, \"get_weights\") else None))\n",
    "        prev_was_conv_like = False\n",
    "\n",
    "    # Build new Sequential model with InputLayer\n",
    "    seq = models.Sequential(name=orig_model.name + \"_struct_pruned\")\n",
    "    seq.add(layers.InputLayer(input_shape=tuple(input_shape)))\n",
    "    for lyr_obj, w in new_layers:\n",
    "        seq.add(lyr_obj)\n",
    "        if w is not None:\n",
    "            try:\n",
    "                seq.layers[-1].set_weights(w)\n",
    "            except Exception as e:\n",
    "                log(\"Warning: couldn't set weights for\", seq.layers[-1].name, \":\", e)\n",
    "    log(\"Structural pruning complete. New model summary:\")\n",
    "    seq.summary()\n",
    "    return seq\n",
    "\n",
    "# ---------------------------\n",
    "# FLOPS and timing helpers\n",
    "# ---------------------------\n",
    "def calculate_conv_flops(input_shape, kernel_shape, strides=(1,1), padding='same'):\n",
    "    h_in, w_in, c_in = input_shape\n",
    "    kh, kw, _, c_out = kernel_shape\n",
    "    if padding == 'same':\n",
    "        h_out = math.ceil(h_in / strides[0])\n",
    "        w_out = math.ceil(w_in / strides[1])\n",
    "    else:\n",
    "        h_out = math.ceil((h_in - kh + 1) / strides[0])\n",
    "        w_out = math.ceil((w_in - kw + 1) / strides[1])\n",
    "    flops = h_out * w_out * (kh * kw * c_in) * c_out * 2\n",
    "    return flops, (h_out, w_out, c_out)\n",
    "\n",
    "def calculate_dense_flops(in_size, out_size):\n",
    "    return in_size * out_size * 2\n",
    "\n",
    "def calculate_model_flops(model, input_shape):\n",
    "    total = 0\n",
    "    current_shape = tuple(input_shape)\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, layers.Conv2D):\n",
    "            weights = layer.get_weights()\n",
    "            if not weights:\n",
    "                continue\n",
    "            kernel_shape = weights[0].shape  # (kh, kw, in_c, out_c)\n",
    "            layer_flops, current_shape = calculate_conv_flops(current_shape, kernel_shape, strides=layer.strides, padding=layer.padding)\n",
    "            total += layer_flops\n",
    "        elif isinstance(layer, layers.Flatten):\n",
    "            current_shape = (int(np.prod(current_shape)),)\n",
    "        elif isinstance(layer, layers.Dense):\n",
    "            in_size = current_shape[0] if isinstance(current_shape, tuple) and len(current_shape)>0 else int(current_shape)\n",
    "            layer_flops = calculate_dense_flops(in_size, layer.units)\n",
    "            total += layer_flops\n",
    "            current_shape = (layer.units,)\n",
    "        elif isinstance(layer, layers.MaxPooling2D):\n",
    "            h,w,c = current_shape\n",
    "            pool = layer.pool_size[0] if hasattr(layer.pool_size, \"__getitem__\") else layer.pool_size\n",
    "            current_shape = (h//pool, w//pool, c)\n",
    "        else:\n",
    "            # ignore other layers for shape changes\n",
    "            pass\n",
    "    return total\n",
    "\n",
    "def measure_inference_time(model, sample_batch, steps=20):\n",
    "    model.predict(sample_batch, verbose=0)  # warmup\n",
    "    t0 = time.time()\n",
    "    for _ in range(steps):\n",
    "        model.predict(sample_batch, verbose=0)\n",
    "    t1 = time.time()\n",
    "    return (t1 - t0) / steps\n",
    "\n",
    "# ---------------------------\n",
    "# Save masks helper\n",
    "# ---------------------------\n",
    "def save_masks(masks, path):\n",
    "    serial = {k: v.tolist() for k,v in masks.items()}\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(serial, f, indent=2)\n",
    "    log(\"Saved masks to\", path)\n",
    "\n",
    "# ---------------------------\n",
    "# Plot helper\n",
    "# ---------------------------\n",
    "def plot_mask_histograms(masks, outdir=SAVE_DIR):\n",
    "    if not PLOT_RESULTS:\n",
    "        return\n",
    "    for name, mask in masks.items():\n",
    "        plt.figure(figsize=(5,2))\n",
    "        plt.title(name)\n",
    "        plt.hist(mask, bins=2)\n",
    "        plt.xlabel(\"0=pruned, 1=kept\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(outdir, f\"mask_{name}.png\"))\n",
    "        plt.close()\n",
    "\n",
    "# ---------------------------\n",
    "# MAIN pipeline\n",
    "# ---------------------------\n",
    "def full_pipeline(model_path, dataset_path):\n",
    "    # 1) load model (safe)\n",
    "    model = safe_load_model(model_path)\n",
    "    log(\"Model loaded. Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    # compile original so evaluate works (use small lr default)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # 2) infer input shape\n",
    "    input_shape = model.input_shape[1:]\n",
    "    log(\"Inferred input shape:\", input_shape)\n",
    "\n",
    "    # 3) load dataset\n",
    "    train_ds, val_ds = load_image_folder_dataset(dataset_path, image_size=input_shape[:2], batch_size=BATCH_SIZE)\n",
    "    # calibration subset\n",
    "    calib_ds = train_ds.take(CALIB_BATCHES)\n",
    "\n",
    "    # sample for timing\n",
    "    try:\n",
    "        sample_x, _ = next(iter(val_ds))\n",
    "    except Exception:\n",
    "        sample_x, _ = next(iter(train_ds))\n",
    "    sample_x_small = sample_x[:min(16, sample_x.shape[0])]\n",
    "\n",
    "    # 4) choose layers to prune (conv + hidden dense only)\n",
    "    dense_layers = [lyr for lyr in model.layers if isinstance(lyr, layers.Dense)]\n",
    "    last_dense = dense_layers[-1] if dense_layers else None\n",
    "\n",
    "    prune_layer_names = []\n",
    "    for lyr in model.layers:\n",
    "        if isinstance(lyr, layers.Conv2D):\n",
    "            prune_layer_names.append(lyr.name)\n",
    "        elif isinstance(lyr, layers.Dense) and lyr is not last_dense:\n",
    "            prune_layer_names.append(lyr.name)\n",
    "    log(\"Layers considered for pruning:\", prune_layer_names)\n",
    "\n",
    "    # 5) compute stats\n",
    "    stats = compute_activation_grad_stats(model, prune_layer_names, calib_ds, max_batches=CALIB_BATCHES)\n",
    "\n",
    "    # 6) importance & masks\n",
    "    score_map = compute_importance_scores(stats)\n",
    "    masks = make_masks_from_scores(score_map, keep_ratio=KEEP_RATIO)\n",
    "    save_masks(masks, os.path.join(SAVE_DIR, \"masks.json\"))\n",
    "    plot_mask_histograms(masks)\n",
    "\n",
    "    # 7) build masked model and compile\n",
    "    masked_model = build_masked_model(model, masks)\n",
    "    masked_model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    log(\"Masked model built.\")\n",
    "\n",
    "    # quick eval before FT\n",
    "    try:\n",
    "        loss0, acc0 = masked_model.evaluate(val_ds.take(5), verbose=0)\n",
    "        log(\"Masked model pre-FT acc:\", acc0)\n",
    "    except Exception as e:\n",
    "        log(\"Masked model pre-eval failed:\", e)\n",
    "\n",
    "    # 8) measure baseline flops & time\n",
    "    baseline_flops = calculate_model_flops(model, input_shape)\n",
    "    baseline_time = measure_inference_time(model, sample_x_small, steps=10)\n",
    "    log(f\"Baseline FLOPS: {baseline_flops:,}, baseline time (avg batch): {baseline_time:.4f}s\")\n",
    "\n",
    "    # 9) fine-tune masked model\n",
    "    try:\n",
    "        masked_model.fit(train_ds.take(FT_BATCHES_TO_USE), validation_data=val_ds.take(5), epochs=FT_EPOCHS, verbose=2)\n",
    "    except Exception as e:\n",
    "        log(\"Masked fine-tune failed/partial:\", e)\n",
    "\n",
    "    # 10) structural prune\n",
    "    pruned_model = prune_structural_sequential(model, masks, input_shape)\n",
    "    pruned_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    log(\"Starting fine-tuning of PRUNED model (100 epochs + EarlyStopping)...\")\n",
    "\n",
    "    early_cb = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=3,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        pruned_model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=100,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=[early_cb],\n",
    "        verbose=2\n",
    "        )\n",
    "    except Exception as e:\n",
    "        log(\"Pruned model fine-tune failed/partial:\", e)\n",
    "\n",
    "\n",
    "    # 11) evaluate models\n",
    "    log(\"Evaluating Original model:\")\n",
    "    orig_loss, orig_acc = model.evaluate(val_ds, verbose=0)\n",
    "    log(\"Original acc:\", orig_acc)\n",
    "\n",
    "    log(\"Evaluating Masked model (after FT):\")\n",
    "    try:\n",
    "        mask_loss, mask_acc = masked_model.evaluate(val_ds, verbose=0)\n",
    "        log(\"Masked acc:\", mask_acc)\n",
    "    except Exception as e:\n",
    "        log(\"Masked evaluate failed:\", e)\n",
    "        mask_acc = None\n",
    "\n",
    "    log(\"Evaluating Pruned model:\")\n",
    "    try:\n",
    "        pruned_loss, pruned_acc = pruned_model.evaluate(val_ds, verbose=0)\n",
    "        log(\"Pruned acc:\", pruned_acc)\n",
    "    except Exception as e:\n",
    "        log(\"Pruned evaluate failed:\", e)\n",
    "        pruned_acc = None\n",
    "\n",
    "    # 12) FLOPS & timing after prune\n",
    "    pruned_flops = calculate_model_flops(pruned_model, input_shape)\n",
    "    pruned_time = measure_inference_time(pruned_model, sample_x_small, steps=10)\n",
    "    log(f\"Pruned FLOPS: {pruned_flops:,}, pruned time: {pruned_time:.4f}s\")\n",
    "\n",
    "    # 13) summary & save\n",
    "    reduction = 1.0 - (pruned_flops / baseline_flops) if baseline_flops > 0 else 0.0\n",
    "    log(\"=\"*60)\n",
    "    log(\"SUMMARY:\")\n",
    "    log(f\"Baseline FLOPS: {baseline_flops:,}\")\n",
    "    log(f\"Pruned FLOPS:   {pruned_flops:,}\")\n",
    "    log(f\"FLOPS reduction: {reduction:.2%}\")\n",
    "    log(f\"Original acc: {orig_acc}, Masked acc: {mask_acc}, Pruned acc: {pruned_acc}\")\n",
    "    log(\"=\"*60)\n",
    "\n",
    "    # ---- Extra Metrics: GFLOPS + Accuracy Reduction ----\n",
    "    baseline_gflops = baseline_flops / 1e9\n",
    "    pruned_gflops = pruned_flops / 1e9\n",
    "    gflops_reduction = 1.0 - (pruned_gflops / baseline_gflops) if baseline_gflops > 0 else 0.0\n",
    "\n",
    "    acc_reduction = (orig_acc - pruned_acc) if (orig_acc is not None and pruned_acc is not None) else None\n",
    "\n",
    "    log(f\"Baseline GFLOPS: {baseline_gflops:.4f}\")\n",
    "    log(f\"Pruned GFLOPS:   {pruned_gflops:.4f}\")\n",
    "    log(f\"GFLOPS reduction: {gflops_reduction:.2%}\")\n",
    "\n",
    "    if acc_reduction is not None:\n",
    "        log(f\"Accuracy reduction: {acc_reduction:.4f}\")\n",
    "    else:\n",
    "        log(\"Accuracy reduction: N/A\")\n",
    "\n",
    "\n",
    "    # save artifacts\n",
    "    try:\n",
    "        model.save(os.path.join(SAVE_DIR, \"model_baseline\"))\n",
    "        masked_model.save(os.path.join(SAVE_DIR, \"model_masked\"))\n",
    "        pruned_model.save(os.path.join(SAVE_DIR, \"model_pruned\"))\n",
    "        log(\"Saved models to\", SAVE_DIR)\n",
    "    except Exception as e:\n",
    "        log(\"Save models failed:\", e)\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"masked_model\": masked_model,\n",
    "        \"pruned_model\": pruned_model,\n",
    "        \"masks\": masks,\n",
    "        \"baseline_flops\": baseline_flops,\n",
    "        \"pruned_flops\": pruned_flops,\n",
    "        \"baseline_time\": baseline_time,\n",
    "        \"pruned_time\": pruned_time,\n",
    "        \"orig_acc\": orig_acc,\n",
    "        \"mask_acc\": mask_acc,\n",
    "        \"pruned_acc\": pruned_acc\n",
    "    }\n",
    "\n",
    "# ---------------------------\n",
    "# Run\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    out = full_pipeline(MODEL_PATH, DATASET_PATH)\n",
    "    log(\"Pipeline finished. Outputs:\", out.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524f9770",
   "metadata": {},
   "source": [
    "# **Main CNN with early call back for both multi as well as binary classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50e7546b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading model: D:\\college\\sem-8\\models\\garbage_cnn_model.h5\n",
      "[INFO] Loaded model directly.\n",
      "[INFO] Model loaded. Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36992</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">9,470,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,542</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36992\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m9,470,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │         \u001b[38;5;34m1,542\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,564,998</span> (36.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,564,998\u001b[0m (36.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,564,998</span> (36.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,564,998\u001b[0m (36.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inferred input shape: (150, 150, 3)\n",
      "[INFO] Loading dataset folder: D:\\college\\sem-8\\dataset\\Garbage classification\\Garbage classification image_size: (150, 150)\n",
      "Found 2527 files belonging to 6 classes.\n",
      "Using 2022 files for training.\n",
      "Found 2527 files belonging to 6 classes.\n",
      "Using 505 files for validation.\n",
      "Found 2527 files belonging to 6 classes.\n",
      "[INFO] Detected dataset classes (num_classes): 6\n",
      "[INFO] Model output matches dataset classes.\n",
      "[INFO] Final model used (after potential rebuild). Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36992</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">9,470,208</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,542</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36992\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m9,470,208\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │         \u001b[38;5;34m1,542\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,564,998</span> (36.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,564,998\u001b[0m (36.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,564,998</span> (36.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,564,998\u001b[0m (36.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Layers considered for pruning: ['conv2d_8', 'conv2d_9', 'conv2d_10', 'dense_4']\n",
      "[INFO] Computing activation & gradient stats...\n",
      "[INFO] conv2d_8: len=32 meanA=3.907894e-02 meanG=4.665647e-06 meanV=1.253217e-03\n",
      "[INFO] conv2d_9: len=64 meanA=1.634991e-02 meanG=9.924619e-06 meanV=8.001033e-04\n",
      "[INFO] conv2d_10: len=128 meanA=4.965286e-03 meanG=2.531735e-05 meanV=6.397757e-04\n",
      "[INFO] dense_4: len=256 meanA=2.026012e-01 meanG=6.300302e-04 meanV=2.911527e-01\n",
      "[INFO] conv2d_8: keep 26/32\n",
      "[INFO] conv2d_9: keep 53/64\n",
      "[INFO] conv2d_10: keep 106/128\n",
      "[INFO] dense_4: keep 212/256\n",
      "[INFO] Saved masks to pruning_output\\masks.json\n",
      "[INFO] Building masked model with gates (cloning layers)...\n",
      "[INFO] Masked model created: sequential_2_masked\n",
      "[INFO] Masked model built.\n",
      "[INFO] Masked model pre-FT acc: 0.684374988079071\n",
      "[INFO] Baseline FLOPS: 418,355,200, baseline time (avg batch): 0.1179s\n",
      "Epoch 1/3\n",
      "32/32 - 28s - 861ms/step - accuracy: 0.6578 - loss: 0.9145 - val_accuracy: 0.6969 - val_loss: 0.8313\n",
      "Epoch 2/3\n",
      "32/32 - 26s - 810ms/step - accuracy: 0.6815 - loss: 0.8943 - val_accuracy: 0.7156 - val_loss: 0.7855\n",
      "Epoch 3/3\n",
      "32/32 - 26s - 820ms/step - accuracy: 0.6939 - loss: 0.8468 - val_accuracy: 0.7344 - val_loss: 0.7675\n",
      "[INFO] Structural pruning (safe) start...\n",
      "[INFO] Structural pruning (safe) start...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ishan\\Documents\\sample_p1\\env\\Lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Warning: couldn't set weights for conv2d_9_pruned : Layer conv2d_9_pruned weight shape (3, 3, 26, 53) is not compatible with provided weight shape (3, 3, 32, 53).\n",
      "[INFO] Warning: couldn't set weights for conv2d_10_pruned : Layer conv2d_10_pruned weight shape (3, 3, 53, 106) is not compatible with provided weight shape (3, 3, 64, 106).\n",
      "[INFO] Warning: couldn't set weights for dense_4_pruned : Layer dense_4_pruned weight shape (30634, 212) is not compatible with provided weight shape (36992, 212).\n",
      "[INFO] Warning: couldn't set weights for dense_5_pruned : Layer dense_5_pruned weight shape (212, 6) is not compatible with provided weight shape (256, 6).\n",
      "[INFO] Structural pruning complete. New model summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2_struct_pruned\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2_struct_pruned\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_8_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">728</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">74</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">53</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,455</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">53</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">106</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,668</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">106</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30634</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">212</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">6,494,620</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">212</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5_pruned (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,278</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_8_pruned (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m148\u001b[0m, \u001b[38;5;34m26\u001b[0m)   │           \u001b[38;5;34m728\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m74\u001b[0m, \u001b[38;5;34m26\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9_pruned (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m72\u001b[0m, \u001b[38;5;34m53\u001b[0m)     │        \u001b[38;5;34m12,455\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_9 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m36\u001b[0m, \u001b[38;5;34m53\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_10_pruned (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m106\u001b[0m)    │        \u001b[38;5;34m50,668\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_10 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m106\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30634\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4_pruned (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m212\u001b[0m)            │     \u001b[38;5;34m6,494,620\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m212\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5_pruned (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │         \u001b[38;5;34m1,278\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,559,749</span> (25.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,559,749\u001b[0m (25.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,559,749</span> (25.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,559,749\u001b[0m (25.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Starting fine-tuning of PRUNED model (EarlyStopping)...\n",
      "Epoch 1/20\n",
      "32/32 - 23s - 724ms/step - accuracy: 0.3398 - loss: 1.5953 - val_accuracy: 0.3842 - val_loss: 1.4580\n",
      "Epoch 2/20\n",
      "32/32 - 19s - 597ms/step - accuracy: 0.4545 - loss: 1.3824 - val_accuracy: 0.4436 - val_loss: 1.3553\n",
      "Epoch 3/20\n",
      "32/32 - 21s - 655ms/step - accuracy: 0.4931 - loss: 1.2840 - val_accuracy: 0.4634 - val_loss: 1.3128\n",
      "Epoch 4/20\n",
      "32/32 - 17s - 532ms/step - accuracy: 0.5223 - loss: 1.2243 - val_accuracy: 0.4891 - val_loss: 1.2259\n",
      "Epoch 5/20\n",
      "32/32 - 17s - 533ms/step - accuracy: 0.5569 - loss: 1.1549 - val_accuracy: 0.5307 - val_loss: 1.2143\n",
      "Epoch 6/20\n",
      "32/32 - 17s - 533ms/step - accuracy: 0.5692 - loss: 1.1153 - val_accuracy: 0.5485 - val_loss: 1.1570\n",
      "Epoch 7/20\n",
      "32/32 - 18s - 573ms/step - accuracy: 0.5989 - loss: 1.0659 - val_accuracy: 0.5545 - val_loss: 1.1248\n",
      "Epoch 8/20\n",
      "32/32 - 17s - 534ms/step - accuracy: 0.6182 - loss: 1.0355 - val_accuracy: 0.5842 - val_loss: 1.0907\n",
      "Epoch 9/20\n",
      "32/32 - 18s - 574ms/step - accuracy: 0.6316 - loss: 0.9896 - val_accuracy: 0.6040 - val_loss: 1.0673\n",
      "Epoch 10/20\n",
      "32/32 - 17s - 537ms/step - accuracy: 0.6409 - loss: 0.9503 - val_accuracy: 0.5802 - val_loss: 1.0467\n",
      "Epoch 11/20\n",
      "32/32 - 17s - 539ms/step - accuracy: 0.6662 - loss: 0.9103 - val_accuracy: 0.6099 - val_loss: 1.0179\n",
      "Epoch 12/20\n",
      "32/32 - 18s - 559ms/step - accuracy: 0.6800 - loss: 0.8956 - val_accuracy: 0.6238 - val_loss: 0.9906\n",
      "Epoch 13/20\n",
      "32/32 - 17s - 525ms/step - accuracy: 0.6904 - loss: 0.8580 - val_accuracy: 0.6436 - val_loss: 0.9902\n",
      "Epoch 14/20\n",
      "32/32 - 17s - 527ms/step - accuracy: 0.6815 - loss: 0.8440 - val_accuracy: 0.6436 - val_loss: 0.9681\n",
      "Epoch 15/20\n",
      "32/32 - 20s - 613ms/step - accuracy: 0.6949 - loss: 0.8128 - val_accuracy: 0.6356 - val_loss: 0.9614\n",
      "[INFO] Evaluating Original model:\n",
      "[INFO] Original acc: 0.6732673048973083\n",
      "[INFO] Evaluating Masked model (after FT):\n",
      "[INFO] Masked acc: 0.7148514986038208\n",
      "[INFO] Evaluating Pruned model:\n",
      "[INFO] Pruned acc: 0.6435643434524536\n",
      "[INFO] Pruned FLOPS: 289,227,856, pruned time: 0.1038s\n",
      "[INFO] ============================================================\n",
      "[INFO] SUMMARY:\n",
      "[INFO] Baseline FLOPS: 418,355,200\n",
      "[INFO] Pruned FLOPS: 289,227,856\n",
      "[INFO] FLOPS reduction: 30.87%\n",
      "[INFO] Original acc: 0.6732673048973083, Masked acc: 0.7148514986038208, Pruned acc: 0.6435643434524536\n",
      "[INFO] ============================================================\n",
      "[INFO] Baseline GFLOPS: 0.4184\n",
      "[INFO] Pruned GFLOPS: 0.2892\n",
      "[INFO] GFLOPS reduction: 30.87%\n",
      "[INFO] Accuracy reduction: 0.0297\n",
      "[INFO] Saved models under names: garbage_cnn_model_baseline.keras, garbage_cnn_model_masked.keras, garbage_cnn_model_pruned.keras\n",
      "[INFO] Saved models to pruning_output\n",
      "[INFO] Pipeline finished. Outputs: dict_keys(['model', 'masked_model', 'pruned_model', 'masks', 'baseline_flops', 'pruned_flops', 'baseline_time', 'pruned_time', 'orig_acc', 'mask_acc', 'pruned_acc'])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "sequential_cnn_pruning_full_fixed.py\n",
    "Full Sequential CNN pruning pipeline (single-file)\n",
    "\n",
    "- Loads user Sequential CNN (.h5/.keras / SavedModel)\n",
    "- Sanitizes layer names in .h5 if they contain '/'\n",
    "- Loads folder dataset (image_dataset_from_directory)\n",
    "- Computes activation/gradient/variance importance\n",
    "- Creates masks (keep_ratio)\n",
    "- Builds masked model (gating layer)\n",
    "- Fine-tunes masked model\n",
    "- Structurally prunes model (conv filter removal, prune Dense outputs only)\n",
    "- Computes FLOPS & timings, evaluates models\n",
    "- Saves models and masks\n",
    "\n",
    "Fixes:\n",
    "- Ensures final layer matches dataset classes (automatically rebuilds final layer if needed)\n",
    "- Uses appropriate loss function (binary vs sparse categorical) during stat collection and training\n",
    "- Adds GFLOPS, accuracy reduction, inference timing\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# ---------------------------\n",
    "# USER CONFIG (edit paths)\n",
    "# ---------------------------\n",
    "MODEL_PATH = r\"D:\\college\\sem-8\\models\\garbage_cnn_model.h5\"   # path to model (.h5/.keras or SavedModel dir)\n",
    "DATASET_PATH = r\"D:\\college\\sem-8\\dataset\\Garbage classification\\Garbage classification\"      # folder with subfolders per class\n",
    "SAVE_DIR = r\"pruning_output\"                                 # where outputs are saved\n",
    "base_name = os.path.splitext(os.path.basename(MODEL_PATH))[0]\n",
    "\n",
    "\n",
    "KEEP_RATIO = 0.83            # fraction of channels/units to keep\n",
    "ALPHA, BETA, GAMMA = 0.4, 0.3, 0.3  # importance weights\n",
    "BATCH_SIZE = 64\n",
    "CALIB_BATCHES = 30\n",
    "FT_EPOCHS = 3\n",
    "FT_BATCHES_TO_USE = 150\n",
    "PLOT_RESULTS = True\n",
    "VERBOSE = True\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def log(*args):\n",
    "    if VERBOSE:\n",
    "        print(\"[INFO]\", *args)\n",
    "\n",
    "# ---------------------------\n",
    "# Safe load model (handles '/' in h5 layer names)\n",
    "# ---------------------------\n",
    "def safe_load_model(model_path):\n",
    "    \"\"\"\n",
    "    Try normal load_model; if fails (e.g., '/' in layer names in H5), sanitize model_config JSON and rebuild.\n",
    "    Returns a Keras model (compiled=False).\n",
    "    \"\"\"\n",
    "    log(\"Loading model:\", model_path)\n",
    "    # Try direct load first\n",
    "    try:\n",
    "        m = tf.keras.models.load_model(model_path, compile=False)\n",
    "        log(\"Loaded model directly.\")\n",
    "        return m\n",
    "    except Exception as e:\n",
    "        log(\"Direct load failed:\", e)\n",
    "\n",
    "    # If HDF5, attempt to sanitize layer names in model_config\n",
    "    try:\n",
    "        with h5py.File(model_path, \"r\") as f:\n",
    "            if \"model_config\" in f:\n",
    "                raw = f[\"model_config\"][()]\n",
    "                if isinstance(raw, bytes):\n",
    "                    raw = raw.decode(\"utf-8\")\n",
    "                cfg_json = json.loads(raw)\n",
    "                changed = False\n",
    "                for layer in cfg_json.get(\"config\", {}).get(\"layers\", []):\n",
    "                    cfg = layer.get(\"config\", {})\n",
    "                    name = cfg.get(\"name\")\n",
    "                    if isinstance(name, str) and \"/\" in name:\n",
    "                        new_name = name.replace(\"/\", \"_\")\n",
    "                        cfg[\"name\"] = new_name\n",
    "                        changed = True\n",
    "                        log(f\"[FIX] layer name: {name} -> {new_name}\")\n",
    "                if changed:\n",
    "                    fixed_json = json.dumps(cfg_json)\n",
    "                    model = tf.keras.models.model_from_json(fixed_json)\n",
    "                    model.load_weights(model_path)\n",
    "                    log(\"Loaded model from sanitized JSON + weights.\")\n",
    "                    return model\n",
    "    except Exception as e2:\n",
    "        log(\"H5 sanitization attempt failed:\", e2)\n",
    "\n",
    "    # final fallback: try load_model with safe_mode=False (older TF)\n",
    "    try:\n",
    "        m = tf.keras.models.load_model(model_path, compile=False, safe_mode=False)\n",
    "        log(\"Loaded model with safe_mode=False.\")\n",
    "        return m\n",
    "    except Exception as e3:\n",
    "        log(\"All load attempts failed:\", e3)\n",
    "        raise RuntimeError(\"Failed to load model. Ensure path and format are correct.\")\n",
    "\n",
    "# ---------------------------\n",
    "# Rebuild final layer to match num_classes (safe, best-effort)\n",
    "# ---------------------------\n",
    "def ensure_output_matches_dataset(orig_model, num_classes):\n",
    "    \"\"\"\n",
    "    If the model's current output shape doesn't match num_classes, rebuild final output\n",
    "    to match. Works for Sequential-style networks. Returns new_model, loss_fn.\n",
    "    \"\"\"\n",
    "    # Determine model's output dim\n",
    "    out_shape = tuple(orig_model.output_shape) if orig_model.output_shape is not None else None\n",
    "    # If already matches (and for multiclass softmax case), return original and appropriate loss.\n",
    "    if out_shape is not None:\n",
    "        if num_classes == 2 and (out_shape[-1] == 1 or out_shape[-1] == 2):\n",
    "            # binary case: allow Dense(1) or Dense(2) (Dense(2) could be softmax but labels are 0/1)\n",
    "            log(\"Model output seems compatible with binary classification.\")\n",
    "            loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False) if out_shape[-1] == 1 else tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "            return orig_model, loss_fn\n",
    "        if num_classes > 2 and out_shape[-1] == num_classes:\n",
    "            log(\"Model output matches dataset classes.\")\n",
    "            loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "            return orig_model, loss_fn\n",
    "\n",
    "    # Need to rebuild final layer\n",
    "    log(\"Rebuilding model final layer to match num_classes:\", num_classes)\n",
    "    # We'll clone all layers except the last one and then append a new final dense.\n",
    "    # Use layer.from_config to avoid reusing layer objects in two models.\n",
    "    new_seq = models.Sequential(name=(orig_model.name or \"rebuilt_model\") + \"_rebuilt\")\n",
    "    # Add InputLayer\n",
    "    input_shape = orig_model.input_shape[1:]\n",
    "    new_seq.add(layers.InputLayer(input_shape=tuple(input_shape)))\n",
    "\n",
    "    # Clone all layers except the last (we will replace last)\n",
    "    # We'll attempt to copy weights for layers that remain identical\n",
    "    for layer in orig_model.layers[:-1]:\n",
    "        try:\n",
    "            cfg = layer.get_config()\n",
    "            Cls = layer.__class__\n",
    "            cloned = Cls.from_config(cfg)\n",
    "            new_seq.add(cloned)\n",
    "            # set weights if possible and shapes match\n",
    "            try:\n",
    "                w = layer.get_weights()\n",
    "                if w:\n",
    "                    new_seq.layers[-1].set_weights(w)\n",
    "            except Exception:\n",
    "                # ignore weight copy failures\n",
    "                pass\n",
    "        except Exception:\n",
    "            # fallback: try to append original layer (may cause errors but best-effort)\n",
    "            try:\n",
    "                new_seq.add(layer)\n",
    "            except Exception:\n",
    "                log(\"Warning: couldn't clone layer\", layer.name, \"- skipping weights copy.\")\n",
    "\n",
    "    # Add new final layer depending on num_classes\n",
    "    if num_classes == 2:\n",
    "        # binary: Dense(1, activation='sigmoid')\n",
    "        new_seq.add(layers.Dense(1, activation=\"sigmoid\", name=\"output_rebuilt\"))\n",
    "        loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    else:\n",
    "        new_seq.add(layers.Dense(num_classes, activation=\"softmax\", name=\"output_rebuilt\"))\n",
    "        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "    # Try to compile minimal to ensure shape correctness (we'll let caller compile fully later)\n",
    "    return new_seq, loss_fn\n",
    "\n",
    "# ---------------------------\n",
    "# Dataset loader (folder-based)\n",
    "# ---------------------------\n",
    "def load_image_folder_dataset(path, image_size, batch_size=BATCH_SIZE):\n",
    "    log(\"Loading dataset folder:\", path, \"image_size:\", image_size)\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        path,\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=42,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        path,\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        seed=42,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    rescaler = layers.Rescaling(1.0 / 255)\n",
    "    train_ds = train_ds.map(lambda x, y: (rescaler(x), y)).prefetch(tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.map(lambda x, y: (rescaler(x), y)).prefetch(tf.data.AUTOTUNE)\n",
    "    return train_ds, val_ds\n",
    "\n",
    "# ---------------------------\n",
    "# Activation & gradient stats (uses provided loss function)\n",
    "# ---------------------------\n",
    "def compute_activation_grad_stats(model, layer_names, dataset, loss_fn, max_batches=CALIB_BATCHES):\n",
    "    \"\"\"\n",
    "    For each layer in layer_names, compute:\n",
    "      - A: mean(abs(activation)) per filter/unit\n",
    "      - G: mean(abs(grad wrt activation)) per filter/unit\n",
    "      - V: variance(activation) per filter/unit\n",
    "    Returns: dict name -> (A, G, V)\n",
    "    \"\"\"\n",
    "    log(\"Computing activation & gradient stats...\")\n",
    "    results = {n: [] for n in layer_names}\n",
    "    grad_results = {n: [] for n in layer_names}\n",
    "    var_results = {n: [] for n in layer_names}\n",
    "\n",
    "    batch_count = 0\n",
    "    for x_batch, y_batch in dataset:\n",
    "        if batch_count >= max_batches:\n",
    "            break\n",
    "        batch_count += 1\n",
    "        layer_acts = {}\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            a = x_batch\n",
    "            for layer in model.layers:\n",
    "                a = layer(a)\n",
    "                if layer.name in layer_names:\n",
    "                    tape.watch(a)\n",
    "                    layer_acts[layer.name] = a\n",
    "            preds = a\n",
    "            # compute loss using provided loss_fn (works for both binary & sparse categorical)\n",
    "            # When loss_fn is a Keras loss instance, call like a function\n",
    "            # Ensure y_batch dtype is int for sparse CE, float for binary BCE\n",
    "            try:\n",
    "                loss_vals = loss_fn(y_batch, preds)\n",
    "            except Exception:\n",
    "                # fallback attempt: convert types for binary\n",
    "                if isinstance(loss_fn, tf.keras.losses.BinaryCrossentropy):\n",
    "                    loss_vals = loss_fn(tf.cast(y_batch, tf.float32), preds)\n",
    "                else:\n",
    "                    loss_vals = loss_fn(y_batch, preds)\n",
    "            loss = tf.reduce_mean(loss_vals)\n",
    "\n",
    "        for name in layer_names:\n",
    "            a = layer_acts[name]\n",
    "            if len(a.shape) == 4:\n",
    "                A = tf.reduce_mean(tf.abs(a), axis=(0,1,2)).numpy()\n",
    "                V = tf.math.reduce_variance(a, axis=(0,1,2)).numpy()\n",
    "            else:\n",
    "                A = tf.reduce_mean(tf.abs(a), axis=0).numpy()\n",
    "                V = tf.math.reduce_variance(a, axis=0).numpy()\n",
    "\n",
    "            grad = tape.gradient(loss, a)\n",
    "            if grad is None:\n",
    "                G = np.zeros_like(A)\n",
    "            else:\n",
    "                if len(grad.shape) == 4:\n",
    "                    G = tf.reduce_mean(tf.abs(grad), axis=(0,1,2)).numpy()\n",
    "                else:\n",
    "                    G = tf.reduce_mean(tf.abs(grad), axis=0).numpy()\n",
    "\n",
    "            results[name].append(A)\n",
    "            var_results[name].append(V)\n",
    "            grad_results[name].append(G)\n",
    "        del tape\n",
    "\n",
    "    stats = {}\n",
    "    for name in layer_names:\n",
    "        A = np.mean(results[name], axis=0)\n",
    "        V = np.mean(var_results[name], axis=0)\n",
    "        G = np.mean(grad_results[name], axis=0)\n",
    "        stats[name] = (A, G, V)\n",
    "        log(f\"{name}: len={len(A)} meanA={A.mean():.6e} meanG={G.mean():.6e} meanV={V.mean():.6e}\")\n",
    "    return stats\n",
    "\n",
    "# ---------------------------\n",
    "# Importance scores & masks\n",
    "# ---------------------------\n",
    "def compute_importance_scores(stats, alpha=ALPHA, beta=BETA, gamma=GAMMA):\n",
    "    def normalize(x):\n",
    "        x = x - x.min()\n",
    "        if x.max() > 0:\n",
    "            x = x / x.max()\n",
    "        return x\n",
    "    scores = {}\n",
    "    for name, (A, G, V) in stats.items():\n",
    "        scores[name] = alpha * normalize(A) + beta * normalize(G) + gamma * normalize(V)\n",
    "    return scores\n",
    "\n",
    "def make_masks_from_scores(score_map, keep_ratio=KEEP_RATIO):\n",
    "    masks = {}\n",
    "    for name, score in score_map.items():\n",
    "        k = max(1, int(len(score) * keep_ratio))\n",
    "        thresh = np.partition(score, -k)[-k]\n",
    "        mask = (score >= thresh).astype(np.float32)\n",
    "        masks[name] = mask\n",
    "        log(f\"{name}: keep {int(mask.sum())}/{len(mask)}\")\n",
    "    return masks\n",
    "\n",
    "# ---------------------------\n",
    "# Mask gate layer & masked model\n",
    "# ---------------------------\n",
    "class CNNGate(tf.keras.layers.Layer):\n",
    "    def __init__(self, channels, mask=None, **kwargs):\n",
    "        \"\"\"\n",
    "        channels: int number of channels this gate controls\n",
    "        mask: 1D array-like of length 'channels' with 0/1 values (or floats in [0,1]).\n",
    "              If provided, gate variable is initialized to these values; otherwise ones.\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.channels = int(channels)\n",
    "        # store mask as numpy array if provided (for serialization convenience)\n",
    "        self._init_mask = None if mask is None else np.array(mask, dtype=np.float32)\n",
    "        init_val = self._init_mask if self._init_mask is not None else np.ones((self.channels,), dtype=np.float32)\n",
    "        # gate is non-trainable scalar per-channel multiplier\n",
    "        self.gate = self.add_weight(\n",
    "            name=\"gate\",\n",
    "            shape=(self.channels,),\n",
    "            initializer=tf.keras.initializers.Constant(init_val),\n",
    "            trainable=False,\n",
    "            dtype=tf.float32,\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # supports inputs with shape [batch, H, W, C] or [batch, C] (works broadcasting)\n",
    "        g = self.gate\n",
    "        # expand dims to match channels in conv output\n",
    "        if len(inputs.shape) == 4:\n",
    "            return inputs * g[None, None, None, :]\n",
    "        elif len(inputs.shape) == 2:\n",
    "            return inputs * g[None, :]\n",
    "        else:\n",
    "            # fallback broadcasting\n",
    "            return inputs * g\n",
    "\n",
    "    def get_config(self):\n",
    "        cfg = super().get_config()\n",
    "        # do NOT embed gate values directly here (weights are saved by Keras),\n",
    "        # but we include channels for reconstruction convenience.\n",
    "        cfg.update({\n",
    "            \"channels\": self.channels,\n",
    "            # don't include mask/gate here to avoid duplicating weight data;\n",
    "            # the gate weight will be saved/loaded normally by Keras.\n",
    "        })\n",
    "        return cfg\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        # config may only contain \"channels\" — weight values will be restored by Keras load.\n",
    "        channels = config.pop(\"channels\")\n",
    "        return cls(channels=channels, **config)\n",
    "\n",
    "\n",
    "def build_masked_model(orig_model, masks):\n",
    "    \"\"\"\n",
    "    Build a new functional model with cloned layers from orig_model and insert a CNNGate\n",
    "    after each layer named in `masks`. The gate is initialized from masks[layer_name].\n",
    "    \"\"\"\n",
    "    log(\"Building masked model with gates (cloning layers)...\")\n",
    "    inp = tf.keras.Input(shape=orig_model.input_shape[1:])\n",
    "    x = inp\n",
    "\n",
    "    # keep mapping from original layer name -> new layer object (for weight copying)\n",
    "    for layer in orig_model.layers:\n",
    "        # clone layer if possible to avoid reusing original layer objects\n",
    "        try:\n",
    "            cfg = layer.get_config()\n",
    "            Cls = layer.__class__\n",
    "            new_layer = Cls.from_config(cfg)\n",
    "        except Exception:\n",
    "            # fallback: try to reuse the layer (less safe)\n",
    "            new_layer = layer\n",
    "\n",
    "        # apply the new layer to current tensor\n",
    "        x = new_layer(x)\n",
    "\n",
    "        # copy weights if layer had weights and we cloned it\n",
    "        try:\n",
    "            w = layer.get_weights()\n",
    "            if w:\n",
    "                try:\n",
    "                    new_layer.set_weights(w)\n",
    "                except Exception:\n",
    "                    # some layers (e.g., fused ops) may not accept direct set_weights — ignore\n",
    "                    pass\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        # insert gate if this original layer is in masks\n",
    "        if layer.name in masks:\n",
    "            mask = np.array(masks[layer.name], dtype=np.float32)\n",
    "            channels = int(mask.shape[0])\n",
    "            gate_layer = CNNGate(channels=channels, mask=mask, name=layer.name + \"_gate\")\n",
    "            x = gate_layer(x)\n",
    "            # gate weight is already initialized from mask in CNNGate.__init__, so nothing else to do\n",
    "\n",
    "    masked = tf.keras.Model(inputs=inp, outputs=x, name=(orig_model.name or \"model\") + \"_masked\")\n",
    "    log(\"Masked model created:\", masked.name)\n",
    "    return masked\n",
    "\n",
    "# ---------------------------\n",
    "# Structural pruning (safe)\n",
    "# ---------------------------\n",
    "def prune_structural_sequential(orig_model, masks, input_shape):\n",
    "    \"\"\"\n",
    "    Structural pruning for Sequential models.\n",
    "    - Prune Conv2D output filters using masks[layer.name]\n",
    "    - Prune Dense output units only (do not slice Dense input rows that come from Flatten/Conv)\n",
    "    - Attempt to slice BatchNorm params to match conv outputs\n",
    "    \"\"\"\n",
    "    log(\"Structural pruning (safe) start...\")\n",
    "    new_layers = []\n",
    "    prev_was_conv_like = False  # indicates that Flatten/Conv preceded Dense inputs\n",
    "\n",
    "    for layer in orig_model.layers:\n",
    "        # Conv2D: slice output channels\n",
    "        if isinstance(layer, layers.Conv2D):\n",
    "            W, b = layer.get_weights()\n",
    "            orig_out = W.shape[-1]\n",
    "            mask = masks.get(layer.name, np.ones(orig_out, dtype=np.float32))\n",
    "            keep_idx = np.where(mask == 1)[0]\n",
    "            if keep_idx.size == 0:\n",
    "                keep_idx = np.array([int(np.argmax(mask))], dtype=np.int32)\n",
    "            W_new = W[:, :, :, keep_idx]\n",
    "            b_new = b[keep_idx]\n",
    "            new_conv = layers.Conv2D(\n",
    "                filters=len(keep_idx),\n",
    "                kernel_size=layer.kernel_size,\n",
    "                strides=layer.strides,\n",
    "                padding=layer.padding,\n",
    "                activation=layer.activation,\n",
    "                use_bias=layer.use_bias,\n",
    "                name=layer.name + \"_pruned\"\n",
    "            )\n",
    "            new_layers.append((new_conv, [W_new, b_new]))\n",
    "            prev_was_conv_like = True\n",
    "            continue\n",
    "\n",
    "        # BatchNorm: slice params if prev was conv-like\n",
    "        if isinstance(layer, layers.BatchNormalization):\n",
    "            try:\n",
    "                weights = layer.get_weights()\n",
    "                if prev_was_conv_like and new_layers:\n",
    "                    prev_layer_obj, prev_w = new_layers[-1]\n",
    "                    if prev_w is not None:\n",
    "                        out_ch = prev_w[0].shape[-1]  # kernel last dim\n",
    "                        gamma, beta, mean, var = weights\n",
    "                        gamma = gamma[:out_ch]\n",
    "                        beta = beta[:out_ch]\n",
    "                        mean = mean[:out_ch]\n",
    "                        var = var[:out_ch]\n",
    "                        new_bn = layers.BatchNormalization.from_config(layer.get_config())\n",
    "                        new_layers.append((new_bn, [gamma, beta, mean, var]))\n",
    "                        continue\n",
    "            except Exception:\n",
    "                pass\n",
    "            # fallback keep BN as-is\n",
    "            try:\n",
    "                new_bn = layers.BatchNormalization.from_config(layer.get_config())\n",
    "                new_layers.append((new_bn, layer.get_weights()))\n",
    "            except Exception:\n",
    "                new_layers.append((layer, layer.get_weights() if hasattr(layer, \"get_weights\") else None))\n",
    "            # prev_was_conv_like unchanged\n",
    "            continue\n",
    "\n",
    "        # MaxPool/Activation/Dropout/Flatten/GlobalAvgPool: clone or reuse\n",
    "        if isinstance(layer, (layers.MaxPooling2D, layers.Activation, layers.ReLU, layers.Dropout, layers.Flatten, layers.GlobalAveragePooling2D)):\n",
    "            try:\n",
    "                cloned = layer.__class__.from_config(layer.get_config())\n",
    "                w = layer.get_weights() if hasattr(layer, \"get_weights\") else None\n",
    "                new_layers.append((cloned, w if w else None))\n",
    "            except Exception:\n",
    "                new_layers.append((layer, layer.get_weights() if hasattr(layer, \"get_weights\") else None))\n",
    "            if isinstance(layer, layers.Flatten) or isinstance(layer, layers.GlobalAveragePooling2D):\n",
    "                prev_was_conv_like = True\n",
    "            continue\n",
    "\n",
    "        # Dense: prune outputs only (safe)\n",
    "        if isinstance(layer, layers.Dense):\n",
    "            W, b = layer.get_weights()  # shape (in_dim, out_dim)\n",
    "            out_mask = masks.get(layer.name, np.ones(W.shape[1], dtype=np.float32))\n",
    "            out_idx = np.where(out_mask == 1)[0]\n",
    "            if out_idx.size == 0:\n",
    "                out_idx = np.array([int(np.argmax(out_mask))], dtype=np.int32)\n",
    "            W_new = W[:, out_idx]   # keep all input rows (safe)\n",
    "            b_new = b[out_idx]\n",
    "            new_dense = layers.Dense(units=W_new.shape[1], activation=layer.activation, name=layer.name + \"_pruned\")\n",
    "            new_layers.append((new_dense, [W_new, b_new]))\n",
    "            prev_was_conv_like = False\n",
    "            continue\n",
    "\n",
    "        # Fallback for other layers\n",
    "        try:\n",
    "            cloned = layer.__class__.from_config(layer.get_config())\n",
    "            w = layer.get_weights() if hasattr(layer, \"get_weights\") else None\n",
    "            new_layers.append((cloned, w if w else None))\n",
    "        except Exception:\n",
    "            new_layers.append((layer, layer.get_weights() if hasattr(layer, \"get_weights\") else None))\n",
    "        prev_was_conv_like = False\n",
    "\n",
    "    # Build new Sequential model with InputLayer\n",
    "    seq = models.Sequential(name=orig_model.name + \"_struct_pruned\")\n",
    "    seq.add(layers.InputLayer(input_shape=tuple(input_shape)))\n",
    "    for lyr_obj, w in new_layers:\n",
    "        seq.add(lyr_obj)\n",
    "        if w is not None:\n",
    "            try:\n",
    "                seq.layers[-1].set_weights(w)\n",
    "            except Exception as e:\n",
    "                log(\"Warning: couldn't set weights for\", seq.layers[-1].name, \":\", e)\n",
    "    log(\"Structural pruning complete. New model summary:\")\n",
    "    seq.summary()\n",
    "    return seq\n",
    "\n",
    "# ---------------------------\n",
    "# FLOPS and timing helpers\n",
    "# ---------------------------\n",
    "def calculate_conv_flops(input_shape, kernel_shape, strides=(1,1), padding='same'):\n",
    "    h_in, w_in, c_in = input_shape\n",
    "    kh, kw, _, c_out = kernel_shape\n",
    "    if padding == 'same':\n",
    "        h_out = math.ceil(h_in / strides[0])\n",
    "        w_out = math.ceil(w_in / strides[1])\n",
    "    else:\n",
    "        h_out = math.ceil((h_in - kh + 1) / strides[0])\n",
    "        w_out = math.ceil((w_in - kw + 1) / strides[1])\n",
    "    flops = h_out * w_out * (kh * kw * c_in) * c_out * 2\n",
    "    return flops, (h_out, w_out, c_out)\n",
    "\n",
    "def calculate_dense_flops(in_size, out_size):\n",
    "    return in_size * out_size * 2\n",
    "\n",
    "def calculate_model_flops(model, input_shape):\n",
    "    total = 0\n",
    "    current_shape = tuple(input_shape)\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, layers.Conv2D):\n",
    "            weights = layer.get_weights()\n",
    "            if not weights:\n",
    "                continue\n",
    "            kernel_shape = weights[0].shape  # (kh, kw, in_c, out_c)\n",
    "            layer_flops, current_shape = calculate_conv_flops(current_shape, kernel_shape, strides=layer.strides, padding=layer.padding)\n",
    "            total += layer_flops\n",
    "        elif isinstance(layer, layers.Flatten):\n",
    "            current_shape = (int(np.prod(current_shape)),)\n",
    "        elif isinstance(layer, layers.Dense):\n",
    "            in_size = current_shape[0] if isinstance(current_shape, tuple) and len(current_shape)>0 else int(current_shape)\n",
    "            layer_flops = calculate_dense_flops(in_size, layer.units)\n",
    "            total += layer_flops\n",
    "            current_shape = (layer.units,)\n",
    "        elif isinstance(layer, layers.MaxPooling2D):\n",
    "            h,w,c = current_shape\n",
    "            pool = layer.pool_size[0] if hasattr(layer.pool_size, \"__getitem__\") else layer.pool_size\n",
    "            current_shape = (h//pool, w//pool, c)\n",
    "        else:\n",
    "            # ignore other layers for shape changes\n",
    "            pass\n",
    "    return total\n",
    "\n",
    "def measure_inference_time(model, sample_batch, steps=20):\n",
    "    model.predict(sample_batch, verbose=0)  # warmup\n",
    "    t0 = time.time()\n",
    "    for _ in range(steps):\n",
    "        model.predict(sample_batch, verbose=0)\n",
    "    t1 = time.time()\n",
    "    return (t1 - t0) / steps\n",
    "\n",
    "# ---------------------------\n",
    "# Save masks helper\n",
    "# ---------------------------\n",
    "def save_masks(masks, path):\n",
    "    serial = {k: v.tolist() for k,v in masks.items()}\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(serial, f, indent=2)\n",
    "    log(\"Saved masks to\", path)\n",
    "\n",
    "# ---------------------------\n",
    "# Plot helper\n",
    "# ---------------------------\n",
    "def plot_mask_histograms(masks, outdir=SAVE_DIR):\n",
    "    if not PLOT_RESULTS:\n",
    "        return\n",
    "    for name, mask in masks.items():\n",
    "        plt.figure(figsize=(5,2))\n",
    "        plt.title(name)\n",
    "        plt.hist(mask, bins=2)\n",
    "        plt.xlabel(\"0=pruned, 1=kept\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(outdir, f\"mask_{name}.png\"))\n",
    "        plt.close()\n",
    "\n",
    "# ---------------------------\n",
    "# MAIN pipeline\n",
    "# ---------------------------\n",
    "def full_pipeline(model_path, dataset_path):\n",
    "    # 1) load model (safe)\n",
    "    model = safe_load_model(model_path)\n",
    "    log(\"Model loaded. Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    # 2) load dataset and infer num_classes\n",
    "    # We need input size so infer from model\n",
    "    input_shape = model.input_shape[1:]\n",
    "    log(\"Inferred input shape:\", input_shape)\n",
    "\n",
    "    train_ds, val_ds = load_image_folder_dataset(dataset_path, image_size=input_shape[:2], batch_size=BATCH_SIZE)\n",
    "    # Determine number of classes from dataset\n",
    "    try:\n",
    "        # tf.data.Dataset from image_dataset_from_directory has .class_names on the original Dataset returned object,\n",
    "        # but not on the batched dataset — so inspect via a fresh loader:\n",
    "        tmp = tf.keras.utils.image_dataset_from_directory(dataset_path, image_size=input_shape[:2], batch_size=1)\n",
    "        num_classes = len(tmp.class_names)\n",
    "        del tmp\n",
    "    except Exception:\n",
    "        # fallback: infer from labels in train_ds\n",
    "        classes = set()\n",
    "        for _, y in train_ds.take(10):\n",
    "            classes.update(y.numpy().tolist())\n",
    "        num_classes = max(classes) + 1 if classes else 2\n",
    "\n",
    "    log(\"Detected dataset classes (num_classes):\", num_classes)\n",
    "\n",
    "    # 3) ensure model output matches dataset classes\n",
    "    model, loss_fn = ensure_output_matches_dataset(model, num_classes)\n",
    "    # compile original so evaluate works (use small lr default) with detected loss\n",
    "    if isinstance(loss_fn, tf.keras.losses.BinaryCrossentropy):\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(), loss=loss_fn, metrics=[\"accuracy\"])\n",
    "    else:\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(), loss=loss_fn, metrics=[\"accuracy\"])\n",
    "\n",
    "    # reprint summary\n",
    "    log(\"Final model used (after potential rebuild). Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    # calibration subset for stats\n",
    "    calib_ds = train_ds.take(CALIB_BATCHES)\n",
    "\n",
    "    # sample for timing\n",
    "    try:\n",
    "        sample_x, _ = next(iter(val_ds))\n",
    "    except Exception:\n",
    "        sample_x, _ = next(iter(train_ds))\n",
    "    sample_x_small = sample_x[:min(16, sample_x.shape[0])]\n",
    "\n",
    "    # 4) choose layers to prune (conv + hidden dense only, not final output)\n",
    "    dense_layers = [lyr for lyr in model.layers if isinstance(lyr, layers.Dense)]\n",
    "    last_dense = dense_layers[-1] if dense_layers else None\n",
    "\n",
    "    prune_layer_names = []\n",
    "    for lyr in model.layers:\n",
    "        if isinstance(lyr, layers.Conv2D):\n",
    "            prune_layer_names.append(lyr.name)\n",
    "        elif isinstance(lyr, layers.Dense) and lyr is not last_dense:\n",
    "            prune_layer_names.append(lyr.name)\n",
    "    log(\"Layers considered for pruning:\", prune_layer_names)\n",
    "\n",
    "    # 5) compute stats (pass loss_fn)\n",
    "    stats = compute_activation_grad_stats(model, prune_layer_names, calib_ds, loss_fn=loss_fn, max_batches=CALIB_BATCHES)\n",
    "\n",
    "    # 6) importance & masks\n",
    "    score_map = compute_importance_scores(stats)\n",
    "    masks = make_masks_from_scores(score_map, keep_ratio=KEEP_RATIO)\n",
    "    save_masks(masks, os.path.join(SAVE_DIR, \"masks.json\"))\n",
    "    plot_mask_histograms(masks)\n",
    "\n",
    "    # 7) build masked model and compile (use same loss)\n",
    "    masked_model = build_masked_model(model, masks)\n",
    "    masked_model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=loss_fn, metrics=[\"accuracy\"])\n",
    "    log(\"Masked model built.\")\n",
    "\n",
    "    # quick eval before FT (small subset)\n",
    "        # quick eval before FT (small subset)\n",
    "    try:\n",
    "        loss0, acc0 = masked_model.evaluate(val_ds.take(5), verbose=0)\n",
    "        log(\"Masked model pre-FT acc:\", acc0)\n",
    "    except Exception as e:\n",
    "        log(\"Masked model pre-eval failed:\", e)\n",
    "        acc0 = None\n",
    "\n",
    "    # 8) measure baseline flops & time\n",
    "    baseline_flops = calculate_model_flops(model, input_shape)\n",
    "    baseline_time = measure_inference_time(model, sample_x_small, steps=10)\n",
    "    log(f\"Baseline FLOPS: {baseline_flops:,}, baseline time (avg batch): {baseline_time:.4f}s\")\n",
    "\n",
    "    # 9) fine-tune masked model\n",
    "    try:\n",
    "        masked_model.fit(\n",
    "            train_ds.take(FT_BATCHES_TO_USE),\n",
    "            validation_data=val_ds.take(5),\n",
    "            epochs=FT_EPOCHS,\n",
    "            verbose=2\n",
    "        )\n",
    "    except Exception as e:\n",
    "        log(\"Masked fine-tune failed/partial:\", e)\n",
    "\n",
    "    # 10) structural prune\n",
    "    # NOTE: you can prune the original model or the masked_model.\n",
    "    #       pruning masked_model preserves gating decisions — often desired.\n",
    "    try:\n",
    "        pruned_model = prune_structural_sequential(masked_model, masks, input_shape)\n",
    "    except Exception:\n",
    "        # fallback to pruning original model if pruning masked_model fails\n",
    "        pruned_model = prune_structural_sequential(model, masks, input_shape)\n",
    "\n",
    "    # compile pruned model for evaluation / training with same loss\n",
    "    pruned_model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "        loss=loss_fn,\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    log(\"Starting fine-tuning of PRUNED model (EarlyStopping)...\")\n",
    "    early_cb = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    try:\n",
    "        pruned_model.fit(\n",
    "            train_ds,\n",
    "            validation_data=val_ds,\n",
    "            epochs=20,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            callbacks=[early_cb],\n",
    "            verbose=2\n",
    "        )\n",
    "    except Exception as e:\n",
    "        log(\"Pruned model fine-tune failed/partial:\", e)\n",
    "\n",
    "    # 11) evaluate models\n",
    "    log(\"Evaluating Original model:\")\n",
    "    orig_loss, orig_acc = model.evaluate(val_ds, verbose=0)\n",
    "    log(\"Original acc:\", orig_acc)\n",
    "\n",
    "    log(\"Evaluating Masked model (after FT):\")\n",
    "    try:\n",
    "        mask_loss, mask_acc = masked_model.evaluate(val_ds, verbose=0)\n",
    "        log(\"Masked acc:\", mask_acc)\n",
    "    except Exception as e:\n",
    "        log(\"Masked evaluate failed:\", e)\n",
    "        mask_acc = None\n",
    "\n",
    "    log(\"Evaluating Pruned model:\")\n",
    "    try:\n",
    "        pruned_loss, pruned_acc = pruned_model.evaluate(val_ds, verbose=0)\n",
    "        log(\"Pruned acc:\", pruned_acc)\n",
    "    except Exception as e:\n",
    "        log(\"Pruned evaluate failed:\", e)\n",
    "        pruned_acc = None\n",
    "\n",
    "    # 12) FLOPS & timing after prune\n",
    "    pruned_flops = calculate_model_flops(pruned_model, input_shape)\n",
    "    pruned_time = measure_inference_time(pruned_model, sample_x_small, steps=10)\n",
    "    log(f\"Pruned FLOPS: {pruned_flops:,}, pruned time: {pruned_time:.4f}s\")\n",
    "\n",
    "    # 13) summary & save\n",
    "    reduction = 1.0 - (pruned_flops / baseline_flops) if baseline_flops > 0 else 0.0\n",
    "    log(\"=\"*60)\n",
    "    log(\"SUMMARY:\")\n",
    "    log(f\"Baseline FLOPS: {baseline_flops:,}\")\n",
    "    log(f\"Pruned FLOPS: {pruned_flops:,}\")\n",
    "    log(f\"FLOPS reduction: {reduction:.2%}\")\n",
    "    log(f\"Original acc: {orig_acc}, Masked acc: {mask_acc}, Pruned acc: {pruned_acc}\")\n",
    "    log(\"=\"*60)\n",
    "\n",
    "    # ---- Extra Metrics: GFLOPS + Accuracy Reduction ----\n",
    "    baseline_gflops = baseline_flops / 1e9\n",
    "    pruned_gflops = pruned_flops / 1e9\n",
    "    gflops_reduction = 1.0 - (pruned_gflops / baseline_gflops) if baseline_gflops > 0 else 0.0\n",
    "    acc_reduction = (orig_acc - pruned_acc) if (orig_acc is not None and pruned_acc is not None) else None\n",
    "\n",
    "    log(f\"Baseline GFLOPS: {baseline_gflops:.4f}\")\n",
    "    log(f\"Pruned GFLOPS: {pruned_gflops:.4f}\")\n",
    "    log(f\"GFLOPS reduction: {gflops_reduction:.2%}\")\n",
    "    if acc_reduction is not None:\n",
    "        log(f\"Accuracy reduction: {acc_reduction:.4f}\")\n",
    "    else:\n",
    "        log(\"Accuracy reduction: N/A\")\n",
    "\n",
    "    # save artifacts\n",
    "    try:\n",
    "        # use proper file extensions to avoid Keras save errors\n",
    "        baseline_name = base_name + \"_baseline.keras\"\n",
    "        masked_name   = base_name + \"_masked.keras\"\n",
    "        pruned_name   = base_name + \"_pruned.keras\"\n",
    "\n",
    "        model.save(os.path.join(SAVE_DIR, baseline_name))\n",
    "        masked_model.save(os.path.join(SAVE_DIR, masked_name))\n",
    "        pruned_model.save(os.path.join(SAVE_DIR, pruned_name))\n",
    "\n",
    "        log(f\"Saved models under names: {baseline_name}, {masked_name}, {pruned_name}\")\n",
    "\n",
    "        log(\"Saved models to\", SAVE_DIR)\n",
    "    except Exception as e:\n",
    "        log(\"Save models failed:\", e)\n",
    "\n",
    "    return {\n",
    "        \"model\": model,\n",
    "        \"masked_model\": masked_model,\n",
    "        \"pruned_model\": pruned_model,\n",
    "        \"masks\": masks,\n",
    "        \"baseline_flops\": baseline_flops,\n",
    "        \"pruned_flops\": pruned_flops,\n",
    "        \"baseline_time\": baseline_time,\n",
    "        \"pruned_time\": pruned_time,\n",
    "        \"orig_acc\": orig_acc,\n",
    "        \"mask_acc\": mask_acc,\n",
    "        \"pruned_acc\": pruned_acc\n",
    "    }\n",
    "\n",
    "# ---------------------------\n",
    "# Run\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    out = full_pipeline(MODEL_PATH, DATASET_PATH)\n",
    "    log(\"Pipeline finished. Outputs:\", out.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4ec88f",
   "metadata": {},
   "source": [
    "# **CNN user input masking only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a48ca5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading model: D:\\college\\sem-8\\models\\pothole_cnn_model.h5\n",
      "[INFO] Loaded model directly.\n",
      "[INFO] Model loaded. Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">11,075,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │    \u001b[38;5;34m11,075,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m129\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,169,089</span> (42.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,169,089\u001b[0m (42.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,169,089</span> (42.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,169,089\u001b[0m (42.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Inferred input shape: (224, 224, 3)\n",
      "[INFO] Loading dataset folder: D:\\college\\sem-8\\dataset\\pothole image_size: (224, 224)\n",
      "Found 681 files belonging to 2 classes.\n",
      "Using 545 files for training.\n",
      "Found 681 files belonging to 2 classes.\n",
      "Using 136 files for validation.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required.\n\t [[{{node decode_image/DecodeImage}}]] [Op:IteratorGetNext] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 548\u001b[0m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[0;32m    545\u001b[0m \u001b[38;5;66;03m# Run\u001b[39;00m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 548\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mfull_pipeline_mask_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATASET_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    549\u001b[0m     log(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline finished. Metadata keys:\u001b[39m\u001b[38;5;124m\"\u001b[39m, out\u001b[38;5;241m.\u001b[39mkeys())\n",
      "Cell \u001b[1;32mIn[55], line 404\u001b[0m, in \u001b[0;36mfull_pipeline_mask_only\u001b[1;34m(model_path, dataset_path)\u001b[0m\n\u001b[0;32m    402\u001b[0m     sample_x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(val_ds))\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m--> 404\u001b[0m     sample_x, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m sample_x_small \u001b[38;5;241m=\u001b[39m sample_x[:\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;241m16\u001b[39m, sample_x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n\u001b[0;32m    407\u001b[0m \u001b[38;5;66;03m# choose pruneable layers: conv + hidden dense (exclude final classifier)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ishan\\Documents\\sample_p1\\env\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:826\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    825\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 826\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    827\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ishan\\Documents\\sample_p1\\env\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:776\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 776\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    777\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    778\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    781\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ishan\\Documents\\sample_p1\\env\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3113\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3111\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 3113\u001b[0m   \u001b[43m_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_from_not_ok_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3114\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_FallbackException:\n\u001b[0;32m   3115\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ishan\\Documents\\sample_p1\\env\\Lib\\site-packages\\tensorflow\\python\\framework\\ops.py:6002\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6000\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mraise_from_not_ok_status\u001b[39m(e, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m   6001\u001b[0m   e\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m name: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(name \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m-> 6002\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_status_to_exception(e) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__IteratorGetNext_output_types_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Unknown image file format. One of JPEG, PNG, GIF, BMP required.\n\t [[{{node decode_image/DecodeImage}}]] [Op:IteratorGetNext] name: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "sequential_cnn_mask_only.py\n",
    "\n",
    "Mask-only pruning pipeline (Sequential CNN)\n",
    "- No structural pruning (no physical removal of filters)\n",
    "- Builds masked model with gates, fine-tunes masked model\n",
    "- Computes baseline FLOPS and effective FLOPS when applying masks (estimation)\n",
    "- Measures inference time and prints metrics\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# ---------------------------\n",
    "# USER CONFIG\n",
    "# ---------------------------\n",
    "MODEL_PATH = r\"D:\\college\\sem-8\\models\\pothole_cnn_model.h5\"\n",
    "DATASET_PATH = r\"D:\\college\\sem-8\\dataset\\pothole\"\n",
    "SAVE_DIR = r\"pruning_output\"\n",
    "MODEL_SAVE_EXT = \".keras\"   # use \".keras\" or \".h5\"\n",
    "\n",
    "KEEP_RATIO = 0.7\n",
    "ALPHA, BETA, GAMMA = 0.4, 0.3, 0.3\n",
    "BATCH_SIZE = 64\n",
    "CALIB_BATCHES = 30\n",
    "FT_EPOCHS = 5\n",
    "FT_BATCHES_TO_USE = 150\n",
    "PLOT_RESULTS = True\n",
    "VERBOSE = True\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def log(*args):\n",
    "    if VERBOSE:\n",
    "        print(\"[INFO]\", *args)\n",
    "\n",
    "# ---------------------------\n",
    "# Safe load model (handles '/' in h5 layer names)\n",
    "# ---------------------------\n",
    "def safe_load_model(model_path):\n",
    "    log(\"Loading model:\", model_path)\n",
    "    try:\n",
    "        m = tf.keras.models.load_model(model_path, compile=False)\n",
    "        log(\"Loaded model directly.\")\n",
    "        return m\n",
    "    except Exception as e:\n",
    "        log(\"Direct load failed:\", e)\n",
    "    # try sanitizing H5 model_config\n",
    "    try:\n",
    "        with h5py.File(model_path, \"r\") as f:\n",
    "            if \"model_config\" in f:\n",
    "                raw = f[\"model_config\"][()]\n",
    "                if isinstance(raw, bytes):\n",
    "                    raw = raw.decode(\"utf-8\")\n",
    "                cfg_json = json.loads(raw)\n",
    "                changed = False\n",
    "                for layer in cfg_json.get(\"config\", {}).get(\"layers\", []):\n",
    "                    cfg = layer.get(\"config\", {})\n",
    "                    name = cfg.get(\"name\")\n",
    "                    if isinstance(name, str) and \"/\" in name:\n",
    "                        new_name = name.replace(\"/\", \"_\")\n",
    "                        cfg[\"name\"] = new_name\n",
    "                        changed = True\n",
    "                        log(f\"[FIX] layer name: {name} -> {new_name}\")\n",
    "                if changed:\n",
    "                    fixed_json = json.dumps(cfg_json)\n",
    "                    model = tf.keras.models.model_from_json(fixed_json)\n",
    "                    model.load_weights(model_path)\n",
    "                    log(\"Loaded model from sanitized JSON + weights.\")\n",
    "                    return model\n",
    "    except Exception as e2:\n",
    "        log(\"H5 sanitization attempt failed:\", e2)\n",
    "    # final fallback\n",
    "    try:\n",
    "        m = tf.keras.models.load_model(model_path, compile=False, safe_mode=False)\n",
    "        log(\"Loaded model with safe_mode=False.\")\n",
    "        return m\n",
    "    except Exception as e3:\n",
    "        log(\"All load attempts failed:\", e3)\n",
    "        raise RuntimeError(\"Failed to load model. Ensure path and format are correct.\")\n",
    "\n",
    "# ---------------------------\n",
    "# Dataset loader (folder)\n",
    "# ---------------------------\n",
    "def load_image_folder_dataset(path, image_size, batch_size=BATCH_SIZE):\n",
    "    log(\"Loading dataset folder:\", path, \"image_size:\", image_size)\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        path,\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=42,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        path,\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\",\n",
    "        seed=42,\n",
    "        image_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    rescaler = layers.Rescaling(1.0 / 255)\n",
    "    train_ds = train_ds.map(lambda x, y: (rescaler(x), y)).prefetch(tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.map(lambda x, y: (rescaler(x), y)).prefetch(tf.data.AUTOTUNE)\n",
    "    return train_ds, val_ds\n",
    "\n",
    "# ---------------------------\n",
    "# Stats (activation, grad, variance)\n",
    "# ---------------------------\n",
    "def compute_activation_grad_stats(model, layer_names, dataset, max_batches=CALIB_BATCHES):\n",
    "    log(\"Computing activation & gradient stats...\")\n",
    "    results_A, results_V, results_G = {n:[] for n in layer_names}, {n:[] for n in layer_names}, {n:[] for n in layer_names}\n",
    "    batch_count = 0\n",
    "    for x_batch, y_batch in dataset:\n",
    "        if batch_count >= max_batches:\n",
    "            break\n",
    "        batch_count += 1\n",
    "        layer_acts = {}\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            a = x_batch\n",
    "            for layer in model.layers:\n",
    "                a = layer(a)\n",
    "                if layer.name in layer_names:\n",
    "                    tape.watch(a)\n",
    "                    layer_acts[layer.name] = a\n",
    "            preds = a\n",
    "            loss = tf.keras.losses.sparse_categorical_crossentropy(y_batch, preds)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "        for name in layer_names:\n",
    "            a = layer_acts[name]\n",
    "            if len(a.shape) == 4:\n",
    "                A = tf.reduce_mean(tf.abs(a), axis=(0,1,2)).numpy()\n",
    "                V = tf.math.reduce_variance(a, axis=(0,1,2)).numpy()\n",
    "            else:\n",
    "                A = tf.reduce_mean(tf.abs(a), axis=0).numpy()\n",
    "                V = tf.math.reduce_variance(a, axis=0).numpy()\n",
    "            grad = tape.gradient(loss, a)\n",
    "            if grad is None:\n",
    "                G = np.zeros_like(A)\n",
    "            else:\n",
    "                if len(grad.shape) == 4:\n",
    "                    G = tf.reduce_mean(tf.abs(grad), axis=(0,1,2)).numpy()\n",
    "                else:\n",
    "                    G = tf.reduce_mean(tf.abs(grad), axis=0).numpy()\n",
    "            results_A[name].append(A)\n",
    "            results_V[name].append(V)\n",
    "            results_G[name].append(G)\n",
    "        del tape\n",
    "    stats = {}\n",
    "    for name in layer_names:\n",
    "        A = np.mean(results_A[name], axis=0)\n",
    "        V = np.mean(results_V[name], axis=0)\n",
    "        G = np.mean(results_G[name], axis=0)\n",
    "        stats[name] = (A, G, V)\n",
    "        log(f\"{name}: units={len(A)} meanA={A.mean():.6e} meanG={G.mean():.6e} meanV={V.mean():.6e}\")\n",
    "    return stats\n",
    "\n",
    "# ---------------------------\n",
    "# Importance scores & masks\n",
    "# ---------------------------\n",
    "def compute_importance_scores(stats, alpha=ALPHA, beta=BETA, gamma=GAMMA):\n",
    "    def normalize(x):\n",
    "        x = x - x.min()\n",
    "        if x.max() > 0:\n",
    "            x = x / x.max()\n",
    "        return x\n",
    "    scores = {}\n",
    "    for name, (A,G,V) in stats.items():\n",
    "        scores[name] = alpha*normalize(A) + beta*normalize(G) + gamma*normalize(V)\n",
    "    return scores\n",
    "\n",
    "def make_masks_from_scores(score_map, keep_ratio=KEEP_RATIO):\n",
    "    masks = {}\n",
    "    for name, score in score_map.items():\n",
    "        k = max(1, int(len(score) * keep_ratio))\n",
    "        thresh = np.partition(score, -k)[-k]\n",
    "        mask = (score >= thresh).astype(np.float32)\n",
    "        masks[name] = mask\n",
    "        log(f\"{name}: keep {int(mask.sum())}/{len(mask)}\")\n",
    "    return masks\n",
    "\n",
    "# ---------------------------\n",
    "# Mask gate & masked model\n",
    "# ---------------------------\n",
    "class CNNGate(tf.keras.layers.Layer):\n",
    "    def __init__(self, mask=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.mask = tf.constant(mask, dtype=tf.float32) if mask is not None else None\n",
    "    def call(self, x):\n",
    "        if self.mask is None:\n",
    "            return x\n",
    "        if len(x.shape) == 4:\n",
    "            return x * tf.reshape(self.mask, (1,1,1,-1))\n",
    "        else:\n",
    "            return x * self.mask\n",
    "\n",
    "def build_masked_model(orig_model, masks):\n",
    "    log(\"Building masked model with gates (no structural changes)...\")\n",
    "    inp = tf.keras.Input(shape=orig_model.input_shape[1:])\n",
    "    x = inp\n",
    "    for layer in orig_model.layers:\n",
    "        x = layer(x)\n",
    "        if layer.name in masks:\n",
    "            x = CNNGate(mask=masks[layer.name], name=layer.name + \"_gate\")(x)\n",
    "    masked = tf.keras.Model(inputs=inp, outputs=x, name=orig_model.name + \"_masked\")\n",
    "    # best-effort copy weights to identically named layers\n",
    "    for layer in orig_model.layers:\n",
    "        try:\n",
    "            masked_layer = masked.get_layer(layer.name)\n",
    "            masked_layer.set_weights(layer.get_weights())\n",
    "        except Exception:\n",
    "            pass\n",
    "    return masked\n",
    "\n",
    "# ---------------------------\n",
    "# FLOPS helpers: baseline & effective (using masks)\n",
    "# ---------------------------\n",
    "def calculate_conv_flops(input_shape, kernel_shape, strides=(1,1), padding='same'):\n",
    "    h_in, w_in, c_in = input_shape\n",
    "    kh, kw, _, c_out = kernel_shape\n",
    "    if padding == 'same':\n",
    "        h_out = math.ceil(h_in / strides[0])\n",
    "        w_out = math.ceil(w_in / strides[1])\n",
    "    else:\n",
    "        h_out = math.ceil((h_in - kh + 1) / strides[0])\n",
    "        w_out = math.ceil((w_in - kw + 1) / strides[1])\n",
    "    flops = h_out * w_out * (kh * kw * c_in) * c_out * 2\n",
    "    return flops, (h_out, w_out, c_out)\n",
    "\n",
    "def calculate_dense_flops(in_size, out_size):\n",
    "    return in_size * out_size * 2\n",
    "\n",
    "def calculate_model_flops(model, input_shape):\n",
    "    total = 0\n",
    "    current_shape = tuple(input_shape)\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, layers.Conv2D):\n",
    "            weights = layer.get_weights()\n",
    "            if not weights:\n",
    "                continue\n",
    "            kernel_shape = weights[0].shape\n",
    "            layer_flops, current_shape = calculate_conv_flops(current_shape, kernel_shape, strides=layer.strides, padding=layer.padding)\n",
    "            total += layer_flops\n",
    "        elif isinstance(layer, layers.Flatten):\n",
    "            current_shape = (int(np.prod(current_shape)),)\n",
    "        elif isinstance(layer, layers.Dense):\n",
    "            in_size = current_shape[0] if isinstance(current_shape, tuple) and len(current_shape)>0 else int(current_shape)\n",
    "            layer_flops = calculate_dense_flops(in_size, layer.units)\n",
    "            total += layer_flops\n",
    "            current_shape = (layer.units,)\n",
    "        elif isinstance(layer, layers.MaxPooling2D):\n",
    "            h,w,c = current_shape\n",
    "            pool = layer.pool_size[0] if hasattr(layer.pool_size, \"__getitem__\") else layer.pool_size\n",
    "            current_shape = (h//pool, w//pool, c)\n",
    "        else:\n",
    "            # ignore other layers\n",
    "            pass\n",
    "    return total\n",
    "\n",
    "def calculate_effective_flops_with_masks(model, masks, input_shape):\n",
    "    \"\"\"\n",
    "    Estimate effective FLOPS when applying masks (gates).\n",
    "    For Conv layers, reduce out_channels by mask.sum().\n",
    "    For Dense layers, reduce output units by mask.sum() if masked.\n",
    "    This is an estimate (masked model still contains same kernels; runtime reduction depends on backend).\n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    current_shape = tuple(input_shape)\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, layers.Conv2D):\n",
    "            weights = layer.get_weights()\n",
    "            if not weights:\n",
    "                continue\n",
    "            kernel_shape = weights[0].shape  # (kh, kw, in_c, out_c)\n",
    "            orig_out = kernel_shape[3]\n",
    "            if layer.name in masks:\n",
    "                effective_out = int(np.sum(masks[layer.name]))\n",
    "            else:\n",
    "                effective_out = orig_out\n",
    "            kh, kw = kernel_shape[0], kernel_shape[1]\n",
    "            # use current in_channels from current_shape\n",
    "            h_in, w_in, c_in = current_shape\n",
    "            # if mask existed on previous conv, c_in should be adjusted in this estimation:\n",
    "            # We will approximate c_in as kernel_shape[2] scaled by ratio of previous mask if previous named layer was masked.\n",
    "            # Simpler estimation: use kernel_shape[2] as in_channels\n",
    "            c_in_effective = kernel_shape[2]\n",
    "            if layer.name in masks:\n",
    "                # compute output dims\n",
    "                strides = layer.strides\n",
    "                padding = layer.padding\n",
    "                h_out = math.ceil(h_in / strides[0]) if padding == 'same' else math.ceil((h_in - kh + 1)/strides[0])\n",
    "                w_out = math.ceil(w_in / strides[1]) if padding == 'same' else math.ceil((w_in - kw + 1)/strides[1])\n",
    "            else:\n",
    "                strides = layer.strides\n",
    "                padding = layer.padding\n",
    "                kh, kw = kernel_shape[0], kernel_shape[1]\n",
    "                if padding == 'same':\n",
    "                    h_out = math.ceil(h_in / strides[0])\n",
    "                    w_out = math.ceil(w_in / strides[1])\n",
    "                else:\n",
    "                    h_out = math.ceil((h_in - kh + 1)/strides[0])\n",
    "                    w_out = math.ceil((w_in - kw + 1)/strides[1])\n",
    "            flops = h_out * w_out * (kh * kw * c_in_effective) * effective_out * 2\n",
    "            total += flops\n",
    "            current_shape = (h_out, w_out, effective_out)\n",
    "        elif isinstance(layer, layers.Flatten):\n",
    "            current_shape = (int(np.prod(current_shape)),)\n",
    "        elif isinstance(layer, layers.Dense):\n",
    "            in_size = current_shape[0] if isinstance(current_shape, tuple) and len(current_shape)>0 else int(current_shape)\n",
    "            if layer.name in masks:\n",
    "                effective_out = int(np.sum(masks[layer.name]))\n",
    "            else:\n",
    "                effective_out = layer.units\n",
    "            layer_flops = calculate_dense_flops(in_size, effective_out)\n",
    "            total += layer_flops\n",
    "            current_shape = (effective_out,)\n",
    "        elif isinstance(layer, layers.MaxPooling2D):\n",
    "            h,w,c = current_shape\n",
    "            pool = layer.pool_size[0] if hasattr(layer.pool_size, \"__getitem__\") else layer.pool_size\n",
    "            current_shape = (h//pool, w//pool, c)\n",
    "        else:\n",
    "            pass\n",
    "    return total\n",
    "\n",
    "# ---------------------------\n",
    "# inference timing\n",
    "# ---------------------------\n",
    "def measure_inference_time(model, sample_batch, steps=20):\n",
    "    model.predict(sample_batch, verbose=0)\n",
    "    t0 = time.time()\n",
    "    for _ in range(steps):\n",
    "        model.predict(sample_batch, verbose=0)\n",
    "    t1 = time.time()\n",
    "    return (t1 - t0) / steps\n",
    "\n",
    "# ---------------------------\n",
    "# save helpers\n",
    "# ---------------------------\n",
    "def save_masks(masks, path):\n",
    "    serial = {k: v.tolist() for k, v in masks.items()}\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(serial, f, indent=2)\n",
    "    log(\"Saved masks to\", path)\n",
    "\n",
    "def save_model_safe(model, path_no_ext):\n",
    "    ext = MODEL_SAVE_EXT if MODEL_SAVE_EXT.startswith(\".\") else \".\" + MODEL_SAVE_EXT\n",
    "    fullpath = path_no_ext + ext\n",
    "    try:\n",
    "        model.save(fullpath)\n",
    "        log(\"Saved model to\", fullpath)\n",
    "    except Exception as e:\n",
    "        log(\"Failed to save model to\", fullpath, \":\", e)\n",
    "\n",
    "def plot_mask_histograms(masks, outdir=SAVE_DIR):\n",
    "    if not PLOT_RESULTS:\n",
    "        return\n",
    "    for name, mask in masks.items():\n",
    "        plt.figure(figsize=(5,2))\n",
    "        plt.title(name)\n",
    "        plt.hist(mask, bins=2)\n",
    "        plt.xlabel(\"0=pruned, 1=kept\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(outdir, f\"mask_{name}.png\"))\n",
    "        plt.close()\n",
    "\n",
    "def per_layer_remaining_stats(masks):\n",
    "    stats = {}\n",
    "    for name, mask in masks.items():\n",
    "        total = len(mask)\n",
    "        kept = int(mask.sum())\n",
    "        stats[name] = {\"kept\": kept, \"total\": total, \"ratio\": kept/total}\n",
    "    return stats\n",
    "\n",
    "# ---------------------------\n",
    "# MAIN pipeline (mask-only)\n",
    "# ---------------------------\n",
    "def full_pipeline_mask_only(model_path, dataset_path):\n",
    "    model = safe_load_model(model_path)\n",
    "    log(\"Model loaded. Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    # compile original for evaluation\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    input_shape = model.input_shape[1:]\n",
    "    log(\"Inferred input shape:\", input_shape)\n",
    "\n",
    "    train_ds, val_ds = load_image_folder_dataset(dataset_path, image_size=input_shape[:2], batch_size=BATCH_SIZE)\n",
    "    calib_ds = train_ds.take(CALIB_BATCHES)\n",
    "\n",
    "    try:\n",
    "        sample_x, _ = next(iter(val_ds))\n",
    "    except Exception:\n",
    "        sample_x, _ = next(iter(train_ds))\n",
    "    sample_x_small = sample_x[:min(16, sample_x.shape[0])]\n",
    "\n",
    "    # choose pruneable layers: conv + hidden dense (exclude final classifier)\n",
    "    dense_layers = [lyr for lyr in model.layers if isinstance(lyr, layers.Dense)]\n",
    "    last_dense = dense_layers[-1] if dense_layers else None\n",
    "    prune_layer_names = []\n",
    "    for lyr in model.layers:\n",
    "        if isinstance(lyr, layers.Conv2D):\n",
    "            prune_layer_names.append(lyr.name)\n",
    "        elif isinstance(lyr, layers.Dense) and lyr is not last_dense:\n",
    "            prune_layer_names.append(lyr.name)\n",
    "    log(\"Layers considered for masking:\", prune_layer_names)\n",
    "\n",
    "    # compute stats, scores, masks\n",
    "    stats = compute_activation_grad_stats(model, prune_layer_names, calib_ds, max_batches=CALIB_BATCHES)\n",
    "    score_map = compute_importance_scores(stats)\n",
    "    masks = make_masks_from_scores(score_map, keep_ratio=KEEP_RATIO)\n",
    "    save_masks(masks, os.path.join(SAVE_DIR, \"masks.json\"))\n",
    "    plot_mask_histograms(masks)\n",
    "\n",
    "    # build masked model\n",
    "    masked_model = build_masked_model(model, masks)\n",
    "    masked_model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    log(\"Masked model built.\")\n",
    "\n",
    "    # evaluate masked before FT\n",
    "    try:\n",
    "        loss0, acc0 = masked_model.evaluate(val_ds.take(5), verbose=0)\n",
    "        log(\"Masked model pre-FT acc:\", acc0)\n",
    "    except Exception as e:\n",
    "        log(\"Masked model pre-eval failed:\", e)\n",
    "\n",
    "    # baseline flops/time\n",
    "    baseline_flops = calculate_model_flops(model, input_shape)\n",
    "    baseline_gflops = baseline_flops / 1e9\n",
    "    baseline_time = measure_inference_time(model, sample_x_small, steps=10)\n",
    "    log(f\"Baseline FLOPS: {baseline_flops:,} ({baseline_gflops:.6f} GFLOPS), baseline time (avg batch): {baseline_time:.4f}s\")\n",
    "\n",
    "    # fine-tune masked model\n",
    "    try:\n",
    "        masked_model.fit(train_ds.take(FT_BATCHES_TO_USE), validation_data=val_ds.take(5), epochs=FT_EPOCHS, verbose=2)\n",
    "    except Exception as e:\n",
    "        log(\"Masked fine-tune failed/partial:\", e)\n",
    "\n",
    "    # eval\n",
    "    log(\"Evaluating Original model:\")\n",
    "    orig_loss, orig_acc = model.evaluate(val_ds, verbose=0)\n",
    "    log(\"Original acc:\", orig_acc)\n",
    "\n",
    "    log(\"Evaluating Masked model (after FT):\")\n",
    "    try:\n",
    "        mask_loss, mask_acc = masked_model.evaluate(val_ds, verbose=0)\n",
    "        log(\"Masked acc:\", mask_acc)\n",
    "    except Exception as e:\n",
    "        log(\"Masked evaluate failed:\", e)\n",
    "        mask_acc = None\n",
    "\n",
    "    # Effective FLOPS after masking (estimate using masks)\n",
    "    masked_effective_flops = calculate_effective_flops_with_masks(model, masks, input_shape)\n",
    "    masked_effective_gflops = masked_effective_flops / 1e9\n",
    "\n",
    "    # measure masked inference time (actual)\n",
    "    masked_time = measure_inference_time(masked_model, sample_x_small, steps=10)\n",
    "    log(f\"Masked effective FLOPS (estimate): {masked_effective_flops:,} ({masked_effective_gflops:.6f} GFLOPS)\")\n",
    "    log(f\"Masked actual inference time (avg batch): {masked_time:.4f}s\")\n",
    "\n",
    "    # metrics\n",
    "    speedup_time = (baseline_time / masked_time) if masked_time > 0 else float(\"inf\")\n",
    "    flops_reduction = (1 - (masked_effective_flops / baseline_flops)) if baseline_flops > 0 else 0.0\n",
    "    acc_drop_abs = (orig_acc - mask_acc) if (orig_acc is not None and mask_acc is not None) else None\n",
    "    acc_drop_pct = (acc_drop_abs / orig_acc * 100) if (acc_drop_abs is not None and orig_acc != 0) else None\n",
    "\n",
    "    orig_params = model.count_params()\n",
    "    masked_params = masked_model.count_params()  # same structure -> same params, gates don't add many\n",
    "    param_reduction_pct = (1 - masked_params / orig_params) * 100 if orig_params > 0 else 0.0\n",
    "\n",
    "    layer_stats = per_layer_remaining_stats(masks)\n",
    "\n",
    "    # summary\n",
    "    log(\"=\"*70)\n",
    "    log(\"FINAL SUMMARY (MASK-ONLY)\")\n",
    "    log(\"=\"*70)\n",
    "    log(f\"Baseline GFLOPS: {baseline_gflops:.6f} GFLOPS\")\n",
    "    log(f\"Masked effective GFLOPS (estimate): {masked_effective_gflops:.6f} GFLOPS\")\n",
    "    log(f\"FLOPS reduction (estimate): {flops_reduction*100:.2f}%\")\n",
    "    log(f\"Baseline time (avg batch): {baseline_time:.4f}s\")\n",
    "    log(f\"Masked time (avg batch):   {masked_time:.4f}s\")\n",
    "    log(f\"Speed-up ratio (time): {speedup_time:.3f}x\")\n",
    "    if acc_drop_abs is not None:\n",
    "        log(f\"Original acc: {orig_acc:.4f}, Masked acc: {mask_acc:.4f}\")\n",
    "        log(f\"Accuracy drop: {acc_drop_abs:.4f} ({acc_drop_pct:.2f}%)\")\n",
    "    else:\n",
    "        log(\"Accuracy numbers unavailable for drop computation.\")\n",
    "    log(f\"Original params: {orig_params:,}, Masked params: {masked_params:,}\")\n",
    "    log(f\"Parameter reduction (structure-level): {param_reduction_pct:.2f}% (usually 0 for mask-only)\")\n",
    "    log(\"Per-layer remaining (kept/total):\")\n",
    "    for name, s in layer_stats.items():\n",
    "        log(f\"  {name}: {s['kept']}/{s['total']} ({s['ratio']:.2%})\")\n",
    "    log(\"=\"*70)\n",
    "\n",
    "    # save artifacts\n",
    "    save_masks(masks, os.path.join(SAVE_DIR, \"masks.json\"))\n",
    "    try:\n",
    "        save_model_safe(model, os.path.join(SAVE_DIR, \"model_baseline\"))\n",
    "        save_model_safe(masked_model, os.path.join(SAVE_DIR, \"model_masked\"))\n",
    "    except Exception as e:\n",
    "        log(\"Save models failed:\", e)\n",
    "\n",
    "    metadata = {\n",
    "        \"baseline_flops\": int(baseline_flops),\n",
    "        \"masked_effective_flops\": int(masked_effective_flops),\n",
    "        \"baseline_gflops\": float(baseline_gflops),\n",
    "        \"masked_effective_gflops\": float(masked_effective_gflops),\n",
    "        \"baseline_time\": float(baseline_time),\n",
    "        \"masked_time\": float(masked_time),\n",
    "        \"orig_acc\": float(orig_acc),\n",
    "        \"mask_acc\": float(mask_acc) if mask_acc is not None else None,\n",
    "        \"orig_params\": int(orig_params),\n",
    "        \"masked_params\": int(masked_params),\n",
    "        \"flops_reduction_pct\": float(flops_reduction*100),\n",
    "        \"per_layer_stats\": layer_stats\n",
    "    }\n",
    "    with open(os.path.join(SAVE_DIR, \"mask_only_summary.json\"), \"w\") as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "\n",
    "    log(\"Saved metadata to\", os.path.join(SAVE_DIR, \"mask_only_summary.json\"))\n",
    "    return metadata\n",
    "\n",
    "# ---------------------------\n",
    "# helper reused at end\n",
    "# ---------------------------\n",
    "def per_layer_remaining_stats(masks):\n",
    "    stats = {}\n",
    "    for name, mask in masks.items():\n",
    "        total = len(mask)\n",
    "        kept = int(mask.sum())\n",
    "        stats[name] = {\"kept\": kept, \"total\": total, \"ratio\": kept/total}\n",
    "    return stats\n",
    "\n",
    "# ---------------------------\n",
    "# Run\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    out = full_pipeline_mask_only(MODEL_PATH, DATASET_PATH)\n",
    "    log(\"Pipeline finished. Metadata keys:\", out.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1448adf0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f4eeec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
